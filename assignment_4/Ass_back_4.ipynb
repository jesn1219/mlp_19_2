{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "\n",
    "Submitter : JESOON KANG, 20170937\n",
    "Date : 2019. 10. \n",
    "\n",
    "\n",
    "    Assignment 4. \n",
    "\n",
    "-   -\n",
    "\n",
    "\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchvision\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Section 1. #### This Section is bringed Data_import_ex.py file.\n",
    "\n",
    "# Image Data import & resize\n",
    "\n",
    "transform = transforms.Compose([#transforms.Resize((256,256)),  \n",
    "                                transforms.Grayscale(),\t\t# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "                                transforms.ToTensor(),])\n",
    "\n",
    "#train_data_path = 'relative path of training data set'\n",
    "train_data_path = '../data/horse-or-human/train'\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "# if shuffle=True, the data reshuffled at every epoch \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=0)  \n",
    "\n",
    "\n",
    "validation_data_path = '../data/horse-or-human/validation'\n",
    "valset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=100, shuffle=True, num_workers=0)  \n",
    "\n",
    "#### Section 1 END ####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sigmoid Function.\n",
    "def sigmoid(z) :\n",
    "    return 1 / (1 + torch.pow(math.e,-z)+0.000001)\n",
    "\n",
    "def tanh(z) :\n",
    "    ret = (2 / (1 + torch.pow(math.e,-2*z) + 0.000001)) - 1\n",
    "    return ret\n",
    "\n",
    "def derv_tanh(z) :\n",
    "    ret = (1 - (tanh(z)**2))\n",
    "    return ret\n",
    "\n",
    "def relu(z) :\n",
    "    ret = z.clone().detach()\n",
    "    #print(ret)\n",
    "    tmp = torch.zeros_like(ret)\n",
    "    ret = torch.where(ret<=0,tmp,ret)\n",
    "    return ret\n",
    "                                                                  \n",
    "def derv_relu(z) :\n",
    "    ret = z.clone().detach()\n",
    "    tmp_1 = torch.zeros_like(ret)\n",
    "    tmp_2 = torch.ones_like(ret)\n",
    "    ret = torch.where(ret<0,tmp_1,tmp_2)\n",
    "    #print(ret)\n",
    "    return ret\n",
    "    \n",
    "            \n",
    "def leakly_relu(z) :\n",
    "    ret = z.clone().detach()\n",
    "    tmp1 = torch.ones_like(ret)\n",
    "    ret = torch.where(ret<0,ret*0.01,ret)\n",
    "    return ret\n",
    "\n",
    "def derv_leakly_relu(z) :\n",
    "    ret = z.clone().detach()\n",
    "    tmp1 = torch.ones_like(ret)\n",
    "    ret = torch.where(ret<0, tmp1*0.01,tmp1)\n",
    "    \n",
    "    return ret\n",
    "\n",
    "def get_activation(z,type) :\n",
    "    if (type == 0) :\n",
    "        return sigmoid(z)\n",
    "    elif (type == 1) :\n",
    "        return tanh(z)\n",
    "    elif (type == 2) :\n",
    "        return relu(z)\n",
    "    elif (type == 3) :\n",
    "        return leakly_relu(z)\n",
    "    \n",
    "    else :\n",
    "        print(\"Error, get_activation\")\n",
    "        return 0\n",
    "\n",
    "def get_derv_activation(z,type) :\n",
    "    if (type == 0) :\n",
    "        return sigmoid(z)*(1-sigmoid(z))\n",
    "    elif (type == 1) :\n",
    "        return derv_tanh(z)\n",
    "    elif (type == 2) :\n",
    "        return derv_relu(z)\n",
    "    elif (type == 3) :\n",
    "        return derv_leakly_relu(z)    \n",
    "    else :\n",
    "        print(\"Error, get_derv_activation\")\n",
    "        return 0                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(y,a) :\n",
    "    #print(y,a)\n",
    "    ret = -(torch.div(y,a+0.000001) - torch.div(1-y,1-a+0.000001))\n",
    "    \n",
    "    return ret\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "FEATURE_SIZE = 10000\n",
    "class ML :\n",
    "    def __init__(self,act1,act2,act3,L1_size,L2_size,L3_size,lr,min_loss_diff) :\n",
    "        self.act_type_1 = act1\n",
    "        self.act_type_2 = act2\n",
    "        self.act_type_3 = act3 \n",
    "        self.l1_size = L1_size\n",
    "        self.l2_size = L2_size\n",
    "        self.l3_size = L3_size\n",
    "        self.feature_size = 10000\n",
    "        self.epoch = 0\n",
    "        self.lr = lr\n",
    "        self.min_loss_diff = min_loss_diff\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "        print(\"ML Object initialized\")\n",
    "        self.iter = 0\n",
    "\n",
    "        self.val_acc_log = []\n",
    "        self.val_loss_log = []\n",
    "        self.train_acc_log = []\n",
    "        self.train_loss_log = []\n",
    "        self.epoch_log = []\n",
    "        self.val_acc_log.append(0)\n",
    "        self.val_loss_log.append(0)\n",
    "        self.train_acc_log.append(0)\n",
    "        self.train_loss_log.append(0)\n",
    "        self.epoch_log.append(0)\n",
    "        \n",
    "    def init_weights(self) :\n",
    "        self.w_1 = torch.FloatTensor(self.l1_size,self.feature_size).uniform_(-1,1)\n",
    "        self.b_1 = torch.FloatTensor(1,self.l1_size).uniform_(-1,1)\n",
    "        \n",
    "        #torch.FloatTensor(a, b).uniform_(r1, r2)\n",
    "        \n",
    "        self.w_2 = torch.FloatTensor(self.l2_size,self.l1_size).uniform_(-1,1)\n",
    "        self.b_2 = torch.FloatTensor(1,self.l2_size).uniform_(-1,1)\n",
    "\n",
    "        self.w_3 = torch.FloatTensor(self.l3_size,self.l2_size).uniform_(-1,1)\n",
    "        self.b_3 = torch.FloatTensor(1,self.l3_size).uniform_(-1,1)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def training(self) :\n",
    "        \n",
    "        epoch = 0\n",
    "        for epoch in range(0,1000000):\n",
    "            train_acc_log_tmp = []\n",
    "            train_loss_log_tmp = []\n",
    "            val_acc_log_tmp = []\n",
    "            val_loss_log_tmp = []\n",
    "            \n",
    "\n",
    "        # load training images of the batch size for every iteration\n",
    "            for i, data in enumerate(trainloader):\n",
    "                \n",
    "                # inputs is the images\n",
    "                # labels is the class of the image\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.float() , labels.float()\n",
    "                # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "\n",
    "                # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "                \n",
    "                self.t_data_batch = torch.squeeze(torch.FloatTensor(data[0]),3)\n",
    "                \n",
    "                self.t_data_batch = self.t_data_batch.view(len(data[0]),FEATURE_SIZE)\n",
    "                self.z_1 = torch.matmul(self.t_data_batch,self.w_1.T) + self.b_1\n",
    "                #print(self.z_1)\n",
    "                self.a_1 = get_activation(self.z_1,self.act_type_1)\n",
    "                #print(self.a_1)\n",
    "                \n",
    "                self.z_2 = torch.matmul(self.a_1,self.w_2.T) + self.b_2\n",
    "\n",
    "                self.a_2 = get_activation(self.z_2,self.act_type_2) # 1027 x 50\n",
    "\n",
    "                self.z_3 = torch.matmul(self.a_2,self.w_3.T) + self.b_3\n",
    "                #print(self.z_3)\n",
    "                self.a_3 = get_activation(self.z_3,self.act_type_3) # 1027 x 1\n",
    "            \n",
    "                #print(self.a_3)\n",
    "                self.t_yh_batch = data[1].float().unsqueeze(1)\n",
    "\n",
    "                #print(self.a_3,self.t_yh_batch)\n",
    "                acc = self.get_acc(self.a_3,self.t_yh_batch)\n",
    "                loss = np.array(get_loss(self.t_yh_batch, self.a_3)).mean()\n",
    "                \n",
    "                train_acc_log_tmp.append(acc)\n",
    "                train_loss_log_tmp.append(loss)\n",
    "                \n",
    "                self.update_weights(self.t_yh_batch,self.a_3)\n",
    "            \n",
    "            \n",
    "            \n",
    "            train_acc = np.array(train_acc_log_tmp).mean()\n",
    "            train_loss = np.array(train_loss_log_tmp).mean()\n",
    "\n",
    "            print(\"epoch : %s, loss : %s, tra_acc : %s\"%(epoch,train_loss,train_acc))\n",
    "            \n",
    "           \n",
    "\n",
    "            # load validation images of the batch size for every iteration\n",
    "            for i, data in enumerate(valloader):\n",
    "\n",
    "                # inputs is the image\n",
    "                # labels is the class of the image\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.float() , labels.float()\n",
    "                # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "                \n",
    "                \n",
    "                # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "                \n",
    "                self.v_data_batch = torch.squeeze(torch.FloatTensor(data[0]),3)\n",
    "                \n",
    "                self.v_data_batch = self.v_data_batch.view(len(data[0]),FEATURE_SIZE)\n",
    "                \n",
    "                self.z_1 = torch.matmul(self.v_data_batch,self.w_1.T) + self.b_1\n",
    "                \n",
    "                self.a_1 = get_activation(self.z_1,self.act_type_1)\n",
    "                #print(self.a_1)\n",
    "\n",
    "                self.z_2 = torch.matmul(self.a_1,self.w_2.T) + self.b_2\n",
    "                self.a_2 = get_activation(self.z_2,self.act_type_2) # 1027 x 50\n",
    "\n",
    "                self.z_3 = torch.matmul(self.a_2,self.w_3.T) + self.b_3\n",
    "                self.a_3 = get_activation(self.z_3,self.act_type_3) # 1027 x 1\n",
    "\n",
    "                self.v_yh_batch = data[1].float().unsqueeze(1)\n",
    "                acc = self.get_acc(self.a_3,self.v_yh_batch)\n",
    "                \n",
    "                \n",
    "                loss = np.array(get_loss(self.v_yh_batch, self.a_3)).mean()\n",
    "                val_acc_log_tmp.append(acc)\n",
    "                val_loss_log_tmp.append(loss)\n",
    "            val_acc = np.array(val_acc_log_tmp).mean()\n",
    "            val_loss = np.array(val_loss_log_tmp).mean()\n",
    "            \n",
    "            print(\"epoch : %s, loss : %s, val_acc : %s\"%(epoch,val_loss,val_acc))\n",
    "\n",
    "            self.train_acc_log.append(train_acc)\n",
    "            self.train_loss_log.append(train_loss)\n",
    "            self.val_acc_log.append(val_acc)\n",
    "            self.val_loss_log.append(val_loss)\n",
    "            self.epoch_log.append(epoch)\n",
    "            epoch += 1\n",
    "            \n",
    "            tmp_idx = len(self.train_loss_log)-1\n",
    "            if ( abs(self.train_loss_log[tmp_idx]-self.train_loss_log[tmp_idx-1]) < self.min_loss_diff) :\n",
    "                print(\"Learning is terminated.\")\n",
    "                break\n",
    "\n",
    "        \n",
    "    def update_weights(self,t_y,a_3) :\n",
    "        error_wb3 = -(torch.div(t_y,a_3+ 0.00011) - torch.div(1.0-t_y,1.0-a_3+ 0.00001)) # sum ep\n",
    "        d_z_3 = error_wb3*get_derv_activation(self.z_3,self.act_type_3) #         \n",
    "        d_w_3 = torch.matmul(d_z_3.T,self.a_2)\n",
    "        d_b_3 = torch.sum(d_z_3, dim=0, keepdim=True) / self.a_2.shape[0] # mean도 됨\n",
    "        \n",
    "        #########\n",
    "        \n",
    "        error_wb2 = torch.matmul(d_z_3,self.w_3)\n",
    "        \n",
    "        d_z_2 = error_wb2*get_derv_activation(self.z_2,self.act_type_2)\n",
    "        \n",
    "        d_w_2 = torch.matmul(d_z_2.T,self.a_1)\n",
    "        d_b_2 = torch.sum(d_z_2, dim=0,keepdims=True) / self.a_1.shape[0]\n",
    "        \n",
    "   \n",
    "        error_wb1 = torch.matmul(d_z_2,self.w_2)\n",
    "        d_z_1 = error_wb1*get_derv_activation(self.z_1,self.act_type_1)\n",
    "        d_w_1 = torch.matmul(d_z_1.T,self.t_data_batch)\n",
    "        d_b_1 = torch.sum(d_z_1, dim=0,keepdims=True) / self.t_data_batch.shape[0]\n",
    "        \n",
    "        \n",
    "        self.w_3 += -self.lr*d_w_3\n",
    "        self.b_3 += -self.lr*d_b_3\n",
    "        \n",
    "        self.w_2 += -self.lr*d_w_2\n",
    "        self.b_2 += -self.lr*d_b_2\n",
    "        self.w_1 += -self.lr*d_w_1\n",
    "        self.b_1 += -self.lr*d_b_1\n",
    "        #print(b_3,b_2,b_1)\n",
    "        \n",
    "    def get_acc(self,yhat,y) :\n",
    "        count = 0\n",
    "      \n",
    "        for a,b in zip(yhat,y) :\n",
    "            if a >= 0.5 :\n",
    "                if b == 1 :\n",
    "                    count+=1\n",
    "            else :\n",
    "                if b == 0:\n",
    "                    count +=1\n",
    "        \n",
    "        return count / len(yhat)\n",
    "\n",
    "    def show_loss(self) :\n",
    "        #print(self.train_loss_log)\n",
    "        #print(self.val_loss_log)\n",
    "        #print(self.epoch_log)\n",
    "        \n",
    "        tmp_1 = torch.tensor(self.train_loss_log)\n",
    "        tmp_2 = torch.tensor(self.epoch_log)\n",
    "       \n",
    "        t1 = plt.plot(self.epoch_log,self.train_loss_log, color='orange',label='Training Loss')\n",
    "        t2 = plt.plot(self.epoch_log,self.val_loss_log, color= 'red',label='Validation Loss')\n",
    "        plt.title(\"Loss\")\n",
    "        plt.legend(['Training Loss','Validation Loss'])\n",
    "        plt.show()\n",
    "    def show_acc(self) :\n",
    "        t1 = plt.plot(self.epoch_log,self.train_acc_log, color='orange',label='Training Acc')\n",
    "        t2 = plt.plot(self.epoch_log,self.val_acc_log, color= 'red',label='Validation Acc')\n",
    "        plt.title(\"Accuracy\")\n",
    "        plt.legend(['Training Acc','Validation Acc'])\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "activation_type = 0 # 0 = sigmoid\n",
    "learningRate = 0.001\n",
    "min_loss_diff = 0.00001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML Object initialized\n"
     ]
    }
   ],
   "source": [
    "#1,1,0 means tanh, tanh, sigmoid\n",
    "machine = ML(1,1,0,10,5,1,learningRate,min_loss_diff)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, loss : 1.0600404, tra_acc : 0.5316835016835015\n",
      "epoch : 0, loss : 0.20998967, val_acc : 0.5783333333333333\n",
      "epoch : 1, loss : 0.1286435, tra_acc : 0.5536026936026937\n",
      "epoch : 1, loss : 0.11689044, val_acc : 0.5909523809523809\n",
      "epoch : 2, loss : 0.075681455, tra_acc : 0.5575084175084176\n",
      "epoch : 2, loss : 0.13972817, val_acc : 0.5711904761904762\n",
      "epoch : 3, loss : 0.012391556, tra_acc : 0.5636026936026937\n",
      "epoch : 3, loss : 0.20473401, val_acc : 0.5750000000000001\n",
      "epoch : 4, loss : 0.057575203, tra_acc : 0.5645117845117845\n",
      "epoch : 4, loss : 0.25515535, val_acc : 0.5652380952380952\n",
      "epoch : 5, loss : 0.054708634, tra_acc : 0.5605050505050505\n",
      "epoch : 5, loss : 0.20659447, val_acc : 0.5738095238095238\n",
      "epoch : 6, loss : 0.089015834, tra_acc : 0.5663299663299664\n",
      "epoch : 6, loss : 0.23923647, val_acc : 0.565952380952381\n",
      "epoch : 7, loss : 0.06586232, tra_acc : 0.5677777777777778\n",
      "epoch : 7, loss : 0.18643914, val_acc : 0.5816666666666667\n",
      "epoch : 8, loss : 0.115679786, tra_acc : 0.5689562289562289\n",
      "epoch : 8, loss : 0.16121666, val_acc : 0.5869047619047619\n",
      "epoch : 9, loss : 0.09744359, tra_acc : 0.579057239057239\n",
      "epoch : 9, loss : 0.19569953, val_acc : 0.5838095238095238\n",
      "epoch : 10, loss : 0.058741666, tra_acc : 0.5863299663299664\n",
      "epoch : 10, loss : 0.21766417, val_acc : 0.5845238095238096\n",
      "epoch : 11, loss : 0.025449563, tra_acc : 0.5835016835016834\n",
      "epoch : 11, loss : 0.19688295, val_acc : 0.5771428571428572\n",
      "epoch : 12, loss : 0.070239395, tra_acc : 0.5811447811447811\n",
      "epoch : 12, loss : 0.18866521, val_acc : 0.5916666666666667\n",
      "epoch : 13, loss : 0.08840158, tra_acc : 0.5825925925925927\n",
      "epoch : 13, loss : 0.18100904, val_acc : 0.5890476190476189\n",
      "epoch : 14, loss : 0.05762784, tra_acc : 0.5978787878787879\n",
      "epoch : 14, loss : 0.22851157, val_acc : 0.5778571428571428\n",
      "epoch : 15, loss : 0.05541793, tra_acc : 0.5908754208754208\n",
      "epoch : 15, loss : 0.2082821, val_acc : 0.5878571428571429\n",
      "epoch : 16, loss : 0.07583271, tra_acc : 0.5914141414141413\n",
      "epoch : 16, loss : 0.20217498, val_acc : 0.5864285714285714\n",
      "epoch : 17, loss : 0.05010204, tra_acc : 0.6055218855218855\n",
      "epoch : 17, loss : 0.25554502, val_acc : 0.5897619047619048\n",
      "epoch : 18, loss : 0.10641137, tra_acc : 0.5871380471380472\n",
      "epoch : 18, loss : 0.20048994, val_acc : 0.6061904761904763\n",
      "epoch : 19, loss : 0.055408966, tra_acc : 0.6024242424242425\n",
      "epoch : 19, loss : 0.23930292, val_acc : 0.5904761904761905\n",
      "epoch : 20, loss : 0.08573777, tra_acc : 0.5889562289562289\n",
      "epoch : 20, loss : 0.20426434, val_acc : 0.5804761904761905\n",
      "epoch : 21, loss : -0.0006836355, tra_acc : 0.6056902356902358\n",
      "epoch : 21, loss : 0.21582268, val_acc : 0.5983333333333333\n",
      "epoch : 22, loss : 0.024171142, tra_acc : 0.6151515151515151\n",
      "epoch : 22, loss : 0.28232372, val_acc : 0.5890476190476189\n",
      "epoch : 23, loss : 0.08190897, tra_acc : 0.6026936026936028\n",
      "epoch : 23, loss : 0.2861205, val_acc : 0.5811904761904761\n",
      "epoch : 24, loss : 0.083760716, tra_acc : 0.6016835016835016\n",
      "epoch : 24, loss : 0.29699025, val_acc : 0.5766666666666667\n",
      "epoch : 25, loss : 0.061102744, tra_acc : 0.6065993265993265\n",
      "epoch : 25, loss : 0.26403818, val_acc : 0.5792857142857143\n",
      "epoch : 26, loss : 0.05997932, tra_acc : 0.6145117845117846\n",
      "epoch : 26, loss : 0.19092965, val_acc : 0.5957142857142858\n",
      "epoch : 27, loss : 0.05276421, tra_acc : 0.6193265993265994\n",
      "epoch : 27, loss : 0.2198019, val_acc : 0.5771428571428571\n",
      "epoch : 28, loss : 0.021524234, tra_acc : 0.626969696969697\n",
      "epoch : 28, loss : 0.29309547, val_acc : 0.5711904761904762\n",
      "epoch : 29, loss : 0.06508706, tra_acc : 0.612053872053872\n",
      "epoch : 29, loss : 0.20411865, val_acc : 0.5957142857142856\n",
      "epoch : 30, loss : 0.04241301, tra_acc : 0.6220538720538721\n",
      "epoch : 30, loss : 0.2930406, val_acc : 0.5692857142857143\n",
      "epoch : 31, loss : 0.058246747, tra_acc : 0.6224242424242424\n",
      "epoch : 31, loss : 0.29223314, val_acc : 0.5864285714285714\n",
      "epoch : 32, loss : 0.0696715, tra_acc : 0.6287878787878788\n",
      "epoch : 32, loss : 0.22291762, val_acc : 0.6114285714285715\n",
      "epoch : 33, loss : 0.015413862, tra_acc : 0.6220538720538721\n",
      "epoch : 33, loss : 0.29293892, val_acc : 0.5938095238095238\n",
      "epoch : 34, loss : 0.07227826, tra_acc : 0.6281481481481482\n",
      "epoch : 34, loss : 0.23031646, val_acc : 0.606904761904762\n",
      "epoch : 35, loss : 0.012422332, tra_acc : 0.6427946127946128\n",
      "epoch : 35, loss : 0.29854724, val_acc : 0.599047619047619\n",
      "epoch : 36, loss : 0.061663058, tra_acc : 0.6408754208754209\n",
      "epoch : 36, loss : 0.35750306, val_acc : 0.5878571428571429\n",
      "epoch : 37, loss : 0.06981336, tra_acc : 0.6371380471380471\n",
      "epoch : 37, loss : 0.35141382, val_acc : 0.6159523809523809\n",
      "epoch : 38, loss : 0.058071706, tra_acc : 0.6374074074074074\n",
      "epoch : 38, loss : 0.31855264, val_acc : 0.6190476190476191\n",
      "epoch : 39, loss : 0.09468911, tra_acc : 0.6517845117845117\n",
      "epoch : 39, loss : 0.2709171, val_acc : 0.6309523809523809\n",
      "epoch : 40, loss : 0.0027682718, tra_acc : 0.6617845117845117\n",
      "epoch : 40, loss : 0.41588712, val_acc : 0.615\n",
      "epoch : 41, loss : 0.025857903, tra_acc : 0.6684175084175085\n",
      "epoch : 41, loss : 0.36640862, val_acc : 0.6104761904761905\n",
      "epoch : 42, loss : 0.04206045, tra_acc : 0.6746127946127946\n",
      "epoch : 42, loss : 0.43115643, val_acc : 0.5904761904761905\n",
      "epoch : 43, loss : 0.07252882, tra_acc : 0.6843434343434344\n",
      "epoch : 43, loss : 0.38655177, val_acc : 0.6138095238095238\n",
      "epoch : 44, loss : 0.08498102, tra_acc : 0.6754208754208755\n",
      "epoch : 44, loss : 0.4570953, val_acc : 0.5907142857142857\n",
      "epoch : 45, loss : 0.07576323, tra_acc : 0.6769696969696969\n",
      "epoch : 45, loss : 0.41730222, val_acc : 0.603095238095238\n",
      "epoch : 46, loss : 0.009132076, tra_acc : 0.6817845117845118\n",
      "epoch : 46, loss : 0.2838507, val_acc : 0.6261904761904763\n",
      "epoch : 47, loss : -0.009608019, tra_acc : 0.6938047138047139\n",
      "epoch : 47, loss : 0.47017774, val_acc : 0.6078571428571429\n",
      "epoch : 48, loss : 0.042629465, tra_acc : 0.6982491582491582\n",
      "epoch : 48, loss : 0.41984606, val_acc : 0.6178571428571429\n",
      "epoch : 49, loss : -0.0077872495, tra_acc : 0.690976430976431\n",
      "epoch : 49, loss : 0.34030318, val_acc : 0.620952380952381\n",
      "epoch : 50, loss : 0.047962725, tra_acc : 0.681043771043771\n",
      "epoch : 50, loss : 0.48377037, val_acc : 0.629047619047619\n",
      "epoch : 51, loss : 0.066531055, tra_acc : 0.699057239057239\n",
      "epoch : 51, loss : 0.52676255, val_acc : 0.6211904761904762\n",
      "epoch : 52, loss : 0.017389128, tra_acc : 0.7078787878787879\n",
      "epoch : 52, loss : 0.42537713, val_acc : 0.6345238095238096\n",
      "epoch : 53, loss : -0.005322513, tra_acc : 0.6824242424242425\n",
      "epoch : 53, loss : 0.48445305, val_acc : 0.6578571428571428\n",
      "epoch : 54, loss : 0.053855993, tra_acc : 0.7235353535353536\n",
      "epoch : 54, loss : 0.49280724, val_acc : 0.6383333333333333\n",
      "epoch : 55, loss : 0.11807055, tra_acc : 0.7148821548821548\n",
      "epoch : 55, loss : 0.37760672, val_acc : 0.6695238095238096\n",
      "epoch : 56, loss : -0.023564495, tra_acc : 0.7124242424242424\n",
      "epoch : 56, loss : 0.5075013, val_acc : 0.6335714285714286\n",
      "epoch : 57, loss : 0.058404937, tra_acc : 0.7227946127946128\n",
      "epoch : 57, loss : 0.42746592, val_acc : 0.6547619047619048\n",
      "epoch : 58, loss : 0.02328496, tra_acc : 0.7209764309764309\n",
      "epoch : 58, loss : 0.41640544, val_acc : 0.6204761904761905\n",
      "epoch : 59, loss : 0.03338964, tra_acc : 0.7346127946127946\n",
      "epoch : 59, loss : 0.6586223, val_acc : 0.6419047619047619\n",
      "epoch : 60, loss : 0.045808252, tra_acc : 0.7167003367003367\n",
      "epoch : 60, loss : 0.45093215, val_acc : 0.6761904761904761\n",
      "epoch : 61, loss : 0.022414882, tra_acc : 0.7435353535353535\n",
      "epoch : 61, loss : 0.46955433, val_acc : 0.6802380952380952\n",
      "epoch : 62, loss : -0.042425778, tra_acc : 0.7143097643097643\n",
      "epoch : 62, loss : 0.3999034, val_acc : 0.6676190476190476\n",
      "epoch : 63, loss : 0.087187804, tra_acc : 0.7410774410774411\n",
      "epoch : 63, loss : 0.4737364, val_acc : 0.7054761904761904\n",
      "epoch : 64, loss : 0.02274161, tra_acc : 0.7470707070707071\n",
      "epoch : 64, loss : 0.59283566, val_acc : 0.6535714285714286\n",
      "epoch : 65, loss : -0.024898263, tra_acc : 0.7426262626262626\n",
      "epoch : 65, loss : 0.21131717, val_acc : 0.6947619047619048\n",
      "epoch : 66, loss : 0.10384753, tra_acc : 0.7256902356902356\n",
      "epoch : 66, loss : 0.382301, val_acc : 0.7166666666666667\n",
      "epoch : 67, loss : 0.02866438, tra_acc : 0.7519865319865319\n",
      "epoch : 67, loss : 0.72145873, val_acc : 0.6557142857142857\n",
      "epoch : 68, loss : -0.030964987, tra_acc : 0.7357912457912459\n",
      "epoch : 68, loss : 0.68022794, val_acc : 0.6680952380952382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 69, loss : 0.08756261, tra_acc : 0.75006734006734\n",
      "epoch : 69, loss : 0.62764615, val_acc : 0.6642857142857143\n",
      "epoch : 70, loss : 0.06347323, tra_acc : 0.7552525252525253\n",
      "epoch : 70, loss : 0.31767252, val_acc : 0.7054761904761904\n",
      "epoch : 71, loss : -0.02178424, tra_acc : 0.7582491582491584\n",
      "epoch : 71, loss : 0.32279533, val_acc : 0.7254761904761905\n",
      "epoch : 72, loss : 0.0026024987, tra_acc : 0.7656228956228955\n",
      "epoch : 72, loss : 0.31505424, val_acc : 0.7347619047619047\n",
      "epoch : 73, loss : 0.035097566, tra_acc : 0.763164983164983\n",
      "epoch : 73, loss : 0.53873384, val_acc : 0.6935714285714285\n",
      "epoch : 74, loss : 0.022917138, tra_acc : 0.7656228956228955\n",
      "epoch : 74, loss : 0.7362716, val_acc : 0.649047619047619\n",
      "epoch : 75, loss : 0.015087899, tra_acc : 0.7657912457912459\n",
      "epoch : 75, loss : 0.44290745, val_acc : 0.7207142857142858\n",
      "epoch : 76, loss : 0.05692806, tra_acc : 0.775892255892256\n",
      "epoch : 76, loss : 0.60673106, val_acc : 0.6549999999999999\n",
      "epoch : 77, loss : 0.019104201, tra_acc : 0.7742424242424243\n",
      "epoch : 77, loss : -0.09550748, val_acc : 0.7261904761904763\n",
      "epoch : 78, loss : -0.09656341, tra_acc : 0.7753535353535355\n",
      "epoch : 78, loss : 0.57935643, val_acc : 0.73\n",
      "epoch : 79, loss : 0.0947504, tra_acc : 0.7746127946127945\n",
      "epoch : 79, loss : 0.52555305, val_acc : 0.73\n",
      "epoch : 80, loss : -0.040356036, tra_acc : 0.7879797979797979\n",
      "epoch : 80, loss : 0.38445577, val_acc : 0.7366666666666667\n",
      "epoch : 81, loss : -0.0073411707, tra_acc : 0.7645117845117845\n",
      "epoch : 81, loss : 0.6058695, val_acc : 0.7466666666666667\n",
      "epoch : 82, loss : 0.082327195, tra_acc : 0.7797979797979798\n",
      "epoch : 82, loss : 0.5570376, val_acc : 0.73\n",
      "epoch : 83, loss : 0.015111462, tra_acc : 0.7858922558922559\n",
      "epoch : 83, loss : -0.30957377, val_acc : 0.7247619047619048\n",
      "epoch : 84, loss : -0.019341007, tra_acc : 0.7697979797979798\n",
      "epoch : 84, loss : 0.15967226, val_acc : 0.777142857142857\n",
      "epoch : 85, loss : -0.0072087944, tra_acc : 0.7801683501683502\n",
      "epoch : 85, loss : -0.014874746, val_acc : 0.7830952380952381\n",
      "epoch : 86, loss : 0.057259306, tra_acc : 0.8031649831649831\n",
      "epoch : 86, loss : 0.13351797, val_acc : 0.7666666666666666\n",
      "epoch : 87, loss : 0.011355508, tra_acc : 0.7848821548821548\n",
      "epoch : 87, loss : 0.16365086, val_acc : 0.7711904761904762\n",
      "epoch : 88, loss : 0.078657545, tra_acc : 0.8028956228956229\n",
      "epoch : 88, loss : -0.7648129, val_acc : 0.6702380952380952\n",
      "epoch : 89, loss : 0.03482873, tra_acc : 0.7777104377104377\n",
      "epoch : 89, loss : 0.16642487, val_acc : 0.7554761904761905\n",
      "epoch : 90, loss : 0.056796227, tra_acc : 0.7690572390572391\n",
      "epoch : 90, loss : 0.6409702, val_acc : 0.7254761904761905\n",
      "epoch : 91, loss : 0.029562874, tra_acc : 0.7971717171717171\n",
      "epoch : 91, loss : 0.5662342, val_acc : 0.728095238095238\n",
      "epoch : 92, loss : -0.013452953, tra_acc : 0.800976430976431\n",
      "epoch : 92, loss : 0.678154, val_acc : 0.7342857142857143\n",
      "epoch : 93, loss : -0.0059463526, tra_acc : 0.8217171717171717\n",
      "epoch : 93, loss : 0.27329078, val_acc : 0.768095238095238\n",
      "epoch : 94, loss : 0.073991485, tra_acc : 0.7952525252525252\n",
      "epoch : 94, loss : 0.5675259, val_acc : 0.7414285714285714\n",
      "epoch : 95, loss : 0.10517362, tra_acc : 0.8044444444444445\n",
      "epoch : 95, loss : 0.22130351, val_acc : 0.765952380952381\n",
      "epoch : 96, loss : -0.12554573, tra_acc : 0.784983164983165\n",
      "epoch : 96, loss : 0.69517154, val_acc : 0.7652380952380953\n",
      "epoch : 97, loss : 0.052491818, tra_acc : 0.8061616161616162\n",
      "epoch : 97, loss : 0.6598411, val_acc : 0.7359523809523809\n",
      "epoch : 98, loss : 0.031799957, tra_acc : 0.7878787878787878\n",
      "epoch : 98, loss : 0.5308187, val_acc : 0.7330952380952381\n",
      "epoch : 99, loss : 0.02655924, tra_acc : 0.8121548821548822\n",
      "epoch : 99, loss : 0.40083992, val_acc : 0.7600000000000001\n",
      "epoch : 100, loss : -0.07277758, tra_acc : 0.8099663299663299\n",
      "epoch : 100, loss : 0.37639928, val_acc : 0.7923809523809524\n",
      "epoch : 101, loss : 0.0040430967, tra_acc : 0.8130639730639732\n",
      "epoch : 101, loss : 0.43941554, val_acc : 0.7938095238095239\n",
      "epoch : 102, loss : 0.04388788, tra_acc : 0.8219865319865319\n",
      "epoch : 102, loss : 0.49087706, val_acc : 0.7745238095238095\n",
      "epoch : 103, loss : 0.11304584, tra_acc : 0.828989898989899\n",
      "epoch : 103, loss : 0.0867275, val_acc : 0.7997619047619048\n",
      "epoch : 104, loss : 0.03326464, tra_acc : 0.8380808080808081\n",
      "epoch : 104, loss : 0.58778507, val_acc : 0.7607142857142857\n",
      "epoch : 105, loss : 0.052978598, tra_acc : 0.8112457912457913\n",
      "epoch : 105, loss : 0.37165818, val_acc : 0.7797619047619048\n",
      "epoch : 106, loss : 0.044672206, tra_acc : 0.8170707070707072\n",
      "epoch : 106, loss : 0.57191116, val_acc : 0.7645238095238095\n",
      "epoch : 107, loss : 0.030383771, tra_acc : 0.8319865319865318\n",
      "epoch : 107, loss : -0.22810487, val_acc : 0.7733333333333333\n",
      "epoch : 108, loss : 0.00589329, tra_acc : 0.7967003367003368\n",
      "epoch : 108, loss : 0.35188624, val_acc : 0.8045238095238094\n",
      "epoch : 109, loss : 0.0828638, tra_acc : 0.8018855218855219\n",
      "epoch : 109, loss : -0.25372407, val_acc : 0.7964285714285714\n",
      "epoch : 110, loss : 0.038326252, tra_acc : 0.8105387205387206\n",
      "epoch : 110, loss : -0.003100805, val_acc : 0.795952380952381\n",
      "epoch : 111, loss : 0.010086107, tra_acc : 0.8080808080808081\n",
      "epoch : 111, loss : 0.54239804, val_acc : 0.7833333333333333\n",
      "epoch : 112, loss : -0.05128068, tra_acc : 0.8358922558922558\n",
      "epoch : 112, loss : 0.15974313, val_acc : 0.7945238095238096\n",
      "epoch : 113, loss : 0.014674821, tra_acc : 0.8432659932659932\n",
      "epoch : 113, loss : 0.20533665, val_acc : 0.8216666666666667\n",
      "epoch : 114, loss : -0.050385788, tra_acc : 0.816060606060606\n",
      "epoch : 114, loss : 0.62846845, val_acc : 0.762142857142857\n",
      "epoch : 115, loss : -0.026414784, tra_acc : 0.8353535353535354\n",
      "epoch : 115, loss : 0.560458, val_acc : 0.7866666666666667\n",
      "epoch : 116, loss : -0.033526022, tra_acc : 0.8216161616161617\n",
      "epoch : 116, loss : 0.48486614, val_acc : 0.7992857142857143\n",
      "epoch : 117, loss : 0.07272962, tra_acc : 0.8155218855218854\n",
      "epoch : 117, loss : 0.5479661, val_acc : 0.7785714285714286\n",
      "epoch : 118, loss : -0.051918987, tra_acc : 0.8471717171717171\n",
      "epoch : 118, loss : 0.67522186, val_acc : 0.7897619047619048\n",
      "epoch : 119, loss : 0.027478622, tra_acc : 0.818888888888889\n",
      "epoch : 119, loss : 0.66890883, val_acc : 0.7823809523809523\n",
      "epoch : 120, loss : 0.138504, tra_acc : 0.8271717171717173\n",
      "epoch : 120, loss : 0.24300225, val_acc : 0.7807142857142857\n",
      "epoch : 121, loss : -0.066068284, tra_acc : 0.8396296296296296\n",
      "epoch : 121, loss : 0.072075285, val_acc : 0.7907142857142858\n",
      "epoch : 122, loss : -0.07714519, tra_acc : 0.8212457912457913\n",
      "epoch : 122, loss : 0.37595615, val_acc : 0.8152380952380952\n",
      "epoch : 123, loss : 0.057640824, tra_acc : 0.8517171717171718\n",
      "epoch : 123, loss : 0.67842317, val_acc : 0.771904761904762\n",
      "epoch : 124, loss : 0.13819307, tra_acc : 0.8352525252525251\n",
      "epoch : 124, loss : 0.20174827, val_acc : 0.7930952380952382\n",
      "epoch : 125, loss : -0.085033394, tra_acc : 0.8328956228956229\n",
      "epoch : 125, loss : -0.34171566, val_acc : 0.8011904761904761\n",
      "epoch : 126, loss : 0.07897284, tra_acc : 0.82006734006734\n",
      "epoch : 126, loss : 1.002242, val_acc : 0.7561904761904762\n",
      "epoch : 127, loss : -0.062467363, tra_acc : 0.830808080808081\n",
      "epoch : 127, loss : 0.29508153, val_acc : 0.8119047619047618\n",
      "epoch : 128, loss : 0.055505004, tra_acc : 0.8338047138047138\n",
      "epoch : 128, loss : 0.03909732, val_acc : 0.8250000000000001\n",
      "epoch : 129, loss : 0.124142125, tra_acc : 0.8222558922558924\n",
      "epoch : 129, loss : 0.20976467, val_acc : 0.7933333333333333\n",
      "epoch : 130, loss : -0.08530927, tra_acc : 0.855993265993266\n",
      "epoch : 130, loss : 0.18640526, val_acc : 0.8097619047619048\n",
      "epoch : 131, loss : -0.10861791, tra_acc : 0.8226936026936027\n",
      "epoch : 131, loss : -0.44640365, val_acc : 0.7840476190476191\n",
      "epoch : 132, loss : -0.031571236, tra_acc : 0.8444444444444446\n",
      "epoch : 132, loss : 0.84184074, val_acc : 0.7983333333333333\n",
      "epoch : 133, loss : 0.20740548, tra_acc : 0.8155218855218855\n",
      "epoch : 133, loss : 0.6569962, val_acc : 0.7745238095238095\n",
      "epoch : 134, loss : -0.09643981, tra_acc : 0.8514478114478113\n",
      "epoch : 134, loss : 0.18727167, val_acc : 0.8014285714285715\n",
      "epoch : 135, loss : 0.14133738, tra_acc : 0.8238047138047139\n",
      "epoch : 135, loss : 0.29451203, val_acc : 0.7847619047619049\n",
      "epoch : 136, loss : 0.011401523, tra_acc : 0.8417171717171716\n",
      "epoch : 136, loss : 0.22124238, val_acc : 0.8026190476190477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 137, loss : -0.05698764, tra_acc : 0.8456228956228955\n",
      "epoch : 137, loss : 0.5991989, val_acc : 0.7785714285714285\n",
      "epoch : 138, loss : -0.081359595, tra_acc : 0.8486195286195286\n",
      "epoch : 138, loss : 0.60158515, val_acc : 0.8116666666666666\n",
      "epoch : 139, loss : 0.1361811, tra_acc : 0.8383501683501682\n",
      "epoch : 139, loss : -0.111544706, val_acc : 0.8059523809523809\n",
      "epoch : 140, loss : 0.063775435, tra_acc : 0.8265319865319865\n",
      "epoch : 140, loss : 0.24329431, val_acc : 0.8004761904761905\n",
      "epoch : 141, loss : -0.078783445, tra_acc : 0.861077441077441\n",
      "epoch : 141, loss : 0.80953884, val_acc : 0.787142857142857\n",
      "epoch : 142, loss : -0.18299872, tra_acc : 0.8247138047138045\n",
      "epoch : 142, loss : 0.47476968, val_acc : 0.8211904761904761\n",
      "epoch : 143, loss : 0.004155156, tra_acc : 0.8458922558922559\n",
      "epoch : 143, loss : 0.42474818, val_acc : 0.8242857142857143\n",
      "epoch : 144, loss : 0.18384886, tra_acc : 0.8130639730639732\n",
      "epoch : 144, loss : 0.35013548, val_acc : 0.7826190476190477\n",
      "epoch : 145, loss : -0.101108074, tra_acc : 0.8425252525252526\n",
      "epoch : 145, loss : 0.5095051, val_acc : 0.8223809523809523\n",
      "epoch : 146, loss : -0.07802593, tra_acc : 0.8409764309764309\n",
      "epoch : 146, loss : 0.47284567, val_acc : 0.8138095238095238\n",
      "epoch : 147, loss : 0.07239936, tra_acc : 0.8587205387205387\n",
      "epoch : 147, loss : 0.7629926, val_acc : 0.7773809523809524\n",
      "epoch : 148, loss : 0.215576, tra_acc : 0.8437037037037036\n",
      "epoch : 148, loss : 0.6847606, val_acc : 0.7992857142857143\n",
      "epoch : 149, loss : 0.021613084, tra_acc : 0.8522558922558923\n",
      "epoch : 149, loss : 0.29089394, val_acc : 0.8123809523809524\n",
      "epoch : 150, loss : -0.0067325938, tra_acc : 0.8408754208754208\n",
      "epoch : 150, loss : 0.40711036, val_acc : 0.8257142857142857\n",
      "epoch : 151, loss : -0.18532729, tra_acc : 0.8587205387205387\n",
      "epoch : 151, loss : 0.56376785, val_acc : 0.8238095238095239\n",
      "epoch : 152, loss : 0.045908824, tra_acc : 0.8461616161616162\n",
      "epoch : 152, loss : 0.33796892, val_acc : 0.8383333333333334\n",
      "epoch : 153, loss : 0.074373245, tra_acc : 0.8757239057239058\n",
      "epoch : 153, loss : -0.0051276437, val_acc : 0.8271428571428571\n",
      "epoch : 154, loss : 0.02606083, tra_acc : 0.874175084175084\n",
      "epoch : 154, loss : 0.09056306, val_acc : 0.8185714285714285\n",
      "epoch : 155, loss : 0.15171771, tra_acc : 0.8408080808080808\n",
      "epoch : 155, loss : 0.77676517, val_acc : 0.7733333333333334\n",
      "epoch : 156, loss : 0.05176932, tra_acc : 0.8558922558922558\n",
      "epoch : 156, loss : 0.12675737, val_acc : 0.8216666666666667\n",
      "epoch : 157, loss : 0.059557524, tra_acc : 0.8568013468013468\n",
      "epoch : 157, loss : -0.025344083, val_acc : 0.8257142857142857\n",
      "epoch : 158, loss : 0.019718647, tra_acc : 0.8845454545454546\n",
      "epoch : 158, loss : 0.17218567, val_acc : 0.8271428571428571\n",
      "epoch : 159, loss : -0.0073724957, tra_acc : 0.8743434343434344\n",
      "epoch : 159, loss : 0.6718753, val_acc : 0.8066666666666666\n",
      "epoch : 160, loss : 0.04261826, tra_acc : 0.8538047138047137\n",
      "epoch : 160, loss : 0.4972341, val_acc : 0.8145238095238095\n",
      "epoch : 161, loss : 0.2909428, tra_acc : 0.8204377104377105\n",
      "epoch : 161, loss : 1.3573756, val_acc : 0.705952380952381\n",
      "epoch : 162, loss : 0.02753144, tra_acc : 0.81989898989899\n",
      "epoch : 162, loss : 0.09463, val_acc : 0.8316666666666667\n",
      "epoch : 163, loss : -0.09602224, tra_acc : 0.8778114478114478\n",
      "epoch : 163, loss : 0.27692154, val_acc : 0.8197619047619048\n",
      "epoch : 164, loss : -0.018967826, tra_acc : 0.8556228956228956\n",
      "epoch : 164, loss : 0.68119067, val_acc : 0.7926190476190476\n",
      "epoch : 165, loss : -0.0052394243, tra_acc : 0.8680808080808081\n",
      "epoch : 165, loss : 0.67473024, val_acc : 0.8145238095238095\n",
      "epoch : 166, loss : 0.08930111, tra_acc : 0.8823569023569025\n",
      "epoch : 166, loss : 0.22915618, val_acc : 0.8099999999999999\n",
      "epoch : 167, loss : 0.04957471, tra_acc : 0.871986531986532\n",
      "epoch : 167, loss : -0.31378838, val_acc : 0.8178571428571427\n",
      "epoch : 168, loss : -0.04379932, tra_acc : 0.854983164983165\n",
      "epoch : 168, loss : 0.8754743, val_acc : 0.7880952380952381\n",
      "epoch : 169, loss : 0.12611185, tra_acc : 0.871986531986532\n",
      "epoch : 169, loss : 0.47197834, val_acc : 0.8238095238095239\n",
      "epoch : 170, loss : 0.026229708, tra_acc : 0.8819865319865319\n",
      "epoch : 170, loss : 0.32348147, val_acc : 0.8066666666666666\n",
      "epoch : 171, loss : -0.102800995, tra_acc : 0.8697979797979799\n",
      "epoch : 171, loss : 1.6333603, val_acc : 0.7309523809523809\n",
      "epoch : 172, loss : 0.3300844, tra_acc : 0.8278114478114478\n",
      "epoch : 172, loss : -0.25922844, val_acc : 0.830952380952381\n",
      "epoch : 173, loss : 0.024545318, tra_acc : 0.8701683501683501\n",
      "epoch : 173, loss : -0.29101437, val_acc : 0.8364285714285714\n",
      "epoch : 174, loss : -0.05840436, tra_acc : 0.885993265993266\n",
      "epoch : 174, loss : -0.36509636, val_acc : 0.829047619047619\n",
      "epoch : 175, loss : 0.23517145, tra_acc : 0.8425252525252526\n",
      "epoch : 175, loss : 0.3527734, val_acc : 0.7614285714285715\n",
      "epoch : 176, loss : -0.08159897, tra_acc : 0.8828956228956227\n",
      "epoch : 176, loss : -0.03994471, val_acc : 0.8283333333333333\n",
      "epoch : 177, loss : -0.21771474, tra_acc : 0.8583501683501684\n",
      "epoch : 177, loss : 0.91948, val_acc : 0.7792857142857144\n",
      "epoch : 178, loss : 0.21879907, tra_acc : 0.8670707070707071\n",
      "epoch : 178, loss : -0.60825515, val_acc : 0.8197619047619048\n",
      "epoch : 179, loss : -0.10034669, tra_acc : 0.8826262626262625\n",
      "epoch : 179, loss : 0.079340756, val_acc : 0.8497619047619048\n",
      "epoch : 180, loss : 0.11766918, tra_acc : 0.875993265993266\n",
      "epoch : 180, loss : 0.62849826, val_acc : 0.7966666666666667\n",
      "epoch : 181, loss : 0.11913955, tra_acc : 0.8268013468013469\n",
      "epoch : 181, loss : 0.71424264, val_acc : 0.8190476190476191\n",
      "epoch : 182, loss : 0.026628511, tra_acc : 0.8780808080808081\n",
      "epoch : 182, loss : 0.20037806, val_acc : 0.8278571428571428\n",
      "epoch : 183, loss : -0.2511356, tra_acc : 0.8335353535353535\n",
      "epoch : 183, loss : 0.6185139, val_acc : 0.849047619047619\n",
      "epoch : 184, loss : 0.01609043, tra_acc : 0.8838047138047137\n",
      "epoch : 184, loss : 0.8476715, val_acc : 0.8230952380952381\n",
      "epoch : 185, loss : 0.060882807, tra_acc : 0.8780808080808082\n",
      "epoch : 185, loss : 0.8899279, val_acc : 0.7952380952380952\n",
      "epoch : 186, loss : 0.19704838, tra_acc : 0.8875420875420876\n",
      "epoch : 186, loss : 0.20589535, val_acc : 0.833095238095238\n",
      "epoch : 187, loss : -0.036179967, tra_acc : 0.8908080808080808\n",
      "epoch : 187, loss : 1.2289046, val_acc : 0.8111904761904762\n",
      "epoch : 188, loss : 0.09895544, tra_acc : 0.8856228956228956\n",
      "epoch : 188, loss : -0.6115069, val_acc : 0.8178571428571427\n",
      "epoch : 189, loss : -0.014257982, tra_acc : 0.8914478114478115\n",
      "epoch : 189, loss : -0.29446003, val_acc : 0.8371428571428572\n",
      "epoch : 190, loss : -0.33930704, tra_acc : 0.8765319865319866\n",
      "epoch : 190, loss : 0.49872336, val_acc : 0.8345238095238096\n",
      "epoch : 191, loss : 0.15347123, tra_acc : 0.881077441077441\n",
      "epoch : 191, loss : 1.0119287, val_acc : 0.8071428571428573\n",
      "epoch : 192, loss : -0.019770043, tra_acc : 0.8990909090909092\n",
      "epoch : 192, loss : -1.1997881, val_acc : 0.768095238095238\n",
      "epoch : 193, loss : 0.17215237, tra_acc : 0.8694276094276095\n",
      "epoch : 193, loss : 1.1907272, val_acc : 0.829047619047619\n",
      "epoch : 194, loss : 0.11757901, tra_acc : 0.8723569023569021\n",
      "epoch : 194, loss : -0.015300061, val_acc : 0.833095238095238\n",
      "epoch : 195, loss : 0.014387042, tra_acc : 0.8959932659932659\n",
      "epoch : 195, loss : 0.8452949, val_acc : 0.8059523809523809\n",
      "epoch : 196, loss : 0.03600712, tra_acc : 0.8826262626262626\n",
      "epoch : 196, loss : 0.37409195, val_acc : 0.8304761904761904\n",
      "epoch : 197, loss : -0.044263266, tra_acc : 0.8795286195286195\n",
      "epoch : 197, loss : 0.13098323, val_acc : 0.8542857142857142\n",
      "epoch : 198, loss : 0.005718578, tra_acc : 0.9029966329966331\n",
      "epoch : 198, loss : 0.7122753, val_acc : 0.8107142857142856\n",
      "epoch : 199, loss : 0.23735133, tra_acc : 0.8654545454545456\n",
      "epoch : 199, loss : -0.13042758, val_acc : 0.8338095238095239\n",
      "epoch : 200, loss : -0.062229134, tra_acc : 0.9066329966329967\n",
      "epoch : 200, loss : 0.19936092, val_acc : 0.835\n",
      "epoch : 201, loss : 0.06489887, tra_acc : 0.885993265993266\n",
      "epoch : 201, loss : 0.83418226, val_acc : 0.8257142857142857\n",
      "epoch : 202, loss : -0.0034366234, tra_acc : 0.9011784511784512\n",
      "epoch : 202, loss : -0.03986483, val_acc : 0.8319047619047618\n",
      "epoch : 203, loss : 0.007934678, tra_acc : 0.8889898989898991\n",
      "epoch : 203, loss : 0.53854597, val_acc : 0.8278571428571428\n",
      "epoch : 204, loss : 0.06640777, tra_acc : 0.88989898989899\n",
      "epoch : 204, loss : -0.3192978, val_acc : 0.8483333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 205, loss : 0.038754188, tra_acc : 0.8892592592592592\n",
      "epoch : 205, loss : 1.449732, val_acc : 0.8104761904761905\n",
      "epoch : 206, loss : 0.04967328, tra_acc : 0.8838047138047138\n",
      "epoch : 206, loss : 2.2613134, val_acc : 0.7466666666666667\n",
      "epoch : 207, loss : 0.25759804, tra_acc : 0.8753535353535354\n",
      "epoch : 207, loss : -0.31673375, val_acc : 0.8385714285714285\n",
      "epoch : 208, loss : 0.058992602, tra_acc : 0.8887205387205387\n",
      "epoch : 208, loss : -0.05188327, val_acc : 0.8476190476190476\n",
      "epoch : 209, loss : -0.07186897, tra_acc : 0.8895286195286196\n",
      "epoch : 209, loss : 0.334837, val_acc : 0.8304761904761904\n",
      "epoch : 210, loss : -0.050565198, tra_acc : 0.9032659932659932\n",
      "epoch : 210, loss : -0.023591796, val_acc : 0.8564285714285714\n",
      "epoch : 211, loss : -0.1552613, tra_acc : 0.8943434343434343\n",
      "epoch : 211, loss : -0.40450802, val_acc : 0.815952380952381\n",
      "epoch : 212, loss : 0.034336373, tra_acc : 0.8662626262626264\n",
      "epoch : 212, loss : 0.7942701, val_acc : 0.8304761904761904\n",
      "epoch : 213, loss : 0.14523064, tra_acc : 0.8944444444444444\n",
      "epoch : 213, loss : -0.021225909, val_acc : 0.8476190476190476\n",
      "epoch : 214, loss : -0.026881592, tra_acc : 0.9102693602693602\n",
      "epoch : 214, loss : -0.002664653, val_acc : 0.8450000000000001\n",
      "epoch : 215, loss : 0.4701288, tra_acc : 0.8294276094276095\n",
      "epoch : 215, loss : 0.9775551, val_acc : 0.7852380952380952\n",
      "epoch : 216, loss : 0.3625348, tra_acc : 0.7856228956228957\n",
      "epoch : 216, loss : 0.43956542, val_acc : 0.787142857142857\n",
      "epoch : 217, loss : -0.20226502, tra_acc : 0.8666329966329968\n",
      "epoch : 217, loss : -0.6164318, val_acc : 0.862857142857143\n",
      "epoch : 218, loss : -0.11821435, tra_acc : 0.8935353535353537\n",
      "epoch : 218, loss : -0.104284324, val_acc : 0.8326190476190476\n",
      "epoch : 219, loss : -0.018194728, tra_acc : 0.9105387205387205\n",
      "epoch : 219, loss : -0.0055957236, val_acc : 0.853095238095238\n",
      "epoch : 220, loss : 0.020060625, tra_acc : 0.9050841750841752\n",
      "epoch : 220, loss : -0.3573599, val_acc : 0.8483333333333333\n",
      "epoch : 221, loss : -0.016010415, tra_acc : 0.8952525252525255\n",
      "epoch : 221, loss : -2.4121668, val_acc : 0.7752380952380952\n",
      "epoch : 222, loss : -0.09843846, tra_acc : 0.8701683501683501\n",
      "epoch : 222, loss : 0.12983096, val_acc : 0.8411904761904762\n",
      "epoch : 223, loss : 0.019763578, tra_acc : 0.8977104377104378\n",
      "epoch : 223, loss : -0.3127769, val_acc : 0.8502380952380952\n",
      "epoch : 224, loss : 0.08381354, tra_acc : 0.8969023569023569\n",
      "epoch : 224, loss : 0.038458686, val_acc : 0.8364285714285714\n",
      "epoch : 225, loss : 0.06912673, tra_acc : 0.9053535353535355\n",
      "epoch : 225, loss : 1.5995497, val_acc : 0.7992857142857143\n",
      "epoch : 226, loss : -0.021277282, tra_acc : 0.8874410774410774\n",
      "epoch : 226, loss : 0.45416152, val_acc : 0.8278571428571428\n",
      "epoch : 227, loss : 0.15663671, tra_acc : 0.8934343434343436\n",
      "epoch : 227, loss : 0.5010945, val_acc : 0.8338095238095238\n",
      "epoch : 228, loss : 0.07536733, tra_acc : 0.9078114478114478\n",
      "epoch : 228, loss : 0.5963983, val_acc : 0.835\n",
      "epoch : 229, loss : -0.07185925, tra_acc : 0.8826262626262626\n",
      "epoch : 229, loss : 0.4490962, val_acc : 0.8345238095238096\n",
      "epoch : 230, loss : -0.0044403854, tra_acc : 0.8796296296296297\n",
      "epoch : 230, loss : 0.77763146, val_acc : 0.8271428571428571\n",
      "epoch : 231, loss : -0.0032831267, tra_acc : 0.8944444444444446\n",
      "epoch : 231, loss : -1.0414131, val_acc : 0.7930952380952382\n",
      "epoch : 232, loss : -0.12330537, tra_acc : 0.8507070707070707\n",
      "epoch : 232, loss : 0.31554815, val_acc : 0.75\n",
      "epoch : 233, loss : 0.13115191, tra_acc : 0.8553535353535353\n",
      "epoch : 233, loss : 0.5419851, val_acc : 0.853095238095238\n",
      "epoch : 234, loss : 0.2593067, tra_acc : 0.8805387205387205\n",
      "epoch : 234, loss : -0.017858112, val_acc : 0.855\n",
      "epoch : 235, loss : 0.0719262, tra_acc : 0.8843434343434343\n",
      "epoch : 235, loss : 0.96186066, val_acc : 0.8126190476190476\n",
      "epoch : 236, loss : 0.35911903, tra_acc : 0.8417171717171719\n",
      "epoch : 236, loss : -0.330112, val_acc : 0.8285714285714286\n",
      "epoch : 237, loss : 0.0106342, tra_acc : 0.8980808080808079\n",
      "epoch : 237, loss : 1.0287884, val_acc : 0.7880952380952381\n",
      "epoch : 238, loss : 0.096158095, tra_acc : 0.9062626262626261\n",
      "epoch : 238, loss : 0.1391461, val_acc : 0.8397619047619047\n",
      "epoch : 239, loss : 0.099203534, tra_acc : 0.8910774410774411\n",
      "epoch : 239, loss : -0.34363505, val_acc : 0.8430952380952381\n",
      "epoch : 240, loss : -0.05336767, tra_acc : 0.9056228956228957\n",
      "epoch : 240, loss : -0.6452283, val_acc : 0.8119047619047618\n",
      "epoch : 241, loss : 0.07642052, tra_acc : 0.9059932659932659\n",
      "epoch : 241, loss : 0.7298501, val_acc : 0.829047619047619\n",
      "epoch : 242, loss : -0.006763534, tra_acc : 0.9017171717171717\n",
      "epoch : 242, loss : 0.3624402, val_acc : 0.8421428571428571\n",
      "epoch : 243, loss : -0.16977733, tra_acc : 0.9002693602693603\n",
      "epoch : 243, loss : 1.2656507, val_acc : 0.8238095238095239\n",
      "epoch : 244, loss : 0.16815372, tra_acc : 0.8869023569023569\n",
      "epoch : 244, loss : 1.0687143, val_acc : 0.8145238095238095\n",
      "epoch : 245, loss : 0.088819236, tra_acc : 0.9023569023569024\n",
      "epoch : 245, loss : 0.68589973, val_acc : 0.8271428571428571\n",
      "epoch : 246, loss : -0.1266861, tra_acc : 0.897979797979798\n",
      "epoch : 246, loss : -0.5345029, val_acc : 0.8304761904761904\n",
      "epoch : 247, loss : 0.108230494, tra_acc : 0.8987205387205388\n",
      "epoch : 247, loss : 0.30415764, val_acc : 0.8371428571428572\n",
      "epoch : 248, loss : 0.029797578, tra_acc : 0.9117171717171718\n",
      "epoch : 248, loss : 1.1571765, val_acc : 0.8071428571428573\n",
      "epoch : 249, loss : 0.042210642, tra_acc : 0.8944444444444444\n",
      "epoch : 249, loss : 0.010346775, val_acc : 0.8557142857142858\n",
      "epoch : 250, loss : 0.1934573, tra_acc : 0.9205387205387204\n",
      "epoch : 250, loss : 0.092482306, val_acc : 0.8516666666666667\n",
      "epoch : 251, loss : -0.024780752, tra_acc : 0.910808080808081\n",
      "epoch : 251, loss : 0.46810567, val_acc : 0.8178571428571427\n",
      "epoch : 252, loss : 0.057541665, tra_acc : 0.9126262626262626\n",
      "epoch : 252, loss : 0.20542587, val_acc : 0.8397619047619047\n",
      "epoch : 253, loss : 0.25359732, tra_acc : 0.8835353535353536\n",
      "epoch : 253, loss : 0.80134505, val_acc : 0.8211904761904761\n",
      "epoch : 254, loss : 0.32554153, tra_acc : 0.8639057239057241\n",
      "epoch : 254, loss : -0.29339698, val_acc : 0.7880952380952381\n",
      "epoch : 255, loss : 0.047246184, tra_acc : 0.9035353535353536\n",
      "epoch : 255, loss : 0.47071943, val_acc : 0.8571428571428571\n",
      "epoch : 256, loss : 0.11663031, tra_acc : 0.8978114478114477\n",
      "epoch : 256, loss : -1.3820529, val_acc : 0.8130952380952382\n",
      "epoch : 257, loss : -0.09684556, tra_acc : 0.9211784511784512\n",
      "epoch : 257, loss : 0.6371744, val_acc : 0.8469047619047618\n",
      "epoch : 258, loss : 0.039200507, tra_acc : 0.9214478114478113\n",
      "epoch : 258, loss : -0.75848436, val_acc : 0.8316666666666667\n",
      "epoch : 259, loss : 0.122264005, tra_acc : 0.9166329966329968\n",
      "epoch : 259, loss : 0.12218448, val_acc : 0.8338095238095239\n",
      "epoch : 260, loss : -0.0030564016, tra_acc : 0.9250841750841751\n",
      "epoch : 260, loss : -0.7583003, val_acc : 0.829047619047619\n",
      "epoch : 261, loss : -0.06869237, tra_acc : 0.915993265993266\n",
      "epoch : 261, loss : 0.662116, val_acc : 0.8416666666666667\n",
      "epoch : 262, loss : 0.08887295, tra_acc : 0.9248148148148148\n",
      "epoch : 262, loss : 0.27342305, val_acc : 0.8397619047619047\n",
      "epoch : 263, loss : 0.103144914, tra_acc : 0.9196296296296296\n",
      "epoch : 263, loss : 2.1643684, val_acc : 0.7792857142857144\n",
      "epoch : 264, loss : 0.101511076, tra_acc : 0.9\n",
      "epoch : 264, loss : -0.02345713, val_acc : 0.8535714285714285\n",
      "epoch : 265, loss : 0.10477412, tra_acc : 0.9104377104377104\n",
      "epoch : 265, loss : 0.15482242, val_acc : 0.8497619047619048\n",
      "epoch : 266, loss : 0.07072146, tra_acc : 0.9166329966329966\n",
      "epoch : 266, loss : 0.27129057, val_acc : 0.8504761904761905\n",
      "epoch : 267, loss : -0.019505924, tra_acc : 0.9250841750841751\n",
      "epoch : 267, loss : 0.72731453, val_acc : 0.8319047619047618\n",
      "epoch : 268, loss : -0.048732482, tra_acc : 0.9245454545454543\n",
      "epoch : 268, loss : -0.18318705, val_acc : 0.8390476190476189\n",
      "epoch : 269, loss : 0.14155339, tra_acc : 0.8980808080808079\n",
      "epoch : 269, loss : -3.236737, val_acc : 0.7933333333333333\n",
      "epoch : 270, loss : 0.13716334, tra_acc : 0.8926262626262628\n",
      "epoch : 270, loss : -0.3888993, val_acc : 0.8345238095238096\n",
      "epoch : 271, loss : 0.044912007, tra_acc : 0.9184511784511784\n",
      "epoch : 271, loss : -0.526984, val_acc : 0.8376190476190476\n",
      "epoch : 272, loss : 0.1483902, tra_acc : 0.9026262626262626\n",
      "epoch : 272, loss : 0.2492157, val_acc : 0.859047619047619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 273, loss : 0.073414415, tra_acc : 0.9162626262626262\n",
      "epoch : 273, loss : -0.036461134, val_acc : 0.849047619047619\n",
      "epoch : 274, loss : 0.040009547, tra_acc : 0.9120875420875424\n",
      "epoch : 274, loss : -0.110415995, val_acc : 0.8423809523809523\n",
      "epoch : 275, loss : 0.0027586399, tra_acc : 0.9144444444444445\n",
      "epoch : 275, loss : -0.63844615, val_acc : 0.8204761904761906\n",
      "epoch : 276, loss : -0.008051076, tra_acc : 0.9175420875420875\n",
      "epoch : 276, loss : 0.8194508, val_acc : 0.8238095238095239\n",
      "epoch : 277, loss : 0.031651877, tra_acc : 0.9159932659932661\n",
      "epoch : 277, loss : 0.6902208, val_acc : 0.8304761904761904\n",
      "epoch : 278, loss : 0.039938867, tra_acc : 0.9190909090909092\n",
      "epoch : 278, loss : -0.13558741, val_acc : 0.8390476190476192\n",
      "epoch : 279, loss : 0.087139994, tra_acc : 0.9305387205387206\n",
      "epoch : 279, loss : -0.69809777, val_acc : 0.8338095238095238\n",
      "epoch : 280, loss : 0.057096288, tra_acc : 0.9235353535353535\n",
      "epoch : 280, loss : 0.15194787, val_acc : 0.8483333333333333\n",
      "epoch : 281, loss : 0.07279174, tra_acc : 0.9309090909090909\n",
      "epoch : 281, loss : -0.17835867, val_acc : 0.8445238095238095\n",
      "epoch : 282, loss : 0.09798364, tra_acc : 0.9232659932659932\n",
      "epoch : 282, loss : 0.7723892, val_acc : 0.8238095238095239\n",
      "epoch : 283, loss : 0.10813201, tra_acc : 0.9344444444444445\n",
      "epoch : 283, loss : -0.1928137, val_acc : 0.8457142857142856\n",
      "epoch : 284, loss : -0.05174687, tra_acc : 0.922996632996633\n",
      "epoch : 284, loss : 0.9503382, val_acc : 0.8226190476190477\n",
      "epoch : 285, loss : 0.22953488, tra_acc : 0.9244444444444444\n",
      "epoch : 285, loss : 0.5213925, val_acc : 0.8311904761904761\n",
      "epoch : 286, loss : 0.035647977, tra_acc : 0.9025252525252526\n",
      "epoch : 286, loss : -0.61742896, val_acc : 0.8702380952380953\n",
      "epoch : 287, loss : 0.00081376056, tra_acc : 0.9284511784511785\n",
      "epoch : 287, loss : 0.08225221, val_acc : 0.8419047619047619\n",
      "epoch : 288, loss : 0.015451139, tra_acc : 0.935084175084175\n",
      "epoch : 288, loss : -0.7728388, val_acc : 0.8211904761904764\n",
      "epoch : 289, loss : -0.00066047366, tra_acc : 0.9366329966329967\n",
      "epoch : 289, loss : -0.15510559, val_acc : 0.8523809523809524\n",
      "epoch : 290, loss : -0.23918733, tra_acc : 0.9265319865319864\n",
      "epoch : 290, loss : -1.7514919, val_acc : 0.795952380952381\n",
      "epoch : 291, loss : -0.62836707, tra_acc : 0.9036026936026935\n",
      "epoch : 291, loss : -2.1634226, val_acc : 0.666904761904762\n",
      "epoch : 292, loss : 0.1454681, tra_acc : 0.8974410774410775\n",
      "epoch : 292, loss : 1.0041553, val_acc : 0.736904761904762\n",
      "epoch : 293, loss : 0.3054234, tra_acc : 0.9029966329966331\n",
      "epoch : 293, loss : -0.06401984, val_acc : 0.8152380952380952\n",
      "epoch : 294, loss : 0.46980238, tra_acc : 0.8589898989898991\n",
      "epoch : 294, loss : 0.8656047, val_acc : 0.8166666666666668\n",
      "epoch : 295, loss : 0.032576684, tra_acc : 0.9122558922558923\n",
      "epoch : 295, loss : 1.3574638, val_acc : 0.8178571428571427\n",
      "epoch : 296, loss : 0.07286333, tra_acc : 0.9287205387205387\n",
      "epoch : 296, loss : -0.048435617, val_acc : 0.855\n",
      "epoch : 297, loss : -0.050669312, tra_acc : 0.9396296296296296\n",
      "epoch : 297, loss : -0.19185843, val_acc : 0.8452380952380952\n",
      "epoch : 298, loss : -0.029115217, tra_acc : 0.9335353535353537\n",
      "epoch : 298, loss : -0.40183005, val_acc : 0.8164285714285714\n",
      "epoch : 299, loss : 0.077984445, tra_acc : 0.9402693602693604\n",
      "epoch : 299, loss : -0.7010053, val_acc : 0.8211904761904764\n",
      "epoch : 300, loss : -0.0008016852, tra_acc : 0.9298989898989899\n",
      "epoch : 300, loss : 0.47613457, val_acc : 0.8528571428571429\n",
      "epoch : 301, loss : 0.12351188, tra_acc : 0.9305387205387206\n",
      "epoch : 301, loss : -1.2383438, val_acc : 0.8133333333333334\n",
      "epoch : 302, loss : 0.06836392, tra_acc : 0.9329966329966329\n",
      "epoch : 302, loss : 0.99511003, val_acc : 0.8271428571428571\n",
      "epoch : 303, loss : 0.07386701, tra_acc : 0.9378114478114479\n",
      "epoch : 303, loss : -1.1620909, val_acc : 0.815952380952381\n",
      "epoch : 304, loss : -0.11699762, tra_acc : 0.9339057239057239\n",
      "epoch : 304, loss : 0.36505973, val_acc : 0.8483333333333333\n",
      "epoch : 305, loss : -0.114775345, tra_acc : 0.9220875420875422\n",
      "epoch : 305, loss : 0.17038696, val_acc : 0.8245238095238095\n",
      "epoch : 306, loss : 0.16917807, tra_acc : 0.9320875420875421\n",
      "epoch : 306, loss : -0.1426441, val_acc : 0.8542857142857142\n",
      "epoch : 307, loss : 0.1861429, tra_acc : 0.9141750841750842\n",
      "epoch : 307, loss : 1.1055076, val_acc : 0.8173809523809523\n",
      "epoch : 308, loss : 0.033069134, tra_acc : 0.9348148148148149\n",
      "epoch : 308, loss : -0.99321055, val_acc : 0.814047619047619\n",
      "epoch : 309, loss : 0.03778611, tra_acc : 0.944814814814815\n",
      "epoch : 309, loss : -1.2122235, val_acc : 0.8192857142857143\n",
      "epoch : 310, loss : -0.053016543, tra_acc : 0.9493602693602693\n",
      "epoch : 310, loss : -0.67628074, val_acc : 0.8330952380952382\n",
      "epoch : 311, loss : -0.019699693, tra_acc : 0.9371717171717173\n",
      "epoch : 311, loss : -0.6090378, val_acc : 0.8390476190476189\n",
      "epoch : 312, loss : -0.00024825876, tra_acc : 0.9405387205387205\n",
      "epoch : 312, loss : -1.5917467, val_acc : 0.8316666666666667\n",
      "epoch : 313, loss : -0.096073814, tra_acc : 0.9466329966329966\n",
      "epoch : 313, loss : -0.89156723, val_acc : 0.8185714285714285\n",
      "epoch : 314, loss : -0.0029933236, tra_acc : 0.9335353535353537\n",
      "epoch : 314, loss : 2.1325436, val_acc : 0.8004761904761905\n",
      "epoch : 315, loss : 0.30885988, tra_acc : 0.9269023569023568\n",
      "epoch : 315, loss : -1.0196401, val_acc : 0.833095238095238\n",
      "epoch : 316, loss : 0.07197622, tra_acc : 0.922996632996633\n",
      "epoch : 316, loss : -0.75700504, val_acc : 0.833095238095238\n",
      "epoch : 317, loss : -0.040841557, tra_acc : 0.9405387205387205\n",
      "epoch : 317, loss : -0.7272847, val_acc : 0.8311904761904761\n",
      "epoch : 318, loss : 0.06598134, tra_acc : 0.942996632996633\n",
      "epoch : 318, loss : -1.2263812, val_acc : 0.8230952380952381\n",
      "epoch : 319, loss : 0.054086268, tra_acc : 0.9450841750841751\n",
      "epoch : 319, loss : -1.1381978, val_acc : 0.8323809523809523\n",
      "epoch : 320, loss : -0.04028213, tra_acc : 0.9481818181818181\n",
      "epoch : 320, loss : -0.2855303, val_acc : 0.8338095238095238\n",
      "epoch : 321, loss : 0.08221821, tra_acc : 0.9493602693602693\n",
      "epoch : 321, loss : -0.8389387, val_acc : 0.8397619047619047\n",
      "epoch : 322, loss : -0.0694607, tra_acc : 0.9441750841750842\n",
      "epoch : 322, loss : -1.2425019, val_acc : 0.8211904761904764\n",
      "epoch : 323, loss : 0.08337311, tra_acc : 0.9429966329966329\n",
      "epoch : 323, loss : -1.0316356, val_acc : 0.8226190476190477\n",
      "epoch : 324, loss : -0.02659518, tra_acc : 0.9502693602693605\n",
      "epoch : 324, loss : -1.1053702, val_acc : 0.829047619047619\n",
      "epoch : 325, loss : -0.11739629, tra_acc : 0.9453535353535352\n",
      "epoch : 325, loss : -0.9075673, val_acc : 0.8278571428571428\n",
      "epoch : 326, loss : 0.022308426, tra_acc : 0.9527272727272726\n",
      "epoch : 326, loss : -0.8964613, val_acc : 0.8219047619047619\n",
      "epoch : 327, loss : 0.014505524, tra_acc : 0.9478114478114478\n",
      "epoch : 327, loss : -1.3214309, val_acc : 0.8185714285714285\n",
      "epoch : 328, loss : -0.13532, tra_acc : 0.942895622895623\n",
      "epoch : 328, loss : -1.6603504, val_acc : 0.8185714285714285\n",
      "epoch : 329, loss : -0.035571042, tra_acc : 0.9404377104377104\n",
      "epoch : 329, loss : -0.70902205, val_acc : 0.8226190476190477\n",
      "epoch : 330, loss : -0.030625701, tra_acc : 0.9502693602693602\n",
      "epoch : 330, loss : -1.6672577, val_acc : 0.8238095238095239\n",
      "epoch : 331, loss : -0.0415017, tra_acc : 0.9527272727272728\n",
      "epoch : 331, loss : -0.80133194, val_acc : 0.835\n",
      "epoch : 332, loss : 0.06470811, tra_acc : 0.9527272727272726\n",
      "epoch : 332, loss : -1.4635931, val_acc : 0.8271428571428571\n",
      "epoch : 333, loss : -0.019268679, tra_acc : 0.9511784511784511\n",
      "epoch : 333, loss : -1.0767275, val_acc : 0.8442857142857143\n",
      "epoch : 334, loss : -0.13456449, tra_acc : 0.9453535353535354\n",
      "epoch : 334, loss : -1.0031314, val_acc : 0.8245238095238095\n",
      "epoch : 335, loss : 0.061103906, tra_acc : 0.945993265993266\n",
      "epoch : 335, loss : -0.68099946, val_acc : 0.8323809523809524\n",
      "epoch : 336, loss : 0.20088328, tra_acc : 0.9453535353535354\n",
      "epoch : 336, loss : -1.2804878, val_acc : 0.8271428571428571\n",
      "epoch : 337, loss : 0.098012276, tra_acc : 0.9478114478114478\n",
      "epoch : 337, loss : -1.1136454, val_acc : 0.8357142857142857\n",
      "epoch : 338, loss : -0.008440629, tra_acc : 0.9518181818181819\n",
      "epoch : 338, loss : -1.1563177, val_acc : 0.8342857142857142\n",
      "epoch : 339, loss : 0.050511345, tra_acc : 0.9536363636363635\n",
      "epoch : 339, loss : -0.87096596, val_acc : 0.8383333333333334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 340, loss : 0.046802424, tra_acc : 0.9511784511784512\n",
      "epoch : 340, loss : -1.5409797, val_acc : 0.8192857142857143\n",
      "epoch : 341, loss : 0.078923315, tra_acc : 0.9511784511784511\n",
      "epoch : 341, loss : -0.7944905, val_acc : 0.8357142857142857\n",
      "epoch : 342, loss : 0.024547268, tra_acc : 0.9487205387205386\n",
      "epoch : 342, loss : -0.87200373, val_acc : 0.8383333333333333\n",
      "epoch : 343, loss : -0.05895592, tra_acc : 0.9511784511784511\n",
      "epoch : 343, loss : -1.3074065, val_acc : 0.8304761904761904\n",
      "epoch : 344, loss : 0.124599345, tra_acc : 0.9438047138047139\n",
      "epoch : 344, loss : -1.161167, val_acc : 0.8245238095238095\n",
      "epoch : 345, loss : 0.0075810407, tra_acc : 0.9511784511784512\n",
      "epoch : 345, loss : -1.4099112, val_acc : 0.8245238095238095\n",
      "epoch : 346, loss : 0.043703564, tra_acc : 0.9536363636363635\n",
      "epoch : 346, loss : -1.2049061, val_acc : 0.8316666666666667\n",
      "epoch : 347, loss : 0.08250969, tra_acc : 0.9511784511784512\n",
      "epoch : 347, loss : -0.93667036, val_acc : 0.8219047619047619\n",
      "epoch : 348, loss : 0.05599551, tra_acc : 0.9511784511784512\n",
      "epoch : 348, loss : -1.3687037, val_acc : 0.8271428571428571\n",
      "epoch : 349, loss : -0.00288273, tra_acc : 0.9536363636363635\n",
      "epoch : 349, loss : -0.9268055, val_acc : 0.8435714285714285\n",
      "epoch : 350, loss : -0.010904952, tra_acc : 0.9487205387205386\n",
      "epoch : 350, loss : -0.94931406, val_acc : 0.8461904761904763\n",
      "epoch : 351, loss : 0.05418968, tra_acc : 0.9511784511784512\n",
      "epoch : 351, loss : -1.3203529, val_acc : 0.8211904761904764\n",
      "epoch : 352, loss : -0.105336666, tra_acc : 0.9487205387205386\n",
      "epoch : 352, loss : -0.50705355, val_acc : 0.833095238095238\n",
      "epoch : 353, loss : -0.031676196, tra_acc : 0.9511784511784512\n",
      "epoch : 353, loss : -1.0051271, val_acc : 0.833095238095238\n",
      "epoch : 354, loss : -0.016425006, tra_acc : 0.9487205387205389\n",
      "epoch : 354, loss : -1.0855292, val_acc : 0.8383333333333333\n",
      "epoch : 355, loss : 0.09588861, tra_acc : 0.9511784511784511\n",
      "epoch : 355, loss : -1.2297336, val_acc : 0.8178571428571427\n",
      "epoch : 356, loss : 0.025513725, tra_acc : 0.9435353535353534\n",
      "epoch : 356, loss : -0.45859814, val_acc : 0.8435714285714285\n",
      "epoch : 357, loss : 0.067236304, tra_acc : 0.9527272727272726\n",
      "epoch : 357, loss : -0.66849333, val_acc : 0.8435714285714285\n",
      "epoch : 358, loss : 0.036696915, tra_acc : 0.9487205387205385\n",
      "epoch : 358, loss : -1.0446624, val_acc : 0.8323809523809524\n",
      "epoch : 359, loss : 0.042159695, tra_acc : 0.9511784511784512\n",
      "epoch : 359, loss : -0.9763878, val_acc : 0.815952380952381\n",
      "epoch : 360, loss : -0.03372743, tra_acc : 0.9462626262626265\n",
      "epoch : 360, loss : -1.2819725, val_acc : 0.829047619047619\n",
      "epoch : 361, loss : -0.021096967, tra_acc : 0.9487205387205385\n",
      "epoch : 361, loss : -1.2806934, val_acc : 0.8152380952380952\n",
      "epoch : 362, loss : 0.08636914, tra_acc : 0.9487205387205386\n",
      "epoch : 362, loss : 0.64062303, val_acc : 0.8342857142857142\n",
      "epoch : 363, loss : 0.153642, tra_acc : 0.9166329966329966\n",
      "epoch : 363, loss : -0.6453069, val_acc : 0.8476190476190476\n",
      "epoch : 364, loss : -0.089364775, tra_acc : 0.9396296296296296\n",
      "epoch : 364, loss : 0.23807998, val_acc : 0.8352380952380952\n",
      "epoch : 365, loss : 0.2270239, tra_acc : 0.9253535353535353\n",
      "epoch : 365, loss : 1.3839959, val_acc : 0.8230952380952381\n",
      "epoch : 366, loss : 0.052438997, tra_acc : 0.9478114478114478\n",
      "epoch : 366, loss : -0.4132985, val_acc : 0.815952380952381\n",
      "epoch : 367, loss : 0.026084103, tra_acc : 0.9496296296296296\n",
      "epoch : 367, loss : -0.39084235, val_acc : 0.8338095238095239\n",
      "epoch : 368, loss : 0.19017579, tra_acc : 0.9487205387205386\n",
      "epoch : 368, loss : -0.9273577, val_acc : 0.8271428571428571\n",
      "epoch : 369, loss : 0.20837216, tra_acc : 0.9448148148148149\n",
      "epoch : 369, loss : -1.645161, val_acc : 0.815952380952381\n",
      "epoch : 370, loss : 0.09913386, tra_acc : 0.9520875420875423\n",
      "epoch : 370, loss : -1.1397513, val_acc : 0.8264285714285715\n",
      "epoch : 371, loss : 0.0026853273, tra_acc : 0.9511784511784512\n",
      "epoch : 371, loss : -2.5103235, val_acc : 0.7933333333333333\n",
      "epoch : 372, loss : 0.06811685, tra_acc : 0.9484511784511785\n",
      "epoch : 372, loss : -0.92163295, val_acc : 0.829047619047619\n",
      "epoch : 373, loss : -0.09165228, tra_acc : 0.9471717171717171\n",
      "epoch : 373, loss : -0.9943674, val_acc : 0.8238095238095239\n",
      "epoch : 374, loss : -0.10540927, tra_acc : 0.9471717171717171\n",
      "epoch : 374, loss : -0.82326263, val_acc : 0.8271428571428571\n",
      "epoch : 375, loss : -0.006152936, tra_acc : 0.9520875420875421\n",
      "epoch : 375, loss : -0.33395317, val_acc : 0.8416666666666667\n",
      "epoch : 376, loss : 0.0755706, tra_acc : 0.9511784511784512\n",
      "epoch : 376, loss : -1.769427, val_acc : 0.8283333333333333\n",
      "epoch : 377, loss : 0.02376137, tra_acc : 0.9348148148148149\n",
      "epoch : 377, loss : -1.053134, val_acc : 0.835\n",
      "epoch : 378, loss : 0.10001309, tra_acc : 0.9475420875420876\n",
      "epoch : 378, loss : -1.8052049, val_acc : 0.8126190476190476\n",
      "epoch : 379, loss : 0.032593343, tra_acc : 0.9520875420875421\n",
      "epoch : 379, loss : -1.4967448, val_acc : 0.8185714285714285\n",
      "epoch : 380, loss : 0.035374884, tra_acc : 0.9545454545454544\n",
      "epoch : 380, loss : -1.3602319, val_acc : 0.8178571428571427\n",
      "epoch : 381, loss : 0.073582046, tra_acc : 0.9493602693602693\n",
      "epoch : 381, loss : 1.273118, val_acc : 0.835\n",
      "epoch : 382, loss : 0.18881813, tra_acc : 0.9439057239057238\n",
      "epoch : 382, loss : -0.71077824, val_acc : 0.8483333333333333\n",
      "epoch : 383, loss : -0.1672542, tra_acc : 0.9319865319865319\n",
      "epoch : 383, loss : 1.1570067, val_acc : 0.8311904761904761\n",
      "epoch : 384, loss : 0.3891881, tra_acc : 0.8979797979797982\n",
      "epoch : 384, loss : 0.6565654, val_acc : 0.8345238095238096\n",
      "epoch : 385, loss : 0.67817765, tra_acc : 0.8995286195286197\n",
      "epoch : 385, loss : 3.313512, val_acc : 0.7140476190476192\n",
      "epoch : 386, loss : 0.46141824, tra_acc : 0.8880808080808081\n",
      "epoch : 386, loss : -1.8905433, val_acc : 0.8635714285714285\n",
      "epoch : 387, loss : -0.43304136, tra_acc : 0.9244444444444444\n",
      "epoch : 387, loss : 0.28137508, val_acc : 0.8376190476190476\n",
      "epoch : 388, loss : 0.108777285, tra_acc : 0.9536363636363635\n",
      "epoch : 388, loss : -0.21392815, val_acc : 0.82\n",
      "epoch : 389, loss : 0.02883101, tra_acc : 0.9481818181818181\n",
      "epoch : 389, loss : -0.37609327, val_acc : 0.8152380952380952\n",
      "epoch : 390, loss : 0.060502563, tra_acc : 0.9481818181818181\n",
      "epoch : 390, loss : 0.36723706, val_acc : 0.8464285714285714\n",
      "epoch : 391, loss : 0.10442179, tra_acc : 0.947811447811448\n",
      "epoch : 391, loss : -0.42589283, val_acc : 0.8416666666666667\n",
      "epoch : 392, loss : 0.12852198, tra_acc : 0.9484511784511784\n",
      "epoch : 392, loss : -0.6108162, val_acc : 0.8345238095238096\n",
      "epoch : 393, loss : 0.052317917, tra_acc : 0.9563636363636365\n",
      "epoch : 393, loss : -0.48096868, val_acc : 0.8476190476190476\n",
      "epoch : 394, loss : 0.027478004, tra_acc : 0.953905723905724\n",
      "epoch : 394, loss : -0.91359895, val_acc : 0.849047619047619\n",
      "epoch : 395, loss : 0.06712802, tra_acc : 0.9563636363636363\n",
      "epoch : 395, loss : -1.1745621, val_acc : 0.8423809523809523\n",
      "epoch : 396, loss : 0.101415545, tra_acc : 0.9539057239057239\n",
      "epoch : 396, loss : -1.1147224, val_acc : 0.8371428571428572\n",
      "epoch : 397, loss : -0.4523466, tra_acc : 0.9187205387205387\n",
      "epoch : 397, loss : 1.0001019, val_acc : 0.8411904761904762\n",
      "epoch : 398, loss : 0.2903206, tra_acc : 0.9484511784511785\n",
      "epoch : 398, loss : 0.05370164, val_acc : 0.835952380952381\n",
      "epoch : 399, loss : 0.05743769, tra_acc : 0.9366329966329967\n",
      "epoch : 399, loss : 0.65978336, val_acc : 0.8483333333333333\n",
      "epoch : 400, loss : 0.004402407, tra_acc : 0.9320875420875421\n",
      "epoch : 400, loss : 0.78604984, val_acc : 0.8483333333333333\n",
      "epoch : 401, loss : 0.11637134, tra_acc : 0.9539057239057239\n",
      "epoch : 401, loss : -0.4858764, val_acc : 0.8311904761904761\n",
      "epoch : 402, loss : 0.06748471, tra_acc : 0.9480808080808082\n",
      "epoch : 402, loss : -0.6630555, val_acc : 0.8345238095238097\n",
      "epoch : 403, loss : 0.09159357, tra_acc : 0.9471717171717171\n",
      "epoch : 403, loss : -0.25487843, val_acc : 0.8371428571428572\n",
      "epoch : 404, loss : 0.25872004, tra_acc : 0.94989898989899\n",
      "epoch : 404, loss : -1.0023464, val_acc : 0.8416666666666667\n",
      "epoch : 405, loss : 0.118862845, tra_acc : 0.9498989898989898\n",
      "epoch : 405, loss : -0.4266014, val_acc : 0.8345238095238096\n",
      "epoch : 406, loss : 0.12071743, tra_acc : 0.9523569023569024\n",
      "epoch : 406, loss : -1.436307, val_acc : 0.8345238095238096\n",
      "epoch : 407, loss : 0.094991274, tra_acc : 0.9523569023569024\n",
      "epoch : 407, loss : -1.774283, val_acc : 0.8383333333333334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 408, loss : -0.005018245, tra_acc : 0.954814814814815\n",
      "epoch : 408, loss : -1.5057836, val_acc : 0.8371428571428572\n",
      "epoch : 409, loss : 0.03323299, tra_acc : 0.9572727272727274\n",
      "epoch : 409, loss : -1.62436, val_acc : 0.8357142857142857\n",
      "epoch : 410, loss : 0.081765056, tra_acc : 0.9572727272727272\n",
      "epoch : 410, loss : -1.3924093, val_acc : 0.8311904761904761\n",
      "epoch : 411, loss : 0.110662654, tra_acc : 0.9523569023569024\n",
      "epoch : 411, loss : -1.5248405, val_acc : 0.8471428571428571\n",
      "epoch : 412, loss : -0.16453002, tra_acc : 0.9523569023569024\n",
      "epoch : 412, loss : -1.151543, val_acc : 0.8252380952380952\n",
      "epoch : 413, loss : 0.045863118, tra_acc : 0.9572727272727272\n",
      "epoch : 413, loss : -1.0443319, val_acc : 0.8450000000000001\n",
      "epoch : 414, loss : 0.39796135, tra_acc : 0.9214478114478113\n",
      "epoch : 414, loss : -1.7016072, val_acc : 0.855\n",
      "epoch : 415, loss : -0.013848349, tra_acc : 0.9572727272727272\n",
      "epoch : 415, loss : -2.47155, val_acc : 0.8230952380952381\n",
      "epoch : 416, loss : 0.16372435, tra_acc : 0.9514478114478113\n",
      "epoch : 416, loss : -1.5316726, val_acc : 0.8423809523809523\n",
      "epoch : 417, loss : 0.023014402, tra_acc : 0.9548148148148148\n",
      "epoch : 417, loss : -0.78670937, val_acc : 0.8423809523809523\n",
      "epoch : 418, loss : -0.002465622, tra_acc : 0.9548148148148148\n",
      "epoch : 418, loss : -1.2659246, val_acc : 0.8371428571428572\n",
      "epoch : 419, loss : 0.47678196, tra_acc : 0.8975420875420876\n",
      "epoch : 419, loss : -1.864029, val_acc : 0.8483333333333333\n",
      "epoch : 420, loss : -0.088205345, tra_acc : 0.9489898989898989\n",
      "epoch : 420, loss : -0.5473913, val_acc : 0.835952380952381\n",
      "epoch : 421, loss : -0.050592624, tra_acc : 0.9523569023569022\n",
      "epoch : 421, loss : -0.40321767, val_acc : 0.850952380952381\n",
      "epoch : 422, loss : -0.11658942, tra_acc : 0.953905723905724\n",
      "epoch : 422, loss : -0.9858193, val_acc : 0.8364285714285714\n",
      "epoch : 423, loss : 0.08451256, tra_acc : 0.9572727272727272\n",
      "epoch : 423, loss : -0.49850473, val_acc : 0.8345238095238096\n",
      "epoch : 424, loss : -0.18284927, tra_acc : 0.9466329966329966\n",
      "epoch : 424, loss : 0.51067275, val_acc : 0.8278571428571428\n",
      "epoch : 425, loss : 0.42961112, tra_acc : 0.9474410774410774\n",
      "epoch : 425, loss : -0.051276576, val_acc : 0.8450000000000001\n",
      "epoch : 426, loss : 0.14523813, tra_acc : 0.9354545454545454\n",
      "epoch : 426, loss : 0.053598862, val_acc : 0.8430952380952381\n",
      "epoch : 427, loss : 0.08023626, tra_acc : 0.915084175084175\n",
      "epoch : 427, loss : -0.8124938, val_acc : 0.8576190476190476\n",
      "epoch : 428, loss : 0.006751743, tra_acc : 0.9202693602693603\n",
      "epoch : 428, loss : 0.60977876, val_acc : 0.8438095238095237\n",
      "epoch : 429, loss : 0.1422351, tra_acc : 0.9439057239057239\n",
      "epoch : 429, loss : -0.62298393, val_acc : 0.8642857142857143\n",
      "epoch : 430, loss : 0.109904714, tra_acc : 0.9353535353535354\n",
      "epoch : 430, loss : -0.6515345, val_acc : 0.8357142857142857\n",
      "epoch : 431, loss : 0.119705126, tra_acc : 0.9439057239057239\n",
      "epoch : 431, loss : -0.59667444, val_acc : 0.8390476190476192\n",
      "epoch : 432, loss : 0.18469223, tra_acc : 0.9423569023569023\n",
      "epoch : 432, loss : 0.24673207, val_acc : 0.8259523809523809\n",
      "epoch : 433, loss : 0.17887305, tra_acc : 0.9529966329966331\n",
      "epoch : 433, loss : -0.08977783, val_acc : 0.8669047619047618\n",
      "epoch : 434, loss : -0.34483075, tra_acc : 0.9135353535353535\n",
      "epoch : 434, loss : 2.6232812, val_acc : 0.8030952380952381\n",
      "epoch : 435, loss : 0.21753317, tra_acc : 0.9409090909090909\n",
      "epoch : 435, loss : -0.42661706, val_acc : 0.8554761904761904\n",
      "epoch : 436, loss : 0.121510364, tra_acc : 0.9502693602693604\n",
      "epoch : 436, loss : -0.17670731, val_acc : 0.8504761904761905\n",
      "epoch : 437, loss : 0.1885141, tra_acc : 0.9384511784511784\n",
      "epoch : 437, loss : -0.8871381, val_acc : 0.8502380952380952\n",
      "epoch : 438, loss : 0.07186394, tra_acc : 0.9600000000000001\n",
      "epoch : 438, loss : -0.099021375, val_acc : 0.8542857142857142\n",
      "epoch : 439, loss : 0.19405966, tra_acc : 0.955993265993266\n",
      "epoch : 439, loss : -0.863482, val_acc : 0.8311904761904761\n",
      "epoch : 440, loss : 0.068434946, tra_acc : 0.9600000000000001\n",
      "epoch : 440, loss : -1.0715905, val_acc : 0.8471428571428571\n",
      "epoch : 441, loss : 0.07777368, tra_acc : 0.9584511784511786\n",
      "epoch : 441, loss : -0.4253889, val_acc : 0.8576190476190476\n",
      "epoch : 442, loss : 0.104513414, tra_acc : 0.9584511784511786\n",
      "epoch : 442, loss : -1.3437915, val_acc : 0.8404761904761905\n",
      "epoch : 443, loss : -0.110395, tra_acc : 0.9584511784511786\n",
      "epoch : 443, loss : -0.82069224, val_acc : 0.8457142857142856\n",
      "epoch : 444, loss : 0.07078841, tra_acc : 0.9599999999999999\n",
      "epoch : 444, loss : -1.0475558, val_acc : 0.8535714285714285\n",
      "epoch : 445, loss : 0.04912728, tra_acc : 0.9559932659932661\n",
      "epoch : 445, loss : -0.90131736, val_acc : 0.8483333333333333\n",
      "epoch : 446, loss : 0.18036963, tra_acc : 0.9535353535353537\n",
      "epoch : 446, loss : -1.1207005, val_acc : 0.8483333333333333\n",
      "epoch : 447, loss : 0.08603087, tra_acc : 0.9609090909090909\n",
      "epoch : 447, loss : -0.9055536, val_acc : 0.837857142857143\n",
      "epoch : 448, loss : 0.1343742, tra_acc : 0.9584511784511783\n",
      "epoch : 448, loss : -1.829917, val_acc : 0.850952380952381\n",
      "epoch : 449, loss : 0.062277652, tra_acc : 0.9566329966329966\n",
      "epoch : 449, loss : -1.5074158, val_acc : 0.8595238095238095\n",
      "epoch : 450, loss : 0.31925067, tra_acc : 0.9477104377104376\n",
      "epoch : 450, loss : -2.1699438, val_acc : 0.8464285714285714\n",
      "epoch : 451, loss : 0.11795702, tra_acc : 0.9584511784511786\n",
      "epoch : 451, loss : -1.3430566, val_acc : 0.8483333333333333\n",
      "epoch : 452, loss : -0.058599867, tra_acc : 0.955993265993266\n",
      "epoch : 452, loss : -1.6913387, val_acc : 0.8535714285714285\n",
      "epoch : 453, loss : -0.03085395, tra_acc : 0.9575420875420875\n",
      "epoch : 453, loss : -0.98756504, val_acc : 0.8404761904761905\n",
      "epoch : 454, loss : 0.04989284, tra_acc : 0.9372727272727274\n",
      "epoch : 454, loss : 0.50240463, val_acc : 0.8457142857142856\n",
      "epoch : 455, loss : 0.008807854, tra_acc : 0.9550841750841751\n",
      "epoch : 455, loss : -1.2769989, val_acc : 0.8457142857142856\n",
      "epoch : 456, loss : 0.12974979, tra_acc : 0.9557239057239059\n",
      "epoch : 456, loss : -1.5067385, val_acc : 0.8430952380952381\n",
      "epoch : 457, loss : 0.03455857, tra_acc : 0.9590909090909091\n",
      "epoch : 457, loss : -1.2900337, val_acc : 0.8345238095238096\n",
      "epoch : 458, loss : 0.022710593, tra_acc : 0.9453535353535354\n",
      "epoch : 458, loss : -1.4233814, val_acc : 0.837857142857143\n",
      "epoch : 459, loss : 0.07660722, tra_acc : 0.9529966329966331\n",
      "epoch : 459, loss : -2.7064908, val_acc : 0.8404761904761905\n",
      "epoch : 460, loss : 0.028989201, tra_acc : 0.9575420875420875\n",
      "epoch : 460, loss : -2.18077, val_acc : 0.8292857142857143\n",
      "epoch : 461, loss : -0.061158873, tra_acc : 0.9566329966329966\n",
      "epoch : 461, loss : -1.9155957, val_acc : 0.8371428571428572\n",
      "epoch : 462, loss : 0.19547181, tra_acc : 0.9532659932659933\n",
      "epoch : 462, loss : -2.4172156, val_acc : 0.8285714285714286\n",
      "epoch : 463, loss : 0.016522033, tra_acc : 0.9599999999999999\n",
      "epoch : 463, loss : -0.9667864, val_acc : 0.8371428571428572\n",
      "epoch : 464, loss : -0.02509175, tra_acc : 0.9439057239057239\n",
      "epoch : 464, loss : -0.020314932, val_acc : 0.8278571428571428\n",
      "epoch : 465, loss : 0.15084824, tra_acc : 0.9520875420875423\n",
      "epoch : 465, loss : -1.8938669, val_acc : 0.8476190476190476\n",
      "epoch : 466, loss : 0.12469764, tra_acc : 0.9584511784511783\n",
      "epoch : 466, loss : -1.1473058, val_acc : 0.8397619047619047\n",
      "epoch : 467, loss : 0.1528445, tra_acc : 0.9559932659932658\n",
      "epoch : 467, loss : -2.2001107, val_acc : 0.8311904761904761\n",
      "epoch : 468, loss : -0.055550694, tra_acc : 0.9584511784511783\n",
      "epoch : 468, loss : -0.81142044, val_acc : 0.8330952380952382\n",
      "epoch : 469, loss : 0.15933579, tra_acc : 0.9492592592592591\n",
      "epoch : 469, loss : -2.4745228, val_acc : 0.8554761904761904\n",
      "epoch : 470, loss : 0.01791305, tra_acc : 0.9529966329966331\n",
      "epoch : 470, loss : -2.8884423, val_acc : 0.8423809523809523\n",
      "epoch : 471, loss : 0.0046726167, tra_acc : 0.9609090909090909\n",
      "epoch : 471, loss : -1.2678018, val_acc : 0.8502380952380952\n",
      "epoch : 472, loss : 0.16464235, tra_acc : 0.9550841750841751\n",
      "epoch : 472, loss : -1.7385765, val_acc : 0.8345238095238097\n",
      "epoch : 473, loss : 0.18031178, tra_acc : 0.955993265993266\n",
      "epoch : 473, loss : -3.2553227, val_acc : 0.8423809523809523\n",
      "epoch : 474, loss : 0.061476037, tra_acc : 0.955993265993266\n",
      "epoch : 474, loss : -3.2850647, val_acc : 0.8404761904761905\n",
      "epoch : 475, loss : 0.029050494, tra_acc : 0.9600000000000001\n",
      "epoch : 475, loss : -1.2309318, val_acc : 0.8233333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 476, loss : 0.065222055, tra_acc : 0.9609090909090909\n",
      "epoch : 476, loss : -1.2961355, val_acc : 0.8416666666666667\n",
      "epoch : 477, loss : 0.1477579, tra_acc : 0.9559932659932661\n",
      "epoch : 477, loss : -2.520712, val_acc : 0.8319047619047618\n",
      "epoch : 478, loss : 0.0443137, tra_acc : 0.9609090909090908\n",
      "epoch : 478, loss : -2.128349, val_acc : 0.8345238095238097\n",
      "epoch : 479, loss : -0.026716834, tra_acc : 0.9569023569023568\n",
      "epoch : 479, loss : -1.7026979, val_acc : 0.8292857142857143\n",
      "epoch : 480, loss : -0.0011557381, tra_acc : 0.9584511784511786\n",
      "epoch : 480, loss : -0.77694017, val_acc : 0.8450000000000001\n",
      "epoch : 481, loss : -0.10291124, tra_acc : 0.9584511784511786\n",
      "epoch : 481, loss : -0.94632554, val_acc : 0.8423809523809523\n",
      "epoch : 482, loss : 0.018379433, tra_acc : 0.9584511784511786\n",
      "epoch : 482, loss : -1.3453249, val_acc : 0.8311904761904761\n",
      "epoch : 483, loss : 0.03892875, tra_acc : 0.9609090909090909\n",
      "epoch : 483, loss : -0.9850054, val_acc : 0.8304761904761904\n",
      "epoch : 484, loss : -0.080434434, tra_acc : 0.9584511784511786\n",
      "epoch : 484, loss : -1.1163019, val_acc : 0.8278571428571428\n",
      "epoch : 485, loss : 0.078041404, tra_acc : 0.955993265993266\n",
      "epoch : 485, loss : -0.76742345, val_acc : 0.8469047619047618\n",
      "epoch : 486, loss : 0.1244415, tra_acc : 0.9071717171717171\n",
      "epoch : 486, loss : -6.7081475, val_acc : 0.8345238095238096\n",
      "epoch : 487, loss : -0.18285567, tra_acc : 0.9496296296296296\n",
      "epoch : 487, loss : -2.968011, val_acc : 0.8497619047619048\n",
      "epoch : 488, loss : -0.12470148, tra_acc : 0.9505387205387205\n",
      "epoch : 488, loss : -0.30545878, val_acc : 0.8278571428571428\n",
      "epoch : 489, loss : -0.019634578, tra_acc : 0.9584511784511786\n",
      "epoch : 489, loss : -1.2640778, val_acc : 0.8311904761904761\n",
      "epoch : 490, loss : -0.013858483, tra_acc : 0.9602693602693603\n",
      "epoch : 490, loss : -1.0896798, val_acc : 0.8311904761904761\n",
      "epoch : 491, loss : 0.15579028, tra_acc : 0.9593602693602694\n",
      "epoch : 491, loss : -2.2008393, val_acc : 0.824047619047619\n",
      "epoch : 492, loss : 0.0045274454, tra_acc : 0.9627272727272728\n",
      "epoch : 492, loss : -1.4391309, val_acc : 0.8252380952380952\n",
      "epoch : 493, loss : 0.0760281, tra_acc : 0.9578114478114478\n",
      "epoch : 493, loss : -1.9133215, val_acc : 0.8345238095238097\n",
      "epoch : 494, loss : -0.5049455, tra_acc : 0.9569023569023568\n",
      "epoch : 494, loss : -2.7950861, val_acc : 0.8233333333333334\n",
      "epoch : 495, loss : 0.053686645, tra_acc : 0.9584511784511787\n",
      "epoch : 495, loss : -1.0355171, val_acc : 0.8297619047619048\n",
      "epoch : 496, loss : 0.017377205, tra_acc : 0.9627272727272728\n",
      "epoch : 496, loss : -0.8608158, val_acc : 0.8278571428571428\n",
      "epoch : 497, loss : 0.014227095, tra_acc : 0.9627272727272728\n",
      "epoch : 497, loss : -1.1625053, val_acc : 0.8259523809523809\n",
      "epoch : 498, loss : 0.09989075, tra_acc : 0.9602693602693603\n",
      "epoch : 498, loss : -0.9459271, val_acc : 0.8357142857142857\n",
      "epoch : 499, loss : 0.0046900087, tra_acc : 0.9627272727272728\n",
      "epoch : 499, loss : -1.1321567, val_acc : 0.8521428571428572\n",
      "epoch : 500, loss : 0.06193445, tra_acc : 0.9602693602693605\n",
      "epoch : 500, loss : -1.1363202, val_acc : 0.8311904761904761\n",
      "epoch : 501, loss : 0.042958334, tra_acc : 0.9602693602693605\n",
      "epoch : 501, loss : -1.2431117, val_acc : 0.8271428571428571\n",
      "epoch : 502, loss : 0.03476036, tra_acc : 0.9627272727272728\n",
      "epoch : 502, loss : -0.5012745, val_acc : 0.833095238095238\n",
      "epoch : 503, loss : 0.029437268, tra_acc : 0.9627272727272728\n",
      "epoch : 503, loss : -0.46044526, val_acc : 0.8304761904761904\n",
      "epoch : 504, loss : 0.102631874, tra_acc : 0.9627272727272728\n",
      "epoch : 504, loss : -0.87059504, val_acc : 0.8304761904761904\n",
      "epoch : 505, loss : 0.050971333, tra_acc : 0.9627272727272728\n",
      "epoch : 505, loss : -1.0598804, val_acc : 0.8383333333333334\n",
      "epoch : 506, loss : 0.033595417, tra_acc : 0.9602693602693602\n",
      "epoch : 506, loss : -0.77482295, val_acc : 0.8390476190476192\n",
      "epoch : 507, loss : 0.05698824, tra_acc : 0.9553535353535355\n",
      "epoch : 507, loss : -1.3511888, val_acc : 0.8259523809523809\n",
      "epoch : 508, loss : 0.017014287, tra_acc : 0.9627272727272728\n",
      "epoch : 508, loss : -1.2821455, val_acc : 0.8330952380952382\n",
      "epoch : 509, loss : 0.060200717, tra_acc : 0.9627272727272728\n",
      "epoch : 509, loss : -0.9998171, val_acc : 0.8338095238095238\n",
      "epoch : 510, loss : 0.0609761, tra_acc : 0.9602693602693605\n",
      "epoch : 510, loss : -0.7493777, val_acc : 0.8285714285714286\n",
      "epoch : 511, loss : 0.073300205, tra_acc : 0.9578114478114478\n",
      "epoch : 511, loss : -0.9447513, val_acc : 0.8311904761904761\n",
      "epoch : 512, loss : 0.14491782, tra_acc : 0.9602693602693603\n",
      "epoch : 512, loss : -0.81574756, val_acc : 0.8442857142857143\n",
      "epoch : 513, loss : -0.020951618, tra_acc : 0.9578114478114478\n",
      "epoch : 513, loss : -1.3285999, val_acc : 0.8364285714285714\n",
      "epoch : 514, loss : 0.12593548, tra_acc : 0.9578114478114478\n",
      "epoch : 514, loss : -0.9673521, val_acc : 0.8364285714285714\n",
      "epoch : 515, loss : 0.016260285, tra_acc : 0.9602693602693603\n",
      "epoch : 515, loss : -0.26779416, val_acc : 0.833095238095238\n",
      "epoch : 516, loss : 0.07352665, tra_acc : 0.9627272727272728\n",
      "epoch : 516, loss : -1.0562487, val_acc : 0.8338095238095239\n",
      "epoch : 517, loss : 0.022938842, tra_acc : 0.9627272727272728\n",
      "epoch : 517, loss : -0.8066099, val_acc : 0.8397619047619047\n",
      "epoch : 518, loss : 0.026880275, tra_acc : 0.9593602693602694\n",
      "epoch : 518, loss : -1.5357069, val_acc : 0.8357142857142857\n",
      "epoch : 519, loss : 0.10297818, tra_acc : 0.9602693602693603\n",
      "epoch : 519, loss : -0.21178865, val_acc : 0.8416666666666667\n",
      "epoch : 520, loss : 0.03912839, tra_acc : 0.9578114478114478\n",
      "epoch : 520, loss : 0.00048014522, val_acc : 0.8278571428571428\n",
      "epoch : 521, loss : 0.054982748, tra_acc : 0.9544444444444444\n",
      "epoch : 521, loss : -2.0562067, val_acc : 0.8409523809523809\n",
      "epoch : 522, loss : 0.035629008, tra_acc : 0.9627272727272728\n",
      "epoch : 522, loss : -1.0007073, val_acc : 0.8304761904761904\n",
      "epoch : 523, loss : 0.056307435, tra_acc : 0.9578114478114478\n",
      "epoch : 523, loss : -1.9379706, val_acc : 0.8121428571428572\n",
      "epoch : 524, loss : 0.048377577, tra_acc : 0.9602693602693603\n",
      "epoch : 524, loss : -2.3730733, val_acc : 0.8371428571428572\n",
      "epoch : 525, loss : 0.04631346, tra_acc : 0.9627272727272728\n",
      "epoch : 525, loss : -0.9596651, val_acc : 0.8345238095238096\n",
      "epoch : 526, loss : -0.014998185, tra_acc : 0.9600000000000001\n",
      "epoch : 526, loss : -1.2773354, val_acc : 0.850952380952381\n",
      "epoch : 527, loss : 0.055324577, tra_acc : 0.9627272727272728\n",
      "epoch : 527, loss : -1.1159195, val_acc : 0.8364285714285714\n",
      "epoch : 528, loss : 0.15521543, tra_acc : 0.9578114478114478\n",
      "epoch : 528, loss : -3.323644, val_acc : 0.8352380952380952\n",
      "epoch : 529, loss : 0.16730362, tra_acc : 0.9541750841750841\n",
      "epoch : 529, loss : -0.87290365, val_acc : 0.8364285714285714\n",
      "epoch : 530, loss : 0.16395962, tra_acc : 0.9584511784511786\n",
      "epoch : 530, loss : -1.897077, val_acc : 0.8304761904761904\n",
      "epoch : 531, loss : 0.122055694, tra_acc : 0.9602693602693603\n",
      "epoch : 531, loss : -1.334349, val_acc : 0.8330952380952382\n",
      "epoch : 532, loss : 0.0090562375, tra_acc : 0.9618181818181817\n",
      "epoch : 532, loss : -1.8522753, val_acc : 0.8259523809523809\n",
      "epoch : 533, loss : 0.058636595, tra_acc : 0.9572727272727272\n",
      "epoch : 533, loss : -1.6639185, val_acc : 0.8285714285714286\n",
      "epoch : 534, loss : -0.16289958, tra_acc : 0.9544444444444443\n",
      "epoch : 534, loss : -0.7412545, val_acc : 0.8371428571428572\n",
      "epoch : 535, loss : -0.03074184, tra_acc : 0.9578114478114479\n",
      "epoch : 535, loss : -0.43927452, val_acc : 0.8397619047619047\n",
      "epoch : 536, loss : 0.20871863, tra_acc : 0.9578114478114478\n",
      "epoch : 536, loss : -1.5869809, val_acc : 0.8311904761904761\n",
      "epoch : 537, loss : -0.021500856, tra_acc : 0.9575420875420876\n",
      "epoch : 537, loss : -1.216854, val_acc : 0.8285714285714286\n",
      "epoch : 538, loss : 0.039809916, tra_acc : 0.9627272727272728\n",
      "epoch : 538, loss : -1.255761, val_acc : 0.8476190476190476\n",
      "epoch : 539, loss : -0.0006778918, tra_acc : 0.9618181818181818\n",
      "epoch : 539, loss : 0.15608422, val_acc : 0.8345238095238097\n",
      "epoch : 540, loss : 0.030237777, tra_acc : 0.9627272727272728\n",
      "epoch : 540, loss : -0.63789636, val_acc : 0.8383333333333334\n",
      "epoch : 541, loss : 0.16237976, tra_acc : 0.9602693602693603\n",
      "epoch : 541, loss : -0.63004845, val_acc : 0.8364285714285714\n",
      "epoch : 542, loss : 0.13467556, tra_acc : 0.9602693602693602\n",
      "epoch : 542, loss : -0.8088696, val_acc : 0.8319047619047618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 543, loss : -0.0007719926, tra_acc : 0.9584511784511786\n",
      "epoch : 543, loss : -0.97250533, val_acc : 0.8364285714285714\n",
      "epoch : 544, loss : 0.1429448, tra_acc : 0.9541750841750843\n",
      "epoch : 544, loss : -1.072318, val_acc : 0.8364285714285714\n",
      "epoch : 545, loss : -0.16712882, tra_acc : 0.9167003367003368\n",
      "epoch : 545, loss : 7.862695, val_acc : 0.7533333333333333\n",
      "epoch : 546, loss : 0.5737928, tra_acc : 0.9393602693602694\n",
      "epoch : 546, loss : 0.73055905, val_acc : 0.8495238095238097\n",
      "epoch : 547, loss : 0.08651572, tra_acc : 0.9602693602693603\n",
      "epoch : 547, loss : 0.6763058, val_acc : 0.8423809523809523\n",
      "epoch : 548, loss : 0.1458799, tra_acc : 0.9602693602693603\n",
      "epoch : 548, loss : 0.6834758, val_acc : 0.8345238095238096\n",
      "epoch : 549, loss : 0.012472718, tra_acc : 0.9505387205387205\n",
      "epoch : 549, loss : 0.65493315, val_acc : 0.8476190476190476\n",
      "epoch : 550, loss : 0.090639725, tra_acc : 0.9569023569023568\n",
      "epoch : 550, loss : -0.11368084, val_acc : 0.8476190476190476\n",
      "epoch : 551, loss : 0.06767201, tra_acc : 0.9636363636363636\n",
      "epoch : 551, loss : -0.6973136, val_acc : 0.8423809523809523\n",
      "epoch : 552, loss : 0.08632438, tra_acc : 0.9602693602693602\n",
      "epoch : 552, loss : -0.9003882, val_acc : 0.8397619047619048\n",
      "epoch : 553, loss : 0.14814109, tra_acc : 0.9602693602693603\n",
      "epoch : 553, loss : -1.4623823, val_acc : 0.8152380952380952\n",
      "epoch : 554, loss : 0.020895, tra_acc : 0.9609090909090909\n",
      "epoch : 554, loss : -0.6716769, val_acc : 0.8259523809523809\n",
      "epoch : 555, loss : 0.0127642965, tra_acc : 0.9611784511784512\n",
      "epoch : 555, loss : -1.0606298, val_acc : 0.8390476190476189\n",
      "epoch : 556, loss : -0.2756403, tra_acc : 0.9596296296296297\n",
      "epoch : 556, loss : -0.31872898, val_acc : 0.8345238095238096\n",
      "epoch : 557, loss : 0.72208524, tra_acc : 0.9166329966329966\n",
      "epoch : 557, loss : -2.3772233, val_acc : 0.8523809523809524\n",
      "epoch : 558, loss : -0.06774586, tra_acc : 0.9618181818181818\n",
      "epoch : 558, loss : -1.6307812, val_acc : 0.8285714285714286\n",
      "epoch : 559, loss : -0.014868782, tra_acc : 0.9636363636363634\n",
      "epoch : 559, loss : -1.0433866, val_acc : 0.8292857142857143\n",
      "epoch : 560, loss : 0.08569486, tra_acc : 0.9611784511784512\n",
      "epoch : 560, loss : -0.90300584, val_acc : 0.8397619047619048\n",
      "epoch : 561, loss : 0.006112252, tra_acc : 0.9611784511784514\n",
      "epoch : 561, loss : -1.3927436, val_acc : 0.849047619047619\n",
      "epoch : 562, loss : 0.095012166, tra_acc : 0.9602693602693605\n",
      "epoch : 562, loss : -0.33545968, val_acc : 0.8397619047619047\n",
      "epoch : 563, loss : 0.0063456516, tra_acc : 0.9645454545454545\n",
      "epoch : 563, loss : -0.67980915, val_acc : 0.8292857142857143\n",
      "epoch : 564, loss : 0.08726244, tra_acc : 0.9547138047138045\n",
      "epoch : 564, loss : -0.8380936, val_acc : 0.8390476190476189\n",
      "epoch : 565, loss : -0.16145585, tra_acc : 0.9508080808080809\n",
      "epoch : 565, loss : 6.1161613, val_acc : 0.745\n",
      "epoch : 566, loss : 0.8339838, tra_acc : 0.8923569023569022\n",
      "epoch : 566, loss : -2.9369843, val_acc : 0.8516666666666666\n",
      "epoch : 567, loss : -0.10052913, tra_acc : 0.9432659932659931\n",
      "epoch : 567, loss : 0.0030005772, val_acc : 0.850952380952381\n",
      "epoch : 568, loss : -0.083530836, tra_acc : 0.9566329966329966\n",
      "epoch : 568, loss : -0.30873147, val_acc : 0.8326190476190476\n",
      "epoch : 569, loss : 0.006687231, tra_acc : 0.9654545454545456\n",
      "epoch : 569, loss : -0.24222676, val_acc : 0.8430952380952381\n",
      "epoch : 570, loss : 0.07120238, tra_acc : 0.9556228956228956\n",
      "epoch : 570, loss : -0.69490606, val_acc : 0.849047619047619\n",
      "epoch : 571, loss : -0.13895969, tra_acc : 0.9605387205387206\n",
      "epoch : 571, loss : -0.22070695, val_acc : 0.8464285714285715\n",
      "epoch : 572, loss : 0.006849919, tra_acc : 0.9605387205387204\n",
      "epoch : 572, loss : -0.5590555, val_acc : 0.8516666666666667\n",
      "epoch : 573, loss : 0.10965154, tra_acc : 0.9605387205387204\n",
      "epoch : 573, loss : -0.33405733, val_acc : 0.8438095238095237\n",
      "epoch : 574, loss : 0.048265554, tra_acc : 0.962996632996633\n",
      "epoch : 574, loss : -0.27416757, val_acc : 0.8542857142857142\n",
      "epoch : 575, loss : -0.009821585, tra_acc : 0.9645454545454547\n",
      "epoch : 575, loss : 0.017262233, val_acc : 0.8516666666666666\n",
      "epoch : 576, loss : 0.03365141, tra_acc : 0.9654545454545453\n",
      "epoch : 576, loss : 0.22334915, val_acc : 0.8516666666666667\n",
      "epoch : 577, loss : 0.15188064, tra_acc : 0.9575420875420876\n",
      "epoch : 577, loss : 0.5339997, val_acc : 0.8326190476190476\n",
      "epoch : 578, loss : 0.06709845, tra_acc : 0.9654545454545456\n",
      "epoch : 578, loss : -0.2979116, val_acc : 0.8464285714285715\n",
      "epoch : 579, loss : -0.18758942, tra_acc : 0.958080808080808\n",
      "epoch : 579, loss : -1.0375293, val_acc : 0.850952380952381\n",
      "epoch : 580, loss : 0.12249265, tra_acc : 0.9578114478114479\n",
      "epoch : 580, loss : 0.1473998, val_acc : 0.8352380952380952\n",
      "epoch : 581, loss : -0.24501985, tra_acc : 0.9605387205387204\n",
      "epoch : 581, loss : -0.63474905, val_acc : 0.8561904761904762\n",
      "epoch : 582, loss : 0.10749135, tra_acc : 0.9605387205387204\n",
      "epoch : 582, loss : -0.7625826, val_acc : 0.8300000000000001\n",
      "epoch : 583, loss : 0.07667649, tra_acc : 0.9556228956228956\n",
      "epoch : 583, loss : -1.0225883, val_acc : 0.837857142857143\n",
      "epoch : 584, loss : 0.16784273, tra_acc : 0.9605387205387206\n",
      "epoch : 584, loss : -0.48826876, val_acc : 0.8535714285714285\n",
      "epoch : 585, loss : 0.008169449, tra_acc : 0.9654545454545453\n",
      "epoch : 585, loss : 0.20145972, val_acc : 0.8423809523809523\n",
      "epoch : 586, loss : 0.05105373, tra_acc : 0.9654545454545456\n",
      "epoch : 586, loss : -0.856085, val_acc : 0.8266666666666667\n",
      "epoch : 587, loss : -0.0139452135, tra_acc : 0.9602693602693603\n",
      "epoch : 587, loss : 0.030293524, val_acc : 0.8397619047619048\n",
      "epoch : 588, loss : -0.14606337, tra_acc : 0.9605387205387204\n",
      "epoch : 588, loss : -0.431774, val_acc : 0.8476190476190476\n",
      "epoch : 589, loss : 0.040109918, tra_acc : 0.9654545454545453\n",
      "epoch : 589, loss : 0.2580059, val_acc : 0.8476190476190476\n",
      "epoch : 590, loss : 0.19592398, tra_acc : 0.962996632996633\n",
      "epoch : 590, loss : -0.6784088, val_acc : 0.8430952380952381\n",
      "epoch : 591, loss : -0.019314343, tra_acc : 0.9605387205387206\n",
      "epoch : 591, loss : -0.31483603, val_acc : 0.8476190476190476\n",
      "epoch : 592, loss : 0.05430213, tra_acc : 0.9654545454545456\n",
      "epoch : 592, loss : -0.41662583, val_acc : 0.8397619047619048\n",
      "epoch : 593, loss : 0.1377225, tra_acc : 0.9605387205387206\n",
      "epoch : 593, loss : 0.10291714, val_acc : 0.8450000000000001\n",
      "epoch : 594, loss : 0.08002379, tra_acc : 0.962996632996633\n",
      "epoch : 594, loss : -0.3566648, val_acc : 0.8371428571428572\n",
      "epoch : 595, loss : 0.051309165, tra_acc : 0.962996632996633\n",
      "epoch : 595, loss : -0.56302404, val_acc : 0.8233333333333333\n",
      "epoch : 596, loss : -0.009165103, tra_acc : 0.9580808080808082\n",
      "epoch : 596, loss : -0.31082752, val_acc : 0.8416666666666667\n",
      "epoch : 597, loss : 0.027481927, tra_acc : 0.9654545454545456\n",
      "epoch : 597, loss : 0.21075957, val_acc : 0.8442857142857143\n",
      "epoch : 598, loss : 0.035703037, tra_acc : 0.9654545454545452\n",
      "epoch : 598, loss : -0.24713643, val_acc : 0.8338095238095238\n",
      "epoch : 599, loss : 0.08795152, tra_acc : 0.9605387205387206\n",
      "epoch : 599, loss : -0.17519677, val_acc : 0.8390476190476192\n",
      "epoch : 600, loss : 0.030027514, tra_acc : 0.9629966329966332\n",
      "epoch : 600, loss : -0.29882294, val_acc : 0.8364285714285714\n",
      "epoch : 601, loss : -0.0013897202, tra_acc : 0.9654545454545456\n",
      "epoch : 601, loss : 0.18800086, val_acc : 0.8390476190476192\n",
      "epoch : 602, loss : 0.21070571, tra_acc : 0.9580808080808082\n",
      "epoch : 602, loss : -0.31503615, val_acc : 0.8416666666666667\n",
      "epoch : 603, loss : 0.08490464, tra_acc : 0.9654545454545456\n",
      "epoch : 603, loss : -1.1838325, val_acc : 0.8311904761904761\n",
      "epoch : 604, loss : -0.045587875, tra_acc : 0.9629966329966332\n",
      "epoch : 604, loss : -0.60481375, val_acc : 0.8364285714285714\n",
      "epoch : 605, loss : -0.039783947, tra_acc : 0.958080808080808\n",
      "epoch : 605, loss : -0.040451527, val_acc : 0.8469047619047618\n",
      "epoch : 606, loss : 0.045874897, tra_acc : 0.9629966329966332\n",
      "epoch : 606, loss : -0.18737566, val_acc : 0.8285714285714286\n",
      "epoch : 607, loss : 0.067790724, tra_acc : 0.9629966329966332\n",
      "epoch : 607, loss : -0.25348774, val_acc : 0.8364285714285714\n",
      "epoch : 608, loss : 0.04166952, tra_acc : 0.9654545454545453\n",
      "epoch : 608, loss : -0.8570654, val_acc : 0.8364285714285714\n",
      "epoch : 609, loss : -0.20556077, tra_acc : 0.9605387205387206\n",
      "epoch : 609, loss : -0.81335527, val_acc : 0.8416666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 610, loss : -0.022198321, tra_acc : 0.962996632996633\n",
      "epoch : 610, loss : -1.0205476, val_acc : 0.8390476190476189\n",
      "epoch : 611, loss : 0.046893235, tra_acc : 0.9654545454545453\n",
      "epoch : 611, loss : -1.2783114, val_acc : 0.8311904761904761\n",
      "epoch : 612, loss : -0.003705266, tra_acc : 0.962996632996633\n",
      "epoch : 612, loss : -0.3912052, val_acc : 0.8469047619047618\n",
      "epoch : 613, loss : 0.08521497, tra_acc : 0.9654545454545453\n",
      "epoch : 613, loss : -0.9532728, val_acc : 0.8416666666666667\n",
      "epoch : 614, loss : 0.02355989, tra_acc : 0.9654545454545453\n",
      "epoch : 614, loss : -0.006578684, val_acc : 0.8311904761904761\n",
      "epoch : 615, loss : 0.07047364, tra_acc : 0.9605387205387206\n",
      "epoch : 615, loss : -0.39397213, val_acc : 0.8338095238095238\n",
      "epoch : 616, loss : 0.044232108, tra_acc : 0.9636363636363636\n",
      "epoch : 616, loss : 0.09433317, val_acc : 0.8311904761904761\n",
      "epoch : 617, loss : 0.06473251, tra_acc : 0.9629966329966332\n",
      "epoch : 617, loss : -0.35903016, val_acc : 0.8442857142857143\n",
      "epoch : 618, loss : 0.13568497, tra_acc : 0.9580808080808082\n",
      "epoch : 618, loss : -0.57130384, val_acc : 0.8311904761904761\n",
      "epoch : 619, loss : 0.06959719, tra_acc : 0.962996632996633\n",
      "epoch : 619, loss : -1.2134651, val_acc : 0.8311904761904761\n",
      "epoch : 620, loss : 0.06414639, tra_acc : 0.962996632996633\n",
      "epoch : 620, loss : -0.42887616, val_acc : 0.8416666666666667\n",
      "epoch : 621, loss : 0.009243386, tra_acc : 0.9654545454545456\n",
      "epoch : 621, loss : 0.120927535, val_acc : 0.8364285714285714\n",
      "epoch : 622, loss : 0.043235585, tra_acc : 0.962996632996633\n",
      "epoch : 622, loss : -0.41776073, val_acc : 0.8416666666666667\n",
      "epoch : 623, loss : 0.040800236, tra_acc : 0.9629966329966332\n",
      "epoch : 623, loss : -0.3261165, val_acc : 0.8364285714285714\n",
      "epoch : 624, loss : 0.023805011, tra_acc : 0.9654545454545453\n",
      "epoch : 624, loss : -0.10285056, val_acc : 0.8390476190476189\n",
      "epoch : 625, loss : 0.026142282, tra_acc : 0.9654545454545453\n",
      "epoch : 625, loss : -0.12631033, val_acc : 0.8338095238095239\n",
      "epoch : 626, loss : -0.057321917, tra_acc : 0.962996632996633\n",
      "epoch : 626, loss : -0.533446, val_acc : 0.8364285714285714\n",
      "epoch : 627, loss : 0.14235975, tra_acc : 0.9629966329966332\n",
      "epoch : 627, loss : -0.04222874, val_acc : 0.8364285714285714\n",
      "epoch : 628, loss : 0.0340914, tra_acc : 0.9654545454545456\n",
      "epoch : 628, loss : -1.0950756, val_acc : 0.8364285714285714\n",
      "epoch : 629, loss : 0.04786445, tra_acc : 0.9629966329966332\n",
      "epoch : 629, loss : -0.6841739, val_acc : 0.8390476190476192\n",
      "epoch : 630, loss : 0.16829942, tra_acc : 0.9605387205387206\n",
      "epoch : 630, loss : -0.9719248, val_acc : 0.8338095238095238\n",
      "epoch : 631, loss : 0.025292428, tra_acc : 0.9654545454545456\n",
      "epoch : 631, loss : -0.5905772, val_acc : 0.8390476190476189\n",
      "epoch : 632, loss : -0.26766494, tra_acc : 0.9605387205387204\n",
      "epoch : 632, loss : -0.9140306, val_acc : 0.8233333333333333\n",
      "epoch : 633, loss : 0.13209957, tra_acc : 0.9629966329966332\n",
      "epoch : 633, loss : -0.4526117, val_acc : 0.8259523809523809\n",
      "epoch : 634, loss : 0.007180734, tra_acc : 0.962996632996633\n",
      "epoch : 634, loss : -0.18790258, val_acc : 0.8442857142857143\n",
      "epoch : 635, loss : 0.053245533, tra_acc : 0.9629966329966332\n",
      "epoch : 635, loss : -0.3084119, val_acc : 0.8390476190476192\n",
      "epoch : 636, loss : 0.1713821, tra_acc : 0.962996632996633\n",
      "epoch : 636, loss : -0.29978386, val_acc : 0.8390476190476189\n",
      "epoch : 637, loss : 0.027585274, tra_acc : 0.9654545454545456\n",
      "epoch : 637, loss : -0.42746422, val_acc : 0.8259523809523809\n",
      "epoch : 638, loss : 0.044644047, tra_acc : 0.9654545454545456\n",
      "epoch : 638, loss : -0.6489072, val_acc : 0.8416666666666667\n",
      "epoch : 639, loss : 0.06268249, tra_acc : 0.9654545454545456\n",
      "epoch : 639, loss : -0.24326254, val_acc : 0.8207142857142857\n",
      "epoch : 640, loss : -0.24695511, tra_acc : 0.9629966329966332\n",
      "epoch : 640, loss : -0.8281799, val_acc : 0.8390476190476192\n",
      "epoch : 641, loss : 0.05119506, tra_acc : 0.962996632996633\n",
      "epoch : 641, loss : -0.3210167, val_acc : 0.8338095238095238\n",
      "epoch : 642, loss : 0.036610328, tra_acc : 0.9645454545454545\n",
      "epoch : 642, loss : 0.16515736, val_acc : 0.8390476190476189\n",
      "epoch : 643, loss : 0.07009263, tra_acc : 0.9654545454545456\n",
      "epoch : 643, loss : -1.0630144, val_acc : 0.8259523809523809\n",
      "epoch : 644, loss : 0.035736077, tra_acc : 0.9654545454545453\n",
      "epoch : 644, loss : -0.15709907, val_acc : 0.8311904761904761\n",
      "epoch : 645, loss : 0.2715282, tra_acc : 0.9605387205387206\n",
      "epoch : 645, loss : -0.13057369, val_acc : 0.8416666666666667\n",
      "epoch : 646, loss : 0.017112648, tra_acc : 0.9654545454545453\n",
      "epoch : 646, loss : -0.18703486, val_acc : 0.8442857142857143\n",
      "epoch : 647, loss : 0.06634213, tra_acc : 0.962996632996633\n",
      "epoch : 647, loss : -0.8472584, val_acc : 0.8364285714285714\n",
      "epoch : 648, loss : -0.0010210872, tra_acc : 0.9596296296296295\n",
      "epoch : 648, loss : 0.07369503, val_acc : 0.8364285714285714\n",
      "epoch : 649, loss : 0.15193577, tra_acc : 0.962996632996633\n",
      "epoch : 649, loss : 0.025363922, val_acc : 0.8416666666666667\n",
      "epoch : 650, loss : 0.16412853, tra_acc : 0.9584511784511786\n",
      "epoch : 650, loss : -0.28882155, val_acc : 0.8364285714285714\n",
      "epoch : 651, loss : 0.046725214, tra_acc : 0.958080808080808\n",
      "epoch : 651, loss : -0.37574792, val_acc : 0.8338095238095238\n",
      "epoch : 652, loss : 0.0744862, tra_acc : 0.962996632996633\n",
      "epoch : 652, loss : -0.204139, val_acc : 0.8285714285714286\n",
      "epoch : 653, loss : 0.12484508, tra_acc : 0.9620875420875422\n",
      "epoch : 653, loss : 0.18011464, val_acc : 0.8416666666666667\n",
      "epoch : 654, loss : 0.01906264, tra_acc : 0.9654545454545456\n",
      "epoch : 654, loss : 0.14641543, val_acc : 0.8469047619047618\n",
      "epoch : 655, loss : 0.06421321, tra_acc : 0.9605387205387206\n",
      "epoch : 655, loss : -0.5051652, val_acc : 0.8338095238095239\n",
      "epoch : 656, loss : -0.108680986, tra_acc : 0.9605387205387204\n",
      "epoch : 656, loss : -0.14311676, val_acc : 0.8442857142857143\n",
      "epoch : 657, loss : 0.028324308, tra_acc : 0.9602693602693603\n",
      "epoch : 657, loss : -0.23308651, val_acc : 0.8338095238095239\n",
      "epoch : 658, loss : 0.06398361, tra_acc : 0.9654545454545456\n",
      "epoch : 658, loss : -0.22074778, val_acc : 0.8469047619047618\n",
      "epoch : 659, loss : -0.05454304, tra_acc : 0.9596296296296295\n",
      "epoch : 659, loss : -0.7210682, val_acc : 0.8259523809523809\n",
      "epoch : 660, loss : -0.017743994, tra_acc : 0.9578114478114478\n",
      "epoch : 660, loss : 0.009884338, val_acc : 0.8357142857142857\n",
      "epoch : 661, loss : 0.17328498, tra_acc : 0.962996632996633\n",
      "epoch : 661, loss : -0.27859315, val_acc : 0.8233333333333333\n",
      "epoch : 662, loss : 0.034557063, tra_acc : 0.962996632996633\n",
      "epoch : 662, loss : 0.12711298, val_acc : 0.8442857142857143\n",
      "epoch : 663, loss : 0.1984169, tra_acc : 0.9605387205387206\n",
      "epoch : 663, loss : 0.028980574, val_acc : 0.8442857142857143\n",
      "epoch : 664, loss : 0.22094902, tra_acc : 0.9605387205387206\n",
      "epoch : 664, loss : -0.6351394, val_acc : 0.8207142857142857\n",
      "epoch : 665, loss : 0.012581661, tra_acc : 0.9654545454545456\n",
      "epoch : 665, loss : -0.6380476, val_acc : 0.8338095238095238\n",
      "epoch : 666, loss : 0.0039126906, tra_acc : 0.9602693602693602\n",
      "epoch : 666, loss : -0.37636662, val_acc : 0.8338095238095239\n",
      "epoch : 667, loss : 0.04723512, tra_acc : 0.9605387205387206\n",
      "epoch : 667, loss : 0.30830586, val_acc : 0.8311904761904761\n",
      "epoch : 668, loss : 0.03862729, tra_acc : 0.9654545454545456\n",
      "epoch : 668, loss : 0.6103147, val_acc : 0.8442857142857143\n",
      "epoch : 669, loss : 0.08111977, tra_acc : 0.9654545454545453\n",
      "epoch : 669, loss : 0.27653, val_acc : 0.8259523809523809\n",
      "epoch : 670, loss : 0.18527517, tra_acc : 0.962996632996633\n",
      "epoch : 670, loss : -0.6696181, val_acc : 0.8416666666666667\n",
      "epoch : 671, loss : 0.12353093, tra_acc : 0.9629966329966332\n",
      "epoch : 671, loss : 0.12456886, val_acc : 0.8390476190476189\n",
      "epoch : 672, loss : 0.08463251, tra_acc : 0.9654545454545456\n",
      "epoch : 672, loss : -0.06552645, val_acc : 0.8469047619047618\n",
      "epoch : 673, loss : 0.205864, tra_acc : 0.962996632996633\n",
      "epoch : 673, loss : -0.40738836, val_acc : 0.8547619047619048\n",
      "epoch : 674, loss : 0.063018344, tra_acc : 0.9654545454545453\n",
      "epoch : 674, loss : -0.63426405, val_acc : 0.8364285714285714\n",
      "epoch : 675, loss : -0.011555954, tra_acc : 0.9578114478114479\n",
      "epoch : 675, loss : 0.23593293, val_acc : 0.8285714285714286\n",
      "epoch : 676, loss : 0.07856475, tra_acc : 0.9629966329966332\n",
      "epoch : 676, loss : -0.38826695, val_acc : 0.8416666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 677, loss : 0.1705214, tra_acc : 0.9629966329966332\n",
      "epoch : 677, loss : -0.37817863, val_acc : 0.8285714285714286\n",
      "epoch : 678, loss : 0.053210497, tra_acc : 0.9605387205387204\n",
      "epoch : 678, loss : -0.70634884, val_acc : 0.8416666666666667\n",
      "epoch : 679, loss : 0.00063669885, tra_acc : 0.9620875420875422\n",
      "epoch : 679, loss : -0.33413568, val_acc : 0.8259523809523809\n",
      "epoch : 680, loss : 0.039470773, tra_acc : 0.962996632996633\n",
      "epoch : 680, loss : 0.028233727, val_acc : 0.8285714285714286\n",
      "epoch : 681, loss : 0.18621899, tra_acc : 0.962996632996633\n",
      "epoch : 681, loss : -0.4444684, val_acc : 0.8390476190476189\n",
      "epoch : 682, loss : 0.089408025, tra_acc : 0.9580808080808082\n",
      "epoch : 682, loss : -0.2371347, val_acc : 0.8442857142857143\n",
      "epoch : 683, loss : 0.17922948, tra_acc : 0.9556228956228956\n",
      "epoch : 683, loss : -1.10321, val_acc : 0.8390476190476189\n",
      "epoch : 684, loss : 0.031696506, tra_acc : 0.9605387205387206\n",
      "epoch : 684, loss : -0.21988048, val_acc : 0.8364285714285714\n",
      "epoch : 685, loss : 0.06770422, tra_acc : 0.9654545454545453\n",
      "epoch : 685, loss : -0.19117439, val_acc : 0.8390476190476192\n",
      "epoch : 686, loss : 0.15517952, tra_acc : 0.9605387205387206\n",
      "epoch : 686, loss : -0.097537495, val_acc : 0.8357142857142857\n",
      "epoch : 687, loss : 0.060440157, tra_acc : 0.9605387205387206\n",
      "epoch : 687, loss : -0.40660477, val_acc : 0.8338095238095238\n",
      "epoch : 688, loss : 0.045910355, tra_acc : 0.9654545454545453\n",
      "epoch : 688, loss : 0.8234577, val_acc : 0.8390476190476192\n",
      "epoch : 689, loss : 0.20777258, tra_acc : 0.9556228956228956\n",
      "epoch : 689, loss : -0.28691515, val_acc : 0.8442857142857143\n",
      "epoch : 690, loss : 0.046277687, tra_acc : 0.9629966329966332\n",
      "epoch : 690, loss : -0.31076697, val_acc : 0.8285714285714286\n",
      "epoch : 691, loss : 0.07694513, tra_acc : 0.962996632996633\n",
      "epoch : 691, loss : -0.6335692, val_acc : 0.8364285714285714\n",
      "epoch : 692, loss : 0.0400784, tra_acc : 0.9654545454545453\n",
      "epoch : 692, loss : 0.5336314, val_acc : 0.8442857142857143\n",
      "epoch : 693, loss : 0.041572645, tra_acc : 0.9654545454545453\n",
      "epoch : 693, loss : 0.092390895, val_acc : 0.8311904761904761\n",
      "epoch : 694, loss : -0.052943643, tra_acc : 0.962996632996633\n",
      "epoch : 694, loss : -0.2435397, val_acc : 0.8259523809523809\n",
      "epoch : 695, loss : 0.06445446, tra_acc : 0.9629966329966332\n",
      "epoch : 695, loss : -0.1441201, val_acc : 0.8364285714285714\n",
      "epoch : 696, loss : 0.12964205, tra_acc : 0.9605387205387204\n",
      "epoch : 696, loss : -0.29990983, val_acc : 0.8442857142857143\n",
      "epoch : 697, loss : 0.0042937263, tra_acc : 0.9629966329966332\n",
      "epoch : 697, loss : -0.45154938, val_acc : 0.8338095238095238\n",
      "epoch : 698, loss : 0.047182467, tra_acc : 0.962996632996633\n",
      "epoch : 698, loss : -0.0015190182, val_acc : 0.8338095238095238\n",
      "epoch : 699, loss : 0.047145292, tra_acc : 0.9654545454545456\n",
      "epoch : 699, loss : -0.10835823, val_acc : 0.8338095238095238\n",
      "epoch : 700, loss : 0.23406549, tra_acc : 0.9605387205387204\n",
      "epoch : 700, loss : 0.26029643, val_acc : 0.8338095238095238\n",
      "epoch : 701, loss : 0.031186728, tra_acc : 0.962996632996633\n",
      "epoch : 701, loss : 0.6944255, val_acc : 0.8390476190476189\n",
      "epoch : 702, loss : 0.12513581, tra_acc : 0.962996632996633\n",
      "epoch : 702, loss : -0.5116711, val_acc : 0.8442857142857143\n",
      "epoch : 703, loss : 0.17900209, tra_acc : 0.962996632996633\n",
      "epoch : 703, loss : -0.015450875, val_acc : 0.8311904761904761\n",
      "epoch : 704, loss : 0.10181724, tra_acc : 0.9654545454545456\n",
      "epoch : 704, loss : -0.07860998, val_acc : 0.8390476190476189\n",
      "epoch : 705, loss : 0.04788294, tra_acc : 0.9629966329966332\n",
      "epoch : 705, loss : -0.15498929, val_acc : 0.8469047619047618\n",
      "epoch : 706, loss : 0.1504384, tra_acc : 0.9611784511784512\n",
      "epoch : 706, loss : -0.48079887, val_acc : 0.8416666666666667\n",
      "epoch : 707, loss : 0.08900516, tra_acc : 0.9654545454545453\n",
      "epoch : 707, loss : -0.7592676, val_acc : 0.8364285714285714\n",
      "epoch : 708, loss : 0.019929113, tra_acc : 0.962996632996633\n",
      "epoch : 708, loss : -0.7557061, val_acc : 0.8416666666666667\n",
      "epoch : 709, loss : -0.003252983, tra_acc : 0.9466329966329966\n",
      "epoch : 709, loss : 1.7602497, val_acc : 0.8483333333333333\n",
      "epoch : 710, loss : 0.11458531, tra_acc : 0.9654545454545453\n",
      "epoch : 710, loss : 1.4321538, val_acc : 0.8516666666666666\n",
      "epoch : 711, loss : 0.103957534, tra_acc : 0.9654545454545453\n",
      "epoch : 711, loss : 0.8217163, val_acc : 0.8371428571428572\n",
      "epoch : 712, loss : 0.34144807, tra_acc : 0.9605387205387204\n",
      "epoch : 712, loss : 0.64304376, val_acc : 0.8345238095238096\n",
      "epoch : 713, loss : 0.04965861, tra_acc : 0.9654545454545453\n",
      "epoch : 713, loss : 0.29700157, val_acc : 0.8397619047619047\n",
      "epoch : 714, loss : 0.11972514, tra_acc : 0.9654545454545453\n",
      "epoch : 714, loss : 0.105586685, val_acc : 0.8338095238095238\n",
      "epoch : 715, loss : 0.05060436, tra_acc : 0.9620875420875422\n",
      "epoch : 715, loss : 0.27812567, val_acc : 0.850952380952381\n",
      "epoch : 716, loss : 0.048930753, tra_acc : 0.9654545454545453\n",
      "epoch : 716, loss : 0.05971289, val_acc : 0.8338095238095239\n",
      "epoch : 717, loss : 0.08708412, tra_acc : 0.9654545454545456\n",
      "epoch : 717, loss : -0.13962062, val_acc : 0.8364285714285714\n",
      "epoch : 718, loss : 0.0911053, tra_acc : 0.9663636363636363\n",
      "epoch : 718, loss : -0.25499502, val_acc : 0.8423809523809523\n",
      "epoch : 719, loss : 0.023897642, tra_acc : 0.9654545454545453\n",
      "epoch : 719, loss : 0.036476333, val_acc : 0.850952380952381\n",
      "epoch : 720, loss : 0.17805365, tra_acc : 0.9362626262626264\n",
      "epoch : 720, loss : -0.39788222, val_acc : 0.8357142857142857\n",
      "epoch : 721, loss : 0.04334463, tra_acc : 0.9636363636363636\n",
      "epoch : 721, loss : 0.31790593, val_acc : 0.8461904761904763\n",
      "epoch : 722, loss : 0.13158037, tra_acc : 0.955993265993266\n",
      "epoch : 722, loss : -0.11433544, val_acc : 0.824047619047619\n",
      "epoch : 723, loss : 0.08030585, tra_acc : 0.9645454545454545\n",
      "epoch : 723, loss : 0.5536776, val_acc : 0.8326190476190476\n",
      "epoch : 724, loss : 0.121459104, tra_acc : 0.9629966329966332\n",
      "epoch : 724, loss : 0.0894089, val_acc : 0.8416666666666667\n",
      "epoch : 725, loss : 0.06059803, tra_acc : 0.9599999999999999\n",
      "epoch : 725, loss : -3.8334744, val_acc : 0.8423809523809523\n",
      "epoch : 726, loss : 0.33438203, tra_acc : 0.9539057239057239\n",
      "epoch : 726, loss : -0.9149329, val_acc : 0.8450000000000001\n",
      "epoch : 727, loss : 0.31583902, tra_acc : 0.9596296296296297\n",
      "epoch : 727, loss : -0.9721746, val_acc : 0.8319047619047618\n",
      "epoch : 728, loss : 0.08053801, tra_acc : 0.9663636363636363\n",
      "epoch : 728, loss : -1.1142821, val_acc : 0.8416666666666667\n",
      "epoch : 729, loss : -0.016425926, tra_acc : 0.9663636363636363\n",
      "epoch : 729, loss : 0.8018982, val_acc : 0.8311904761904761\n",
      "epoch : 730, loss : 0.07136602, tra_acc : 0.963905723905724\n",
      "epoch : 730, loss : -0.8178911, val_acc : 0.8469047619047618\n",
      "epoch : 731, loss : 0.15196364, tra_acc : 0.9578114478114478\n",
      "epoch : 731, loss : -0.003684615, val_acc : 0.8469047619047618\n",
      "epoch : 732, loss : 0.0016239177, tra_acc : 0.963905723905724\n",
      "epoch : 732, loss : -0.2786152, val_acc : 0.8364285714285714\n",
      "epoch : 733, loss : 0.19374, tra_acc : 0.963905723905724\n",
      "epoch : 733, loss : 0.018371752, val_acc : 0.8502380952380952\n",
      "epoch : 734, loss : 0.16459583, tra_acc : 0.963905723905724\n",
      "epoch : 734, loss : -0.42523804, val_acc : 0.8259523809523809\n",
      "epoch : 735, loss : -0.14836638, tra_acc : 0.9614478114478114\n",
      "epoch : 735, loss : -0.05867998, val_acc : 0.8442857142857143\n",
      "epoch : 736, loss : 0.044007104, tra_acc : 0.9663636363636363\n",
      "epoch : 736, loss : -0.97218007, val_acc : 0.8311904761904761\n",
      "epoch : 737, loss : 0.020662198, tra_acc : 0.963905723905724\n",
      "epoch : 737, loss : -0.35914, val_acc : 0.8259523809523809\n",
      "epoch : 738, loss : 0.03355735, tra_acc : 0.963905723905724\n",
      "epoch : 738, loss : -0.4264554, val_acc : 0.8259523809523809\n",
      "epoch : 739, loss : -0.08026484, tra_acc : 0.9578114478114479\n",
      "epoch : 739, loss : -0.25242484, val_acc : 0.8311904761904761\n",
      "epoch : 740, loss : -0.023721067, tra_acc : 0.9639057239057238\n",
      "epoch : 740, loss : 0.18224259, val_acc : 0.8338095238095239\n",
      "epoch : 741, loss : -0.06370361, tra_acc : 0.9562626262626264\n",
      "epoch : 741, loss : -0.1399843, val_acc : 0.8311904761904761\n",
      "epoch : 742, loss : 0.12802544, tra_acc : 0.963905723905724\n",
      "epoch : 742, loss : -0.10981727, val_acc : 0.8364285714285714\n",
      "epoch : 743, loss : 0.049918365, tra_acc : 0.963905723905724\n",
      "epoch : 743, loss : -0.4921863, val_acc : 0.8338095238095239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 744, loss : 0.16524118, tra_acc : 0.963905723905724\n",
      "epoch : 744, loss : -0.010154049, val_acc : 0.8390476190476189\n",
      "epoch : 745, loss : 0.05840172, tra_acc : 0.9663636363636363\n",
      "epoch : 745, loss : -0.36797032, val_acc : 0.8469047619047618\n",
      "epoch : 746, loss : -0.0016568283, tra_acc : 0.963905723905724\n",
      "epoch : 746, loss : 0.7981369, val_acc : 0.8338095238095238\n",
      "epoch : 747, loss : 0.04584009, tra_acc : 0.9589898989898991\n",
      "epoch : 747, loss : 0.031410098, val_acc : 0.8423809523809523\n",
      "epoch : 748, loss : 0.12247815, tra_acc : 0.963905723905724\n",
      "epoch : 748, loss : 0.23670013, val_acc : 0.8364285714285714\n",
      "epoch : 749, loss : 0.04208955, tra_acc : 0.9663636363636363\n",
      "epoch : 749, loss : -0.10849481, val_acc : 0.8442857142857143\n",
      "epoch : 750, loss : 0.073551826, tra_acc : 0.963905723905724\n",
      "epoch : 750, loss : -0.59520096, val_acc : 0.8364285714285714\n",
      "epoch : 751, loss : 0.06611803, tra_acc : 0.963905723905724\n",
      "epoch : 751, loss : -1.2722102, val_acc : 0.8338095238095239\n",
      "epoch : 752, loss : -0.030426264, tra_acc : 0.9620875420875422\n",
      "epoch : 752, loss : 0.6485428, val_acc : 0.8364285714285714\n",
      "epoch : 753, loss : 0.19098555, tra_acc : 0.9639057239057238\n",
      "epoch : 753, loss : -0.36807558, val_acc : 0.8416666666666667\n",
      "epoch : 754, loss : 0.02665375, tra_acc : 0.9611784511784512\n",
      "epoch : 754, loss : -0.09799015, val_acc : 0.8338095238095238\n",
      "epoch : 755, loss : -0.03152652, tra_acc : 0.963905723905724\n",
      "epoch : 755, loss : 0.08493685, val_acc : 0.8364285714285714\n",
      "epoch : 756, loss : 0.04259762, tra_acc : 0.9663636363636364\n",
      "epoch : 756, loss : 0.33449602, val_acc : 0.8364285714285714\n",
      "epoch : 757, loss : 0.03561968, tra_acc : 0.963905723905724\n",
      "epoch : 757, loss : 0.05310623, val_acc : 0.8469047619047618\n",
      "epoch : 758, loss : 0.085620396, tra_acc : 0.9663636363636363\n",
      "epoch : 758, loss : -0.20180897, val_acc : 0.8442857142857143\n",
      "epoch : 759, loss : 0.20009464, tra_acc : 0.963905723905724\n",
      "epoch : 759, loss : -1.0022829, val_acc : 0.8390476190476192\n",
      "epoch : 760, loss : 0.034275994, tra_acc : 0.9611784511784512\n",
      "epoch : 760, loss : 0.09271964, val_acc : 0.8311904761904761\n",
      "epoch : 761, loss : 0.069644384, tra_acc : 0.9663636363636363\n",
      "epoch : 761, loss : -0.21140234, val_acc : 0.8442857142857143\n",
      "epoch : 762, loss : 0.039157674, tra_acc : 0.9614478114478114\n",
      "epoch : 762, loss : -0.7510986, val_acc : 0.8207142857142857\n",
      "epoch : 763, loss : 0.013599496, tra_acc : 0.9636363636363636\n",
      "epoch : 763, loss : 0.524301, val_acc : 0.8423809523809523\n",
      "epoch : 764, loss : 0.07242149, tra_acc : 0.9663636363636363\n",
      "epoch : 764, loss : 0.2876954, val_acc : 0.8364285714285714\n",
      "epoch : 765, loss : 0.062241174, tra_acc : 0.9639057239057238\n",
      "epoch : 765, loss : -0.013233781, val_acc : 0.8371428571428572\n",
      "epoch : 766, loss : 0.057936493, tra_acc : 0.9663636363636364\n",
      "epoch : 766, loss : -0.31898078, val_acc : 0.8416666666666667\n",
      "epoch : 767, loss : 0.13816793, tra_acc : 0.963905723905724\n",
      "epoch : 767, loss : 0.24524778, val_acc : 0.8364285714285714\n",
      "epoch : 768, loss : 0.10748232, tra_acc : 0.9663636363636363\n",
      "epoch : 768, loss : -0.80934924, val_acc : 0.8285714285714286\n",
      "epoch : 769, loss : -0.009747949, tra_acc : 0.9663636363636364\n",
      "epoch : 769, loss : 0.54506, val_acc : 0.8371428571428572\n",
      "epoch : 770, loss : 0.04327333, tra_acc : 0.9663636363636363\n",
      "epoch : 770, loss : -0.10841528, val_acc : 0.8338095238095238\n",
      "epoch : 771, loss : 0.12825423, tra_acc : 0.963905723905724\n",
      "epoch : 771, loss : 0.17943709, val_acc : 0.8364285714285714\n",
      "epoch : 772, loss : 0.20238338, tra_acc : 0.9614478114478113\n",
      "epoch : 772, loss : -0.18357126, val_acc : 0.8338095238095238\n",
      "epoch : 773, loss : 0.18341175, tra_acc : 0.9614478114478114\n",
      "epoch : 773, loss : -0.6563972, val_acc : 0.8371428571428572\n",
      "epoch : 774, loss : 0.03032086, tra_acc : 0.9636363636363636\n",
      "epoch : 774, loss : 0.09830916, val_acc : 0.8397619047619047\n",
      "epoch : 775, loss : 0.07065192, tra_acc : 0.9663636363636364\n",
      "epoch : 775, loss : 0.26998088, val_acc : 0.8423809523809523\n",
      "epoch : 776, loss : 0.04722573, tra_acc : 0.9629966329966332\n",
      "epoch : 776, loss : 0.2403297, val_acc : 0.8416666666666667\n",
      "epoch : 777, loss : 0.09471276, tra_acc : 0.9663636363636363\n",
      "epoch : 777, loss : -0.164132, val_acc : 0.8364285714285714\n",
      "epoch : 778, loss : 0.07917957, tra_acc : 0.963905723905724\n",
      "epoch : 778, loss : 0.05240385, val_acc : 0.8233333333333333\n",
      "epoch : 779, loss : 0.010617719, tra_acc : 0.9605387205387206\n",
      "epoch : 779, loss : -0.4617174, val_acc : 0.8495238095238097\n",
      "epoch : 780, loss : 0.087787054, tra_acc : 0.9663636363636364\n",
      "epoch : 780, loss : 0.15419054, val_acc : 0.8416666666666667\n",
      "epoch : 781, loss : 0.0786241, tra_acc : 0.963905723905724\n",
      "epoch : 781, loss : -0.37925544, val_acc : 0.8416666666666667\n",
      "epoch : 782, loss : 0.15630499, tra_acc : 0.9614478114478114\n",
      "epoch : 782, loss : -0.25941357, val_acc : 0.8423809523809523\n",
      "epoch : 783, loss : -0.29298565, tra_acc : 0.9614478114478117\n",
      "epoch : 783, loss : -0.5754191, val_acc : 0.8285714285714286\n",
      "epoch : 784, loss : 0.018247241, tra_acc : 0.9614478114478114\n",
      "epoch : 784, loss : 0.16419935, val_acc : 0.8266666666666667\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-5b50f3175314>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmachine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-85e7236959a5>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# load training images of the batch size for every iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;31m# inputs is the images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.7.3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.7.3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.7.3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.7.3/lib/python3.7/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[1;32m    137\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.7.3/lib/python3.7/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.7.3/lib/python3.7/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.7.3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    932\u001b[0m         \"\"\"\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.7.3/lib/python3.7/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "machine.training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "machine.show_loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "machine.show_acc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
