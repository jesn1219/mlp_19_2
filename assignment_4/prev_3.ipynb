{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSubmitter : JESOON KANG, 20170937 Dept.of CSE\\n\\nData : 2019. 10. 9\\n\\nAssignment 3.\\n\\n\\n\\nBinary classification based on 3 layers neural network\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assignment 3 file initialize\n",
    "\n",
    "'''\n",
    "Submitter : JESOON KANG, 20170937 Dept.of CSE\n",
    "\n",
    "Data : 2019. 10. 9\n",
    "\n",
    "Assignment 3.\n",
    "\n",
    "\n",
    "\n",
    "Binary classification based on 3 layers neural network\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Section 1. #### This Section is bringed Data_import_ex.py file.\n",
    "\n",
    "# Image Data import & resize\n",
    "\n",
    "transform = transforms.Compose([#transforms.Resize((256,256)),  \n",
    "                                transforms.Grayscale(),\t\t# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "                                transforms.ToTensor(),])\n",
    "\n",
    "#train_data_path = 'relative path of training data set'\n",
    "train_data_path = '../data/horse-or-human/train'\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "# if shuffle=True, the data reshuffled at every epoch \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=False, num_workers=1)  \n",
    "\n",
    "\n",
    "validation_data_path = '../data/horse-or-human/validation'\n",
    "valset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=1, shuffle=False, num_workers=1)  \n",
    "\n",
    "#### Section 1 END ####\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Section 2 START ####\n",
    "# This Part includes Sigmoid, Hypothesis, Loss, Predict Functions\n",
    "\n",
    "# sigmoid Function.\n",
    "def sigmoid(z) :\n",
    "    return 1 / (1 + math.e ** -z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict Function. if h(x) returns >=0.5, set to 1. other cases, set to 0.\n",
    "def predict(h, labels) :\n",
    "    mount = len(h)\n",
    "    correct = 0\n",
    "    \n",
    "    for i in range(0,mount) :\n",
    "        if h[i] >= 0.5 :\n",
    "            if labels[i] == 1 :\n",
    "                correct +=1\n",
    "        else :\n",
    "            if labels[i] == 0 :\n",
    "                correct +=1\n",
    "    return correct * (1/mount)\n",
    "\n",
    "#### Section 2 END ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Section 3 START ####\n",
    "# Section 3 includes Data Pre-processing. ReDesign datasets to easy calculate\n",
    "\n",
    "# Data reconstruct. vectorize\n",
    "\n",
    "# Each Image file will be stored shape of a row\n",
    "training_vectorized = []\n",
    "training_labels = []\n",
    "\n",
    "validation_vectorized = []\n",
    "validation_labels = []\n",
    "\n",
    "\n",
    "# Training data vectorizing\n",
    "for i, data in enumerate(trainloader) :\n",
    "    train_data = []\n",
    "    inputs, labels = data\n",
    "\n",
    "    for u in inputs :\n",
    "        for col in u[0] :\n",
    "            train_data += list(col)\n",
    "    training_vectorized.append(train_data)\n",
    "    training_labels.append([labels])\n",
    "\n",
    "training_vectorized = np.array(training_vectorized)\n",
    "training_labels = np.array(training_labels)\n",
    "\n",
    "# Validation data vectorizing\n",
    "for i, data in enumerate(valloader) :\n",
    "    val_data = []\n",
    "    inputs, labels = data\n",
    "    for u in inputs :\n",
    "        for col in u[0] :\n",
    "            val_data += list(col)\n",
    "    validation_vectorized.append(val_data)\n",
    "    validation_labels.append([labels])\n",
    "validation_vectorized = np.array(validation_vectorized)\n",
    "validation_labels = np.array(validation_labels)\n",
    "\n",
    "#### Section 3 END ####\n",
    "\n",
    "\n",
    "# log variables setting : to record statements\n",
    "log_training_loss = []\n",
    "log_validation_loss = []\n",
    "log_iter = []\n",
    "log_training_acc = []\n",
    "log_validation_acc = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Section 4 START ####\n",
    "# This Part includes declaring variables which will be used in train & predict & result visualization\n",
    "\n",
    "# Initial Weight Value\n",
    "\n",
    "\n",
    "input_X = training_vectorized\n",
    "target_Y = training_labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/var/pyenv/versions/3.7.3/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in power\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[353.67953026]\n",
      "Loss:  [253.77690125]\n",
      "                     Acc :  0.48490749756572543\n",
      "110\n",
      "Loss:  10.097370983446933\n",
      "                     Acc :  0.48685491723466406\n",
      "110\n",
      "Loss:  10.097370983446933\n",
      "                     Acc :  0.48685491723466406\n",
      "110\n",
      "Loss:  10.097370983446933\n",
      "                     Acc :  0.48685491723466406\n",
      "110\n",
      "Loss:  10.097370983446933\n",
      "                     Acc :  0.48685491723466406\n",
      "110\n",
      "Loss:  10.097370983446933\n",
      "                     Acc :  0.48685491723466406\n",
      "110\n",
      "Loss:  10.097370983446933\n",
      "                     Acc :  0.48685491723466406\n"
     ]
    }
   ],
   "source": [
    "def get_acc_of_list(yhat,target_Y) :\n",
    "    count = 0\n",
    "    for a,b in zip(yhat,target_Y) :\n",
    "        if (a >= 0.5) :\n",
    "            if b == 1 :\n",
    "                count +=1\n",
    "        else :\n",
    "            if b == 0 :\n",
    "                count +=1\n",
    "    return count / len(yhat)\n",
    "def is_correct(yhat,t) :\n",
    "    if yhat >= 0.5 :\n",
    "        if t == 1 :\n",
    "            return 1\n",
    "        else :\n",
    "            return 0\n",
    "    else :\n",
    "        if t == 0 :\n",
    "            return 1\n",
    "        else :\n",
    "            return 0 \n",
    "            \n",
    "def get_loss(yhat,t) :\n",
    "    \n",
    "    return -(t/yhat - (1-t)/(1-yhat))\n",
    "    #return ((-t+0.1) * np.log(yhat+0.1) - (1-t+0.1) * np.log(1-yhat+0.1))\n",
    "\n",
    "def sigmoid_der(x) :\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "\n",
    "def get_error(yhat,t) :\n",
    "    return 0.5* ((t-yhat)**2)\n",
    "\n",
    "u = np.zeros((10000,50))\n",
    "v = np.zeros((50,10))\n",
    "w = np.zeros((10,1))\n",
    "a = np.ones((50,1))\n",
    "b = np.ones((10,1))\n",
    "c = np.ones((1,1))\n",
    "\n",
    "# Learning rate \n",
    "learning_rate = 0.01\n",
    "log_loss = []\n",
    "log_acc = []\n",
    "log_iter = p\n",
    "def propagate(input_X,target_Y,u,v,w,a,b,c, num_epoch) :\n",
    "\n",
    "    \n",
    "    data_size = len(input_X)\n",
    "    prev_loss = 0.0\n",
    "    \n",
    "    for i in range(0,num_epoch) :\n",
    "        Loss_epoch = 10\n",
    "        yhat_list = []\n",
    "        acc = []\n",
    "        for x,t in zip(input_X,target_Y) :\n",
    "            x = x.reshape((10000,1))\n",
    "            z_1 = np.dot(u.T,x) + a\n",
    "            out_1 = sigmoid(z_1) # 150,1\n",
    "\n",
    "            z_2 = np.dot(v.T,out_1) + b\n",
    "            out_2 = sigmoid(z_2) # 50,1\n",
    "\n",
    "            z_3 = np.dot(w.T,out_2) + c\n",
    "            #print(np.sum(z_3))\n",
    "            yhat = sigmoid(np.sum(z_3))\n",
    "            #print(yhat)\n",
    "            yhat_list.append(yhat)\n",
    "            acc.append(is_correct(yhat,t))\n",
    "\n",
    "\n",
    "            # BackPropagation. Gradient Decent Calculate\n",
    "            \n",
    "            error_3 = -(np.divide(t,yhat) - np.divide(1-t, 1-yhat))\n",
    "            \n",
    "            d_z_3 = error_3 * sigmoid_der(z_3)\n",
    "            d_w_3 = np.matmul(d_z_3, out_2.T) / out_2.shape[1]\n",
    "            d_b_3 = np.sum(d_z_3,keepdims=True,axis=1) / out_2.shape[1]\n",
    "            \n",
    "            error_2 = np.matmul(w,d_z_3)\n",
    "            \n",
    "            d_z_2 = error_2* sigmoid_der(z_2)\n",
    "            d_w_2 = np.matmul(d_z_2,out_1.T) / out_1.shape[1]\n",
    "            d_b_2 = np.sum(d_z_2, axis=1, keepdims=True) / out_1.shape[1]\n",
    "            \n",
    "            error_1 = np.matmul(v,d_z_2)\n",
    "            \n",
    "            d_z_1 = error_1 * sigmoid_der(z_1)\n",
    "            d_w_1 = np.matmul(d_z_1,x.T) / x.shape[1]\n",
    "            d_b_1 = np.sum(d_z_1, axis=1, keepdims=True) / x.shape[1]\n",
    "            \n",
    "            \n",
    "            \n",
    "            w = w - learning_rate* d_w_3\n",
    "            c = c - d_b_3\n",
    "            \n",
    "            v = v - learning_rate* d_w_2.T\n",
    "            b = b - d_b_2\n",
    "            \n",
    "            u = u - learning_rate*np.dot(x,z_1.T)\n",
    "            \n",
    "      \n",
    "            #print(get_loss(yhat,t))\n",
    "            tmp = get_loss(yhat,t)\n",
    "            if not math.isnan(tmp) :\n",
    "                Loss_epoch = Loss_epoch + get_loss(yhat,t)\n",
    "            #print(get_loss(yhat,t))\n",
    "        print(Loss_epoch+100)\n",
    "        print(\"Loss: \", Loss_epoch+100/data_size)\n",
    "        \n",
    "        print(\"                     Acc : \", np.array(acc).mean())\n",
    "        log_loss.append(Loss_epoch/data_size)\n",
    "        log_acc.append(np.array(acc).mean())\n",
    "    print(\"Complete\")\n",
    "    \n",
    "propagate(input_X,target_Y,u,v,w,a,b,c,50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Section 5 ####\n",
    "# Data Visualization\n",
    "\n",
    "\n",
    "t1 = plt.plot(log_iter,log_training_loss, color='orange',label='Training Loss')\n",
    "t2 = plt.plot(log_iter,log_validation_loss, color= 'red',label='Validation Loss')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend(['Training Loss','Validation Loss'])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = plt.plot(log_iter,log_training_acc, color='orange',label='Training Acc')\n",
    "t2 = plt.plot(log_iter,log_validation_acc, color= 'red',label='Validation Acc')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(['Training Acc','Validation Acc'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
