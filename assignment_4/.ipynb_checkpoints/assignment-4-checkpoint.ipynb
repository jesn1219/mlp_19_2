{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "\n",
    "Submitter : JESOON KANG, 20170937\n",
    "Date : 2019. 10. \n",
    "\n",
    "\n",
    "    Assignment 4. \n",
    "\n",
    "-   -\n",
    "\n",
    "\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchvision\n",
    "import os\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict Function. if h(x) returns >=0.5, set to 1. other cases, set to 0.\n",
    "def predict(h, labels) :\n",
    "    mount = len(h)\n",
    "    correct = 0\n",
    "    \n",
    "    for i in range(0,mount) :\n",
    "        if h[i] >= 0.5 :\n",
    "            if labels[i] == 1 :\n",
    "                correct +=1\n",
    "        else :\n",
    "            if labels[i] == 0 :\n",
    "                correct +=1\n",
    "    return correct * (1/mount)\n",
    "\n",
    "#### Section 2 END ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Section 1. #### This Section is bringed Data_import_ex.py file.\n",
    "\n",
    "# Image Data import & resize\n",
    "\n",
    "transform = transforms.Compose([#transforms.Resize((256,256)),  \n",
    "                                transforms.Grayscale(),\t\t# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "                                transforms.ToTensor(),])\n",
    "\n",
    "#train_data_path = 'relative path of training data set'\n",
    "train_data_path = '../data/horse-or-human/train'\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "# if shuffle=True, the data reshuffled at every epoch \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=True, num_workers=0)  \n",
    "\n",
    "\n",
    "validation_data_path = '../data/horse-or-human/validation'\n",
    "valset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=1, shuffle=False, num_workers=0)  \n",
    "\n",
    "#### Section 1 END ####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set is loaded\n"
     ]
    }
   ],
   "source": [
    "#### Section 3 START ####\n",
    "# Section 3 includes Data Pre-processing. ReDesign datasets to easy calculate\n",
    "\n",
    "# Data reconstruct. vectorize\n",
    "\n",
    "# Each Image file will be stored shape of a row\n",
    "training_vectorized = []\n",
    "training_labels = []\n",
    "\n",
    "\n",
    "tmp = 0\n",
    "# Training data vectorizing\n",
    "for i, data in enumerate(trainloader) :\n",
    "    train_data = []\n",
    "    inputs, labels = data\n",
    "#    print(tmp)\n",
    "    tmp += 1\n",
    "    for u in inputs :\n",
    "        for col in u[0] :\n",
    "            train_data += list(col)\n",
    "    training_vectorized.append(train_data)\n",
    "    training_labels.append([labels])\n",
    "\n",
    "training_vectorized = torch.Tensor(training_vectorized)\n",
    "training_labels = torch.Tensor(training_labels)\n",
    "print(\"train set is loaded\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1216, 0.1137, 0.2235,  ..., 0.6157, 0.6196, 0.5882],\n",
      "        [0.7647, 0.7608, 0.7608,  ..., 0.7569, 0.7647, 0.7686],\n",
      "        [0.2549, 0.3333, 0.3725,  ..., 0.5373, 0.5020, 0.5098],\n",
      "        ...,\n",
      "        [0.7412, 0.7373, 0.7373,  ..., 0.7137, 0.7137, 0.6941],\n",
      "        [0.7569, 0.7608, 0.7647,  ..., 0.3529, 0.4510, 0.4784],\n",
      "        [0.7412, 0.7647, 0.8157,  ..., 0.1529, 0.1882, 0.1882]])\n"
     ]
    }
   ],
   "source": [
    "print(training_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "validation_vectorized = []\n",
    "validation_labels = []\n",
    "\n",
    "# Validation data vectorizing\n",
    "for i, data in enumerate(valloader) :\n",
    "    val_data = []\n",
    "    inputs, labels = data\n",
    "    for u in inputs :\n",
    "        for col in u[0] :\n",
    "            val_data += list(col)\n",
    "    validation_vectorized.append(val_data)\n",
    "    validation_labels.append([labels])\n",
    "validation_vectorized = torch.Tensor(validation_vectorized)\n",
    "validation_labels = torch.Tensor(validation_labels)\n",
    "\n",
    "#### Section 3 END ####\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "        ...,\n",
      "        [1.0000, 1.0000, 1.0000,  ..., 0.9961, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000,  ..., 0.9961, 0.9961, 0.9961],\n",
      "        [1.0000, 1.0000, 1.0000,  ..., 0.9961, 0.9961, 0.9961]])\n"
     ]
    }
   ],
   "source": [
    "print(validation_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sigmoid Function.\n",
    "def sigmoid(z) :\n",
    "    return 1 / (1 + torch.pow(math.e,-z/100))\n",
    "\n",
    "def get_activation(z,type) :\n",
    "    if (type == 0) :\n",
    "        return sigmoid(z)\n",
    "    else :\n",
    "        print(\"Error, get_activation\")\n",
    "        return 0\n",
    "\n",
    "def get_derv_activation(z,type) :\n",
    "    if (type == 0) :\n",
    "        return sigmoid(z)*(1-sigmoid(z))\n",
    "    else :\n",
    "        print(\"Error, get_derv_activation\")\n",
    "        return 0                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# log variables setting : to record statements\n",
    "log_training_loss = []                                                                                                                                                                                  \n",
    "log_validation_loss = []                                                                                                                                                                                                                                                                                                                                                                                       \n",
    "log_training_acc = []\n",
    "log_validation_acc = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(y,a) :\n",
    "    #print(y,a)\n",
    "    ret = -(torch.div(y,a) - torch.div(1-y,1-a))\n",
    "    \n",
    "    return ret\n",
    "\n",
    "\n",
    "class ML :\n",
    "    def __init__(self,t_data,t_yh,v_data,v_yh,L1_size,L2_size,L3_size,activation_type,lr) :\n",
    "        self.t_data = t_data\n",
    "        self.t_data_size = self.t_data.shape[0]\n",
    "        self.feature_size = self.t_data.shape[1]\n",
    "        self.t_yh = t_yh\n",
    "        self.v_data = v_data\n",
    "        self.v_yh = v_yh\n",
    "        self.l1_size = L1_size\n",
    "        self.l2_size = L2_size\n",
    "        self.l3_size = L3_size\n",
    "        self.batch_size = 256\n",
    "        self.t_batch_idx = 0\n",
    "        self.epoch = 0\n",
    "        self.lr = lr\n",
    "        self.act_type = activation_type\n",
    "        self.init_weights()\n",
    "        \n",
    "        print(\"ML Object initialized\")\n",
    "        self.iter = 0\n",
    "        \n",
    "\n",
    "    def get_training_batch(self) :\n",
    "        self.idx_1 = self.t_batch_idx * self.batch_size\n",
    "        self.idx_2 = self.idx_1 + self.batch_size\n",
    "        self.idx_3 = 0\n",
    "        if self.idx_2 > self.t_data_size :\n",
    "            #print(self.idx_1,self.idx_2,self.idx_3)\n",
    "            self.idx_3 = self.idx_2 - self.t_data_size\n",
    "            self.idx_2 = self.t_data_size\n",
    "            \n",
    "            tmp_tensor = self.t_data[self.idx_1:self.idx_2].clone().detach()\n",
    "            tmp_tensor_2 = self.t_data[0:self.idx_3].clone().detach()\n",
    "            \n",
    "            \n",
    "            ret = torch.cat((tmp_tensor,tmp_tensor_2),0)\n",
    "            \n",
    "            if (ret.shape[0] != self.batch_size) :\n",
    "                print(\"ERROR at get batch, %s\"%(ret.shape[1]))\n",
    "            self.t_batch_idx = 0\n",
    "            self.epoch += 1\n",
    "        else :\n",
    "            self.t_batch_idx += 1\n",
    "            ret = self.t_data[self.idx_1:self.idx_2].clone().detach()\n",
    "\n",
    "        \n",
    "        return ret\n",
    "    def get_t_yh_batch(self) :\n",
    "        if self.idx_3 == 0 :\n",
    "            ret = self.t_yh[self.idx_1:self.idx_2].clone().detach()\n",
    "        else :\n",
    "            tmp_tensor = self.t_yh[self.idx_1:self.idx_2].clone().detach()\n",
    "            tmp_tensor_2 = self.t_yh[0:self.idx_3].clone().detach()\n",
    "            \n",
    "            ret = torch.cat((tmp_tensor,tmp_tensor_2),0)\n",
    "        return ret\n",
    "\n",
    "    \n",
    "    def init_weights(self) :\n",
    "        self.w_1 = torch.FloatTensor(self.l1_size,self.feature_size).uniform_(-1,1)\n",
    "        self.b_1 = torch.FloatTensor(self.batch_size,1).uniform_(-1,1)\n",
    "        \n",
    "        #torch.FloatTensor(a, b).uniform_(r1, r2)\n",
    "        \n",
    "        self.w_2 = torch.FloatTensor(self.l2_size,self.l1_size).uniform_(-1,1)\n",
    "        self.b_2 = torch.FloatTensor(self.batch_size,1).uniform_(-1,1)\n",
    "\n",
    "        self.w_3 = torch.FloatTensor(self.l3_size,self.l2_size).uniform_(-1,1)\n",
    "        self.b_3 = torch.FloatTensor(self.batch_size,1).uniform_(-1,1)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def training(self) :\n",
    "    \n",
    "        while(True) :\n",
    "            self.t_data_batch = self.get_training_batch()\n",
    "            self.z_1 = torch.matmul(self.t_data_batch,self.w_1.T) + self.b_1\n",
    "            \n",
    "            self.a_1 = get_activation(self.z_1,self.act_type)\n",
    "            \n",
    "            \n",
    "            self.z_2 = torch.matmul(self.a_1,self.w_2.T) + self.b_2\n",
    "            self.a_2 = get_activation(self.z_2,self.act_type) # 1027 x 50\n",
    "\n",
    "            self.z_3 = torch.matmul(self.a_2,self.w_3.T) + self.b_3\n",
    "            self.a_3 = get_activation(self.z_3,self.act_type) # 1027 x 1\n",
    "\n",
    "            self.t_yh_batch = self.get_t_yh_batch()\n",
    "\n",
    "            acc = self.get_acc(self.a_3,self.t_yh_batch)\n",
    "            \n",
    "\n",
    "            print(\"iter : %s, epoch : %s, loss : %s, acc : %s\"%(self.iter,self.epoch,0,acc))\n",
    "\n",
    "            self.update_weights(self.t_yh_batch,self.a_3)\n",
    "            print(np.array(get_loss(self.t_yh_batch, self.a_3)).mean())\n",
    "            self.validation()\n",
    "            #break\n",
    "            if self.epoch > 1000000 :\n",
    "                break\n",
    "    \n",
    "    def validation(self) :\n",
    "        self.v_data_batch = self.v_data\n",
    "        self.v_yh_batch = self.v_yh\n",
    "        \n",
    "        self.z_1 = torch.matmul(self.v_data_batch,self.w_1.T) + self.b_1\n",
    "        self.a_1 = get_activation(self.z_1,self.act_type) # Activation 함수 적용\n",
    "        self.z_2 = torch.matmul(self.a_1,self.w_2.T) + self.b_2\n",
    "        self.a_2 = get_activation(self.z_2,self.act_type) # Activation 함수 적용\n",
    "        self.z_3 = torch.matmul(self.a_2,self.w_3.T) + self.b_3\n",
    "        self.a_3 = get_activation(self.z_3,self.act_type) # y^과 같음\n",
    "        \n",
    "        \n",
    "        \n",
    "        acc = self.get_acc(self.a_3,self.v_yh_batch)\n",
    "        print(\"val acc : %s\"%(acc))\n",
    "    \n",
    "        \n",
    "    def update_weights(self,t_y,a_3) :\n",
    "        #print(\"t_y:\",t_y,\"z_3\",z_3)\n",
    "        error_wb3 = -(torch.div(t_y,a_3) - torch.div(1-t_y,1-a_3))\n",
    "        d_a_3 = error_wb3*get_derv_activation(self.a_3,self.act_type) #         \n",
    "        d_w_3 = torch.matmul(d_a_3,self.a_2.T)\n",
    "        d_b_3 = torch.sum(d_a_3, dim=1, keepdim=True) / self.a_3.shape[1]\n",
    "        \n",
    "        #########\n",
    "        \n",
    "        error_wb2 = torch.matmul(d_a_3,self.w_3)\n",
    "        \n",
    "        d_a_2 = error_wb2*get_derv_activation(self.a_2,self.act_type)\n",
    "        \n",
    "        d_w_2 = torch.matmul(d_a_2.T,self.a_1)\n",
    "        d_b_2 = torch.sum(d_a_2, dim=1,keepdims=True) / self.a_2.shape[1]\n",
    "        \n",
    "   \n",
    "        error_wb1 = torch.matmul(d_a_2,self.w_2)\n",
    "        d_a_1 = error_wb1*get_derv_activation(self.a_1,self.act_type)\n",
    "        d_w_1 = torch.matmul(d_a_1.T,self.t_data_batch)\n",
    "        d_b_1 = torch.sum(d_a_1, dim=1,keepdims=True) / self.a_1.shape[1]\n",
    "        \n",
    "        self.w_3 += -self.lr*d_w_3\n",
    "        self.b_3 += -self.lr*d_b_3\n",
    "        \n",
    "        self.w_2 += -self.lr*d_w_2\n",
    "        self.b_2 += -self.lr*d_b_2\n",
    "        self.w_1 += -self.lr*d_w_1\n",
    "        self.b_1 += -self.lr*d_b_1\n",
    "        #print(b_3,b_2,b_1)\n",
    "        \n",
    "    def get_acc(self,yhat,y) :\n",
    "        count = 0\n",
    "        \n",
    "        for a,b in zip(yhat,y) :\n",
    "            if a >= 0.5 :\n",
    "                if b == 1 :\n",
    "                    count+=1\n",
    "            else :\n",
    "                if b == 0:\n",
    "                    count +=1\n",
    "        \n",
    "        return count / len(yhat)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1027, 10000]) torch.Size([1027, 1]) torch.Size([256, 10000]) torch.Size([256, 1])\n",
      "ML Object initialized\n"
     ]
    }
   ],
   "source": [
    "t_data = torch.FloatTensor(training_vectorized)\n",
    "t_yh = torch.FloatTensor(training_labels)\n",
    "v_data = torch.FloatTensor(validation_vectorized)\n",
    "v_yh = torch.FloatTensor(validation_labels)\n",
    "print(t_data.shape,t_yh.shape,v_data.shape,v_yh.shape)\n",
    "\n",
    "activation_type = 0 # 0 = sigmoid\n",
    "learningRate = 0.1\n",
    "machine = ML(t_data,t_yh,v_data,v_yh, 100,50,1,0,learningRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter : 0, epoch : 0, loss : 0, acc : 0.53125\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [256 x 1], m2: [50 x 256] at ../aten/src/TH/generic/THTensorMath.cpp:752",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-289-5b50f3175314>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmachine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-287-2275d7974e7b>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iter : %s, epoch : %s, loss : %s, acc : %s\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_yh_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_yh_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-287-2275d7974e7b>\u001b[0m in \u001b[0;36mupdate_weights\u001b[0;34m(self, t_y, a_3)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0merror_wb3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma_3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0md_a_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_wb3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mget_derv_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma_3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0md_w_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_a_3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0md_b_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_a_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [256 x 1], m2: [50 x 256] at ../aten/src/TH/generic/THTensorMath.cpp:752"
     ]
    }
   ],
   "source": [
    "machine.training()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
