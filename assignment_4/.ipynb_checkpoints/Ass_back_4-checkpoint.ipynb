{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "\n",
    "Submitter : JESOON KANG, 20170937\n",
    "Date : 2019. 10. \n",
    "\n",
    "\n",
    "    Assignment 4. \n",
    "\n",
    "-   -\n",
    "\n",
    "\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchvision\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Section 1. #### This Section is bringed Data_import_ex.py file.\n",
    "\n",
    "# Image Data import & resize\n",
    "\n",
    "transform = transforms.Compose([#transforms.Resize((256,256)),  \n",
    "                                transforms.Grayscale(),\t\t# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "                                transforms.ToTensor(),])\n",
    "\n",
    "#train_data_path = 'relative path of training data set'\n",
    "train_data_path = '../data/horse-or-human/train'\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "# if shuffle=True, the data reshuffled at every epoch \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=0)  \n",
    "\n",
    "\n",
    "validation_data_path = '../data/horse-or-human/validation'\n",
    "valset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=100, shuffle=True, num_workers=0)  \n",
    "\n",
    "#### Section 1 END ####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sigmoid Function.\n",
    "def sigmoid(z) :\n",
    "    return 1 / (1 + torch.pow(math.e,-z)+0.000001)\n",
    "\n",
    "def tanh(z) :\n",
    "    ret = (2 / (1 + torch.pow(math.e,-2*z) + 0.000001)) - 1\n",
    "    return ret\n",
    "\n",
    "def derv_tanh(z) :\n",
    "    ret = (1 - (tanh(z)**2))\n",
    "    return ret\n",
    "\n",
    "def relu(z) :\n",
    "    ret = z.clone().detach()\n",
    "    #print(ret)\n",
    "    tmp = torch.zeros_like(ret)\n",
    "    ret = torch.where(ret<=0,tmp,ret)\n",
    "    return ret\n",
    "                                                                  \n",
    "def derv_relu(z) :\n",
    "    ret = z.clone().detach()\n",
    "    tmp_1 = torch.zeros_like(ret)\n",
    "    tmp_2 = torch.ones_like(ret)\n",
    "    ret = torch.where(ret<0,tmp_1,tmp_2)\n",
    "    #print(ret)\n",
    "    return ret\n",
    "    \n",
    "            \n",
    "def leakly_relu(z) :\n",
    "    ret = z.clone().detach()\n",
    "    tmp1 = torch.ones_like(ret)\n",
    "    ret = torch.where(ret<0,ret*0.01,ret)\n",
    "    return ret\n",
    "\n",
    "def derv_leakly_relu(z) :\n",
    "    ret = z.clone().detach()\n",
    "    tmp1 = torch.ones_like(ret)\n",
    "    ret = torch.where(ret<0, tmp1*0.01,tmp1)\n",
    "    \n",
    "    return ret\n",
    "\n",
    "def get_activation(z,type) :\n",
    "    if (type == 0) :\n",
    "        return sigmoid(z)\n",
    "    elif (type == 1) :\n",
    "        return tanh(z)\n",
    "    elif (type == 2) :\n",
    "        return relu(z)\n",
    "    elif (type == 3) :\n",
    "        return leakly_relu(z)\n",
    "    \n",
    "    else :\n",
    "        print(\"Error, get_activation\")\n",
    "        return 0\n",
    "\n",
    "def get_derv_activation(z,type) :\n",
    "    if (type == 0) :\n",
    "        return sigmoid(z)*(1-sigmoid(z))\n",
    "    elif (type == 1) :\n",
    "        return derv_tanh(z)\n",
    "    elif (type == 2) :\n",
    "        return derv_relu(z)\n",
    "    elif (type == 3) :\n",
    "        return derv_leakly_relu(z)    \n",
    "    else :\n",
    "        print(\"Error, get_derv_activation\")\n",
    "        return 0                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(y,a) :\n",
    "    #print(y,a)\n",
    "    ret = -(torch.div(y,a+0.000001) - torch.div(1-y,1-a+0.000001))\n",
    "    \n",
    "    return ret\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "FEATURE_SIZE = 10000\n",
    "class ML :\n",
    "    def __init__(self,act1,act2,act3,L1_size,L2_size,L3_size,lr,min_loss_diff) :\n",
    "        self.act_type_1 = act1\n",
    "        self.act_type_2 = act2\n",
    "        self.act_type_3 = act3 \n",
    "        self.l1_size = L1_size\n",
    "        self.l2_size = L2_size\n",
    "        self.l3_size = L3_size\n",
    "        self.feature_size = 10000\n",
    "        self.epoch = 0\n",
    "        self.lr = lr\n",
    "        self.min_loss_diff = min_loss_diff\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "        print(\"ML Object initialized\")\n",
    "        self.iter = 0\n",
    "\n",
    "        self.val_acc_log = []\n",
    "        self.val_loss_log = []\n",
    "        self.train_acc_log = []\n",
    "        self.train_loss_log = []\n",
    "        self.epoch_log = []\n",
    "        self.val_acc_log.append(0)\n",
    "        self.val_loss_log.append(0)\n",
    "        self.train_acc_log.append(0)\n",
    "        self.train_loss_log.append(0)\n",
    "        self.epoch_log.append(0)\n",
    "        \n",
    "    def init_weights(self) :\n",
    "        self.w_1 = torch.FloatTensor(self.l1_size,self.feature_size).uniform_(-1,1)\n",
    "        self.b_1 = torch.FloatTensor(1,self.l1_size).uniform_(-1,1)\n",
    "        \n",
    "        #torch.FloatTensor(a, b).uniform_(r1, r2)\n",
    "        \n",
    "        self.w_2 = torch.FloatTensor(self.l2_size,self.l1_size).uniform_(-1,1)\n",
    "        self.b_2 = torch.FloatTensor(1,self.l2_size).uniform_(-1,1)\n",
    "\n",
    "        self.w_3 = torch.FloatTensor(self.l3_size,self.l2_size).uniform_(-1,1)\n",
    "        self.b_3 = torch.FloatTensor(1,self.l3_size).uniform_(-1,1)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def training(self) :\n",
    "        \n",
    "        epoch = 0\n",
    "        for epoch in range(0,1000000):\n",
    "            train_acc_log_tmp = []\n",
    "            train_loss_log_tmp = []\n",
    "            val_acc_log_tmp = []\n",
    "            val_loss_log_tmp = []\n",
    "            \n",
    "\n",
    "        # load training images of the batch size for every iteration\n",
    "            for i, data in enumerate(trainloader):\n",
    "                \n",
    "                # inputs is the images\n",
    "                # labels is the class of the image\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.float() , labels.float()\n",
    "                # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "\n",
    "                # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "                \n",
    "                self.t_data_batch = torch.squeeze(torch.FloatTensor(data[0]),3)\n",
    "                \n",
    "                self.t_data_batch = self.t_data_batch.view(len(data[0]),FEATURE_SIZE)\n",
    "                self.z_1 = torch.matmul(self.t_data_batch,self.w_1.T) + self.b_1\n",
    "                #print(self.z_1)\n",
    "                self.a_1 = get_activation(self.z_1,self.act_type_1)\n",
    "                #print(self.a_1)\n",
    "                \n",
    "                self.z_2 = torch.matmul(self.a_1,self.w_2.T) + self.b_2\n",
    "\n",
    "                self.a_2 = get_activation(self.z_2,self.act_type_2) # 1027 x 50\n",
    "\n",
    "                self.z_3 = torch.matmul(self.a_2,self.w_3.T) + self.b_3\n",
    "                #print(self.z_3)\n",
    "                self.a_3 = get_activation(self.z_3,self.act_type_3) # 1027 x 1\n",
    "            \n",
    "                #print(self.a_3)\n",
    "                self.t_yh_batch = data[1].float().unsqueeze(1)\n",
    "\n",
    "                #print(self.a_3,self.t_yh_batch)\n",
    "                acc = self.get_acc(self.a_3,self.t_yh_batch)\n",
    "                loss = np.array(get_loss(self.t_yh_batch, self.a_3)).mean()\n",
    "                \n",
    "                train_acc_log_tmp.append(acc)\n",
    "                train_loss_log_tmp.append(loss)\n",
    "                \n",
    "                self.update_weights(self.t_yh_batch,self.a_3)\n",
    "            \n",
    "            \n",
    "            \n",
    "            train_acc = np.array(train_acc_log_tmp).mean()\n",
    "            train_loss = np.array(train_loss_log_tmp).mean()\n",
    "\n",
    "            print(\"epoch : %s, loss : %s, tra_acc : %s\"%(epoch,train_loss,train_acc))\n",
    "            \n",
    "           \n",
    "\n",
    "            # load validation images of the batch size for every iteration\n",
    "            for i, data in enumerate(valloader):\n",
    "\n",
    "                # inputs is the image\n",
    "                # labels is the class of the image\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.float() , labels.float()\n",
    "                # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "                \n",
    "                \n",
    "                # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "                \n",
    "                self.v_data_batch = torch.squeeze(torch.FloatTensor(data[0]),3)\n",
    "                \n",
    "                self.v_data_batch = self.v_data_batch.view(len(data[0]),FEATURE_SIZE)\n",
    "                \n",
    "                self.z_1 = torch.matmul(self.v_data_batch,self.w_1.T) + self.b_1\n",
    "                \n",
    "                self.a_1 = get_activation(self.z_1,self.act_type_1)\n",
    "                #print(self.a_1)\n",
    "\n",
    "                self.z_2 = torch.matmul(self.a_1,self.w_2.T) + self.b_2\n",
    "                self.a_2 = get_activation(self.z_2,self.act_type_2) # 1027 x 50\n",
    "\n",
    "                self.z_3 = torch.matmul(self.a_2,self.w_3.T) + self.b_3\n",
    "                self.a_3 = get_activation(self.z_3,self.act_type_3) # 1027 x 1\n",
    "\n",
    "                self.v_yh_batch = data[1].float().unsqueeze(1)\n",
    "                acc = self.get_acc(self.a_3,self.v_yh_batch)\n",
    "                \n",
    "                \n",
    "                loss = np.array(get_loss(self.v_yh_batch, self.a_3)).mean()\n",
    "                val_acc_log_tmp.append(acc)\n",
    "                val_loss_log_tmp.append(loss)\n",
    "            val_acc = np.array(val_acc_log_tmp).mean()\n",
    "            val_loss = np.array(val_loss_log_tmp).mean()\n",
    "            \n",
    "            print(\"epoch : %s, loss : %s, val_acc : %s\"%(epoch,val_loss,val_acc))\n",
    "\n",
    "            self.train_acc_log.append(train_acc)\n",
    "            self.train_loss_log.append(train_loss)\n",
    "            self.val_acc_log.append(val_acc)\n",
    "            self.val_loss_log.append(val_loss)\n",
    "            self.epoch_log.append(epoch)\n",
    "            epoch += 1\n",
    "            \n",
    "            tmp_idx = len(self.train_loss_log)-1\n",
    "            if ( abs(self.train_loss_log[tmp_idx]-self.train_loss_log[tmp_idx-1]) < self.min_loss_diff) :\n",
    "                print(\"Learning is terminated.\")\n",
    "                break\n",
    "\n",
    "        \n",
    "    def update_weights(self,t_y,a_3) :\n",
    "        error_wb3 = -(torch.div(t_y,a_3+ 0.00011) - torch.div(1.0-t_y,1.0-a_3+ 0.00001)) # sum ep\n",
    "        d_z_3 = error_wb3*get_derv_activation(self.z_3,self.act_type_3) #         \n",
    "        d_w_3 = torch.matmul(d_z_3.T,self.a_2)\n",
    "        d_b_3 = torch.sum(d_z_3, dim=0, keepdim=True) / self.a_2.shape[0] # mean도 됨\n",
    "        \n",
    "        #########\n",
    "        \n",
    "        error_wb2 = torch.matmul(d_z_3,self.w_3)\n",
    "        \n",
    "        d_z_2 = error_wb2*get_derv_activation(self.z_2,self.act_type_2)\n",
    "        \n",
    "        d_w_2 = torch.matmul(d_z_2.T,self.a_1)\n",
    "        d_b_2 = torch.sum(d_z_2, dim=0,keepdims=True) / self.a_1.shape[0]\n",
    "        \n",
    "   \n",
    "        error_wb1 = torch.matmul(d_z_2,self.w_2)\n",
    "        d_z_1 = error_wb1*get_derv_activation(self.z_1,self.act_type_1)\n",
    "        d_w_1 = torch.matmul(d_z_1.T,self.t_data_batch)\n",
    "        d_b_1 = torch.sum(d_z_1, dim=0,keepdims=True) / self.t_data_batch.shape[0]\n",
    "        \n",
    "        \n",
    "        self.w_3 += -self.lr*d_w_3\n",
    "        self.b_3 += -self.lr*d_b_3\n",
    "        \n",
    "        self.w_2 += -self.lr*d_w_2\n",
    "        self.b_2 += -self.lr*d_b_2\n",
    "        self.w_1 += -self.lr*d_w_1\n",
    "        self.b_1 += -self.lr*d_b_1\n",
    "        #print(b_3,b_2,b_1)\n",
    "        \n",
    "    def get_acc(self,yhat,y) :\n",
    "        count = 0\n",
    "      \n",
    "        for a,b in zip(yhat,y) :\n",
    "            if a >= 0.5 :\n",
    "                if b == 1 :\n",
    "                    count+=1\n",
    "            else :\n",
    "                if b == 0:\n",
    "                    count +=1\n",
    "        \n",
    "        return count / len(yhat)\n",
    "\n",
    "    def show_loss(self) :\n",
    "        #print(self.train_loss_log)\n",
    "        #print(self.val_loss_log)\n",
    "        #print(self.epoch_log)\n",
    "        \n",
    "        tmp_1 = torch.tensor(self.train_loss_log)\n",
    "        tmp_2 = torch.tensor(self.epoch_log)\n",
    "       \n",
    "        t1 = plt.plot(self.epoch_log,self.train_loss_log, color='orange',label='Training Loss')\n",
    "        t2 = plt.plot(self.epoch_log,self.val_loss_log, color= 'red',label='Validation Loss')\n",
    "        plt.title(\"Loss\")\n",
    "        plt.legend(['Training Loss','Validation Loss'])\n",
    "        plt.show()\n",
    "    def show_acc(self) :\n",
    "        t1 = plt.plot(self.epoch_log,self.train_acc_log, color='orange',label='Training Acc')\n",
    "        t2 = plt.plot(self.epoch_log,self.val_acc_log, color= 'red',label='Validation Acc')\n",
    "        plt.title(\"Accuracy\")\n",
    "        plt.legend(['Training Acc','Validation Acc'])\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "activation_type = 0 # 0 = sigmoid\n",
    "learningRate = 0.00001\n",
    "min_loss_diff = 0.00001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML Object initialized\n"
     ]
    }
   ],
   "source": [
    "#1,1,0 means tanh, tanh, sigmoid\n",
    "machine = ML(1,1,0,10,5,1,learningRate,min_loss_diff)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, loss : 1.881295, tra_acc : 0.5307744107744108\n",
      "epoch : 0, loss : 2.3584208, val_acc : 0.48404761904761906\n",
      "epoch : 1, loss : 1.8999938, tra_acc : 0.5234006734006734\n",
      "epoch : 1, loss : 2.2066104, val_acc : 0.499047619047619\n",
      "epoch : 2, loss : 1.7854034, tra_acc : 0.5356902356902358\n",
      "epoch : 2, loss : 2.20864, val_acc : 0.4780952380952381\n",
      "epoch : 3, loss : 1.7619202, tra_acc : 0.5341414141414141\n",
      "epoch : 3, loss : 2.1163464, val_acc : 0.4885714285714286\n",
      "epoch : 4, loss : 1.7797745, tra_acc : 0.531043771043771\n",
      "epoch : 4, loss : 2.1569486, val_acc : 0.4852380952380952\n",
      "epoch : 5, loss : 1.6973934, tra_acc : 0.5328619528619529\n",
      "epoch : 5, loss : 2.1586165, val_acc : 0.4747619047619048\n",
      "epoch : 6, loss : 1.6893368, tra_acc : 0.5371380471380471\n",
      "epoch : 6, loss : 2.1119478, val_acc : 0.4635714285714285\n",
      "epoch : 7, loss : 1.6923878, tra_acc : 0.538956228956229\n",
      "epoch : 7, loss : 2.0961752, val_acc : 0.46095238095238095\n",
      "epoch : 8, loss : 1.61208, tra_acc : 0.543872053872054\n",
      "epoch : 8, loss : 1.9846106, val_acc : 0.47142857142857136\n",
      "epoch : 9, loss : 1.6271644, tra_acc : 0.538956228956229\n",
      "epoch : 9, loss : 1.8980445, val_acc : 0.47928571428571426\n",
      "epoch : 10, loss : 1.6193626, tra_acc : 0.5315824915824915\n",
      "epoch : 10, loss : 1.9243747, val_acc : 0.47214285714285714\n",
      "epoch : 11, loss : 1.4408771, tra_acc : 0.5570707070707072\n",
      "epoch : 11, loss : 2.018356, val_acc : 0.46095238095238095\n",
      "epoch : 12, loss : 1.4568366, tra_acc : 0.5472390572390573\n",
      "epoch : 12, loss : 1.8589593, val_acc : 0.4688095238095238\n",
      "epoch : 13, loss : 1.5251468, tra_acc : 0.5416835016835017\n",
      "epoch : 13, loss : 1.8687029, val_acc : 0.46214285714285713\n",
      "epoch : 14, loss : 1.4711647, tra_acc : 0.5392255892255892\n",
      "epoch : 14, loss : 1.8242459, val_acc : 0.4595238095238095\n",
      "epoch : 15, loss : 1.4030982, tra_acc : 0.5524242424242425\n",
      "epoch : 15, loss : 1.7974697, val_acc : 0.4647619047619047\n",
      "epoch : 16, loss : 1.5037544, tra_acc : 0.5287542087542086\n",
      "epoch : 16, loss : 1.6732317, val_acc : 0.47523809523809524\n",
      "epoch : 17, loss : 1.3825504, tra_acc : 0.5484175084175084\n",
      "epoch : 17, loss : 1.7276388, val_acc : 0.46404761904761904\n",
      "epoch : 18, loss : 1.3598374, tra_acc : 0.5435016835016835\n",
      "epoch : 18, loss : 1.6454874, val_acc : 0.4673809523809524\n",
      "epoch : 19, loss : 1.4357492, tra_acc : 0.537037037037037\n",
      "epoch : 19, loss : 1.6805105, val_acc : 0.47\n",
      "epoch : 20, loss : 1.3271698, tra_acc : 0.545959595959596\n",
      "epoch : 20, loss : 1.5661327, val_acc : 0.46404761904761904\n",
      "epoch : 21, loss : 1.3283681, tra_acc : 0.5416835016835017\n",
      "epoch : 21, loss : 1.6270059, val_acc : 0.45357142857142857\n",
      "epoch : 22, loss : 1.3077852, tra_acc : 0.5407744107744108\n",
      "epoch : 22, loss : 1.5725855, val_acc : 0.4588095238095238\n",
      "epoch : 23, loss : 1.2792821, tra_acc : 0.5398653198653199\n",
      "epoch : 23, loss : 1.6038975, val_acc : 0.4588095238095238\n",
      "epoch : 24, loss : 1.272215, tra_acc : 0.5465993265993266\n",
      "epoch : 24, loss : 1.526885, val_acc : 0.46142857142857147\n",
      "epoch : 25, loss : 1.2091585, tra_acc : 0.5524242424242426\n",
      "epoch : 25, loss : 1.5155195, val_acc : 0.45809523809523806\n",
      "epoch : 26, loss : 1.1585517, tra_acc : 0.5557912457912458\n",
      "epoch : 26, loss : 1.5328547, val_acc : 0.4383333333333333\n",
      "epoch : 27, loss : 1.1565727, tra_acc : 0.5451515151515152\n",
      "epoch : 27, loss : 1.4856563, val_acc : 0.3930952380952381\n",
      "epoch : 28, loss : 1.1729118, tra_acc : 0.5396969696969698\n",
      "epoch : 28, loss : 1.3967534, val_acc : 0.4102380952380953\n",
      "epoch : 29, loss : 1.2004957, tra_acc : 0.5298653198653199\n",
      "epoch : 29, loss : 1.2577761, val_acc : 0.42333333333333334\n",
      "epoch : 30, loss : 1.1877759, tra_acc : 0.5258585858585859\n",
      "epoch : 30, loss : 1.392181, val_acc : 0.4076190476190476\n",
      "epoch : 31, loss : 1.0593342, tra_acc : 0.5356902356902357\n",
      "epoch : 31, loss : 1.3353525, val_acc : 0.4083333333333334\n",
      "epoch : 32, loss : 1.1645478, tra_acc : 0.5325925925925925\n",
      "epoch : 32, loss : 1.2357019, val_acc : 0.42404761904761906\n",
      "epoch : 33, loss : 1.0386395, tra_acc : 0.5365993265993266\n",
      "epoch : 33, loss : 1.3462852, val_acc : 0.41809523809523813\n",
      "epoch : 34, loss : 1.0888991, tra_acc : 0.535959595959596\n",
      "epoch : 34, loss : 1.2426406, val_acc : 0.4147619047619047\n",
      "epoch : 35, loss : 1.0330842, tra_acc : 0.5411447811447812\n",
      "epoch : 35, loss : 1.188634, val_acc : 0.4088095238095238\n",
      "epoch : 36, loss : 1.0398463, tra_acc : 0.542053872053872\n",
      "epoch : 36, loss : 1.221958, val_acc : 0.40357142857142864\n",
      "epoch : 37, loss : 1.0198493, tra_acc : 0.5414141414141415\n",
      "epoch : 37, loss : 1.3155284, val_acc : 0.4192857142857143\n",
      "epoch : 38, loss : 1.0318708, tra_acc : 0.5414141414141415\n",
      "epoch : 38, loss : 1.2207173, val_acc : 0.4069047619047619\n",
      "epoch : 39, loss : 1.0105238, tra_acc : 0.5257575757575756\n",
      "epoch : 39, loss : 1.2173601, val_acc : 0.40166666666666667\n",
      "epoch : 40, loss : 1.04744, tra_acc : 0.5315824915824915\n",
      "epoch : 40, loss : 1.1504736, val_acc : 0.41214285714285714\n",
      "epoch : 41, loss : 0.9633351, tra_acc : 0.5527946127946128\n",
      "epoch : 41, loss : 1.0531412, val_acc : 0.4226190476190476\n",
      "epoch : 42, loss : 0.9440518, tra_acc : 0.538956228956229\n",
      "epoch : 42, loss : 1.0895039, val_acc : 0.4147619047619047\n",
      "epoch : 43, loss : 0.9845804, tra_acc : 0.5355892255892256\n",
      "epoch : 43, loss : 0.9986265, val_acc : 0.40952380952380957\n",
      "epoch : 44, loss : 0.9851259, tra_acc : 0.5331313131313132\n",
      "epoch : 44, loss : 1.126646, val_acc : 0.40952380952380957\n",
      "epoch : 45, loss : 0.9244253, tra_acc : 0.5374074074074074\n",
      "epoch : 45, loss : 1.057031, val_acc : 0.40166666666666667\n",
      "epoch : 46, loss : 0.9214535, tra_acc : 0.5414141414141415\n",
      "epoch : 46, loss : 1.1006882, val_acc : 0.39119047619047614\n",
      "epoch : 47, loss : 0.9031718, tra_acc : 0.538047138047138\n",
      "epoch : 47, loss : 0.9806578, val_acc : 0.4147619047619047\n",
      "epoch : 48, loss : 0.93797565, tra_acc : 0.5383164983164984\n",
      "epoch : 48, loss : 1.0485564, val_acc : 0.4069047619047619\n",
      "epoch : 49, loss : 0.890457, tra_acc : 0.5383164983164983\n",
      "epoch : 49, loss : 0.9971134, val_acc : 0.41214285714285714\n",
      "epoch : 50, loss : 0.8755009, tra_acc : 0.5293939393939393\n",
      "epoch : 50, loss : 0.9836729, val_acc : 0.41214285714285714\n",
      "epoch : 51, loss : 0.85072005, tra_acc : 0.5392255892255893\n",
      "epoch : 51, loss : 0.91019076, val_acc : 0.4069047619047619\n",
      "epoch : 52, loss : 0.8376966, tra_acc : 0.5416835016835017\n",
      "epoch : 52, loss : 1.0385083, val_acc : 0.3964285714285714\n",
      "epoch : 53, loss : 0.85671824, tra_acc : 0.5425925925925926\n",
      "epoch : 53, loss : 1.0130543, val_acc : 0.38857142857142857\n",
      "epoch : 54, loss : 0.8221201, tra_acc : 0.5392255892255892\n",
      "epoch : 54, loss : 0.9389515, val_acc : 0.41214285714285714\n",
      "epoch : 55, loss : 0.8237486, tra_acc : 0.5367676767676767\n",
      "epoch : 55, loss : 0.88939315, val_acc : 0.3971428571428572\n",
      "epoch : 56, loss : 0.82654345, tra_acc : 0.5318518518518519\n",
      "epoch : 56, loss : 0.96362704, val_acc : 0.39904761904761904\n",
      "epoch : 57, loss : 0.8128159, tra_acc : 0.5441414141414141\n",
      "epoch : 57, loss : 0.9243235, val_acc : 0.4042857142857143\n",
      "epoch : 58, loss : 0.7666212, tra_acc : 0.545050505050505\n",
      "epoch : 58, loss : 0.8807686, val_acc : 0.41214285714285714\n",
      "epoch : 59, loss : 0.802564, tra_acc : 0.5358585858585859\n",
      "epoch : 59, loss : 0.9181483, val_acc : 0.4042857142857143\n",
      "epoch : 60, loss : 0.74684864, tra_acc : 0.5407744107744107\n",
      "epoch : 60, loss : 0.87756675, val_acc : 0.3885714285714285\n",
      "epoch : 61, loss : 0.7431667, tra_acc : 0.5456902356902357\n",
      "epoch : 61, loss : 0.925344, val_acc : 0.4114285714285715\n",
      "epoch : 62, loss : 0.72511464, tra_acc : 0.546868686868687\n",
      "epoch : 62, loss : 0.8672332, val_acc : 0.40357142857142864\n",
      "epoch : 63, loss : 0.7535886, tra_acc : 0.5453198653198654\n",
      "epoch : 63, loss : 0.7658004, val_acc : 0.4114285714285715\n",
      "epoch : 64, loss : 0.7366066, tra_acc : 0.5462289562289562\n",
      "epoch : 64, loss : 0.7068601, val_acc : 0.41404761904761905\n",
      "epoch : 65, loss : 0.6634107, tra_acc : 0.5600673400673402\n",
      "epoch : 65, loss : 0.7625053, val_acc : 0.41404761904761905\n",
      "epoch : 66, loss : 0.6506027, tra_acc : 0.5618855218855219\n",
      "epoch : 66, loss : 0.8367079, val_acc : 0.3930952380952381\n",
      "epoch : 67, loss : 0.6830927, tra_acc : 0.5594276094276094\n",
      "epoch : 67, loss : 0.82398397, val_acc : 0.4061904761904762\n",
      "epoch : 68, loss : 0.712318, tra_acc : 0.5520538720538721\n",
      "epoch : 68, loss : 0.778058, val_acc : 0.4114285714285715\n",
      "epoch : 69, loss : 0.6588018, tra_acc : 0.5505050505050505\n",
      "epoch : 69, loss : 0.71668315, val_acc : 0.41404761904761905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 70, loss : 0.6250446, tra_acc : 0.557878787878788\n",
      "epoch : 70, loss : 0.754399, val_acc : 0.39571428571428574\n",
      "epoch : 71, loss : 0.5962874, tra_acc : 0.5603367003367002\n",
      "epoch : 71, loss : 0.6606886, val_acc : 0.40095238095238095\n",
      "epoch : 72, loss : 0.58948344, tra_acc : 0.5554208754208755\n",
      "epoch : 72, loss : 0.78280944, val_acc : 0.3983333333333334\n",
      "epoch : 73, loss : 0.6134864, tra_acc : 0.5498653198653197\n",
      "epoch : 73, loss : 0.77704865, val_acc : 0.40357142857142864\n",
      "epoch : 74, loss : 0.64855325, tra_acc : 0.5514141414141414\n",
      "epoch : 74, loss : 0.80095124, val_acc : 0.3983333333333334\n",
      "epoch : 75, loss : 0.64921975, tra_acc : 0.5464983164983165\n",
      "epoch : 75, loss : 0.6553273, val_acc : 0.4192857142857143\n",
      "epoch : 76, loss : 0.64191306, tra_acc : 0.5514141414141414\n",
      "epoch : 76, loss : 0.68015414, val_acc : 0.41404761904761905\n",
      "epoch : 77, loss : 0.62717074, tra_acc : 0.5514141414141414\n",
      "epoch : 77, loss : 0.7235958, val_acc : 0.3930952380952381\n",
      "epoch : 78, loss : 0.65366936, tra_acc : 0.5415824915824916\n",
      "epoch : 78, loss : 0.7713011, val_acc : 0.3983333333333334\n",
      "epoch : 79, loss : 0.65032077, tra_acc : 0.5406734006734008\n",
      "epoch : 79, loss : 0.6558202, val_acc : 0.4173809523809524\n",
      "epoch : 80, loss : 0.6306874, tra_acc : 0.5342087542087541\n",
      "epoch : 80, loss : 0.66445255, val_acc : 0.4076190476190476\n",
      "epoch : 81, loss : 0.5957312, tra_acc : 0.5505050505050505\n",
      "epoch : 81, loss : 0.6096516, val_acc : 0.4154761904761905\n",
      "epoch : 82, loss : 0.6017587, tra_acc : 0.552962962962963\n",
      "epoch : 82, loss : 0.659138, val_acc : 0.41214285714285714\n",
      "epoch : 83, loss : 0.61328465, tra_acc : 0.5489562289562289\n",
      "epoch : 83, loss : 0.70987767, val_acc : 0.3990476190476191\n",
      "epoch : 84, loss : 0.588913, tra_acc : 0.5498653198653198\n",
      "epoch : 84, loss : 0.67529434, val_acc : 0.4069047619047619\n"
     ]
    }
   ],
   "source": [
    "machine.training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "machine.show_loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine.show_acc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
