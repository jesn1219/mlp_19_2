{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "\n",
    "Submitter : JESOON KANG, 20170937\n",
    "Date : 2019. 10. \n",
    "\n",
    "\n",
    "    Assignment 4. \n",
    "\n",
    "-   -\n",
    "\n",
    "\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchvision\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Section 1. #### This Section is bringed Data_import_ex.py file.\n",
    "\n",
    "# Image Data import & resize\n",
    "\n",
    "transform = transforms.Compose([#transforms.Resize((256,256)),  \n",
    "                                transforms.Grayscale(),\t\t# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "                                transforms.ToTensor(),])\n",
    "\n",
    "#train_data_path = 'relative path of training data set'\n",
    "train_data_path = '../data/horse-or-human/train'\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "# if shuffle=True, the data reshuffled at every epoch \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=0)  \n",
    "\n",
    "\n",
    "validation_data_path = '../data/horse-or-human/validation'\n",
    "valset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=100, shuffle=True, num_workers=0)  \n",
    "\n",
    "#### Section 1 END ####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sigmoid Function.\n",
    "def sigmoid(z) :\n",
    "    return 1 / (1 + torch.pow(math.e,-z)+0.000001)\n",
    "\n",
    "def tanh(z) :\n",
    "    ret = (2 / (1 + torch.pow(math.e,-2*z) + 0.000001)) - 1\n",
    "    return ret\n",
    "\n",
    "def derv_tanh(z) :\n",
    "    ret = (1 - (tanh(z)**2))\n",
    "    return ret\n",
    "\n",
    "def relu(z) :\n",
    "    ret = z.clone().detach()\n",
    "    #print(ret)\n",
    "    tmp = torch.zeros_like(ret)\n",
    "    ret = torch.where(ret<=0,tmp,ret)\n",
    "    return ret\n",
    "                                                                  \n",
    "def derv_relu(z) :\n",
    "    ret = z.clone().detach()\n",
    "    tmp_1 = torch.zeros_like(ret)\n",
    "    tmp_2 = torch.ones_like(ret)\n",
    "    ret = torch.where(ret<0,tmp_1,tmp_2)\n",
    "    #print(ret)\n",
    "    return ret\n",
    "    \n",
    "            \n",
    "def leakly_relu(z) :\n",
    "    ret = z.clone().detach()\n",
    "    tmp1 = torch.ones_like(ret)\n",
    "    ret = torch.where(ret<0,ret*0.01,ret)\n",
    "    return ret\n",
    "\n",
    "def derv_leakly_relu(z) :\n",
    "    ret = z.clone().detach()\n",
    "    tmp1 = torch.ones_like(ret)\n",
    "    ret = torch.where(ret<0, tmp1*0.01,tmp1)\n",
    "    \n",
    "    return ret\n",
    "\n",
    "def get_activation(z,type) :\n",
    "    if (type == 0) :\n",
    "        return sigmoid(z)\n",
    "    elif (type == 1) :\n",
    "        return tanh(z)\n",
    "    elif (type == 2) :\n",
    "        return relu(z)\n",
    "    elif (type == 3) :\n",
    "        return leakly_relu(z)\n",
    "    \n",
    "    else :\n",
    "        print(\"Error, get_activation\")\n",
    "        return 0\n",
    "\n",
    "def get_derv_activation(z,type) :\n",
    "    if (type == 0) :\n",
    "        return sigmoid(z)*(1-sigmoid(z))\n",
    "    elif (type == 1) :\n",
    "        return derv_tanh(z)\n",
    "    elif (type == 2) :\n",
    "        return derv_relu(z)\n",
    "    elif (type == 3) :\n",
    "        return derv_leakly_relu(z)    \n",
    "    else :\n",
    "        print(\"Error, get_derv_activation\")\n",
    "        return 0                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(y,a) :\n",
    "    #print(y,a)\n",
    "    ret = -(torch.div(y,a+0.000001) - torch.div(1-y,1-a+0.000001))\n",
    "    \n",
    "    return ret\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "FEATURE_SIZE = 10000\n",
    "class ML :\n",
    "    def __init__(self,act1,act2,act3,L1_size,L2_size,L3_size,lr,min_loss_diff) :\n",
    "        self.act_type_1 = act1\n",
    "        self.act_type_2 = act2\n",
    "        self.act_type_3 = act3 \n",
    "        self.l1_size = L1_size\n",
    "        self.l2_size = L2_size\n",
    "        self.l3_size = L3_size\n",
    "        self.feature_size = 10000\n",
    "        self.epoch = 0\n",
    "        self.lr = lr\n",
    "        self.min_loss_diff = min_loss_diff\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "        print(\"ML Object initialized\")\n",
    "        self.iter = 0\n",
    "\n",
    "        self.val_acc_log = []\n",
    "        self.val_loss_log = []\n",
    "        self.train_acc_log = []\n",
    "        self.train_loss_log = []\n",
    "        self.epoch_log = []\n",
    "        self.val_acc_log.append(0)\n",
    "        self.val_loss_log.append(0)\n",
    "        self.train_acc_log.append(0)\n",
    "        self.train_loss_log.append(0)\n",
    "        self.epoch_log.append(0)\n",
    "        \n",
    "    def init_weights(self) :\n",
    "        self.w_1 = torch.FloatTensor(self.l1_size,self.feature_size).uniform_(-1,1)\n",
    "        self.b_1 = torch.FloatTensor(1,self.l1_size).uniform_(-1,1)\n",
    "        \n",
    "        #torch.FloatTensor(a, b).uniform_(r1, r2)\n",
    "        \n",
    "        self.w_2 = torch.FloatTensor(self.l2_size,self.l1_size).uniform_(-1,1)\n",
    "        self.b_2 = torch.FloatTensor(1,self.l2_size).uniform_(-1,1)\n",
    "\n",
    "        self.w_3 = torch.FloatTensor(self.l3_size,self.l2_size).uniform_(-1,1)\n",
    "        self.b_3 = torch.FloatTensor(1,self.l3_size).uniform_(-1,1)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def training(self) :\n",
    "        \n",
    "        epoch = 0\n",
    "        for epoch in range(0,1000000):\n",
    "            train_acc_log_tmp = []\n",
    "            train_loss_log_tmp = []\n",
    "            val_acc_log_tmp = []\n",
    "            val_loss_log_tmp = []\n",
    "            \n",
    "\n",
    "        # load training images of the batch size for every iteration\n",
    "            for i, data in enumerate(trainloader):\n",
    "                \n",
    "                # inputs is the images\n",
    "                # labels is the class of the image\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.float() , labels.float()\n",
    "                # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "\n",
    "                # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "                \n",
    "                self.t_data_batch = torch.squeeze(torch.FloatTensor(data[0]),3)\n",
    "                \n",
    "                self.t_data_batch = self.t_data_batch.view(len(data[0]),FEATURE_SIZE)\n",
    "                self.z_1 = torch.matmul(self.t_data_batch,self.w_1.T) + self.b_1\n",
    "                #print(self.z_1)\n",
    "                self.a_1 = get_activation(self.z_1,self.act_type_1)\n",
    "                #print(self.a_1)\n",
    "                \n",
    "                self.z_2 = torch.matmul(self.a_1,self.w_2.T) + self.b_2\n",
    "\n",
    "                self.a_2 = get_activation(self.z_2,self.act_type_2) # 1027 x 50\n",
    "\n",
    "                self.z_3 = torch.matmul(self.a_2,self.w_3.T) + self.b_3\n",
    "                #print(self.z_3)\n",
    "                self.a_3 = get_activation(self.z_3,self.act_type_3) # 1027 x 1\n",
    "            \n",
    "                #print(self.a_3)\n",
    "                self.t_yh_batch = data[1].float().unsqueeze(1)\n",
    "\n",
    "                #print(self.a_3,self.t_yh_batch)\n",
    "                acc = self.get_acc(self.a_3,self.t_yh_batch)\n",
    "                loss = np.array(get_loss(self.t_yh_batch, self.a_3)).mean()\n",
    "                \n",
    "                train_acc_log_tmp.append(acc)\n",
    "                train_loss_log_tmp.append(loss)\n",
    "                \n",
    "                self.update_weights(self.t_yh_batch,self.a_3)\n",
    "            \n",
    "            \n",
    "            \n",
    "            train_acc = np.array(train_acc_log_tmp).mean()\n",
    "            train_loss = np.array(train_loss_log_tmp).mean()\n",
    "\n",
    "            print(\"epoch : %s, loss : %s, tra_acc : %s\"%(epoch,train_loss,train_acc))\n",
    "            \n",
    "           \n",
    "\n",
    "            # load validation images of the batch size for every iteration\n",
    "            for i, data in enumerate(valloader):\n",
    "\n",
    "                # inputs is the image\n",
    "                # labels is the class of the image\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.float() , labels.float()\n",
    "                # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "                \n",
    "                \n",
    "                # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "                \n",
    "                self.v_data_batch = torch.squeeze(torch.FloatTensor(data[0]),3)\n",
    "                \n",
    "                self.v_data_batch = self.v_data_batch.view(len(data[0]),FEATURE_SIZE)\n",
    "                \n",
    "                self.z_1 = torch.matmul(self.v_data_batch,self.w_1.T) + self.b_1\n",
    "                \n",
    "                self.a_1 = get_activation(self.z_1,self.act_type_1)\n",
    "                #print(self.a_1)\n",
    "\n",
    "                self.z_2 = torch.matmul(self.a_1,self.w_2.T) + self.b_2\n",
    "                self.a_2 = get_activation(self.z_2,self.act_type_2) # 1027 x 50\n",
    "\n",
    "                self.z_3 = torch.matmul(self.a_2,self.w_3.T) + self.b_3\n",
    "                self.a_3 = get_activation(self.z_3,self.act_type_3) # 1027 x 1\n",
    "\n",
    "                self.v_yh_batch = data[1].float().unsqueeze(1)\n",
    "                acc = self.get_acc(self.a_3,self.v_yh_batch)\n",
    "                \n",
    "                \n",
    "                loss = np.array(get_loss(self.v_yh_batch, self.a_3)).mean()\n",
    "                val_acc_log_tmp.append(acc)\n",
    "                val_loss_log_tmp.append(loss)\n",
    "            val_acc = np.array(val_acc_log_tmp).mean()\n",
    "            val_loss = np.array(val_loss_log_tmp).mean()\n",
    "            \n",
    "            print(\"epoch : %s, loss : %s, val_acc : %s\"%(epoch,val_loss,val_acc))\n",
    "\n",
    "            self.train_acc_log.append(train_acc)\n",
    "            self.train_loss_log.append(train_loss)\n",
    "            self.val_acc_log.append(val_acc)\n",
    "            self.val_loss_log.append(val_loss)\n",
    "            self.epoch_log.append(epoch)\n",
    "            epoch += 1\n",
    "            \n",
    "            tmp_idx = len(self.train_loss_log)-1\n",
    "            if ( abs(self.train_loss_log[tmp_idx]-self.train_loss_log[tmp_idx-1]) < self.min_loss_diff) :\n",
    "                print(\"Learning is terminated.\")\n",
    "                break\n",
    "\n",
    "        \n",
    "    def update_weights(self,t_y,a_3) :\n",
    "        error_wb3 = -(torch.div(t_y,a_3+ 0.00011) - torch.div(1.0-t_y,1.0-a_3+ 0.00001)) # sum ep\n",
    "        d_z_3 = error_wb3*get_derv_activation(self.z_3,self.act_type_3) #         \n",
    "        d_w_3 = torch.matmul(d_z_3.T,self.a_2)\n",
    "        d_b_3 = torch.sum(d_z_3, dim=0, keepdim=True) / self.a_2.shape[0] # mean도 됨\n",
    "        \n",
    "        #########\n",
    "        \n",
    "        error_wb2 = torch.matmul(d_z_3,self.w_3)\n",
    "        \n",
    "        d_z_2 = error_wb2*get_derv_activation(self.z_2,self.act_type_2)\n",
    "        \n",
    "        d_w_2 = torch.matmul(d_z_2.T,self.a_1)\n",
    "        d_b_2 = torch.sum(d_z_2, dim=0,keepdims=True) / self.a_1.shape[0]\n",
    "        \n",
    "   \n",
    "        error_wb1 = torch.matmul(d_z_2,self.w_2)\n",
    "        d_z_1 = error_wb1*get_derv_activation(self.z_1,self.act_type_1)\n",
    "        d_w_1 = torch.matmul(d_z_1.T,self.t_data_batch)\n",
    "        d_b_1 = torch.sum(d_z_1, dim=0,keepdims=True) / self.t_data_batch.shape[0]\n",
    "        \n",
    "        \n",
    "        self.w_3 += -self.lr*d_w_3\n",
    "        self.b_3 += -self.lr*d_b_3\n",
    "        \n",
    "        self.w_2 += -self.lr*d_w_2\n",
    "        self.b_2 += -self.lr*d_b_2\n",
    "        self.w_1 += -self.lr*d_w_1\n",
    "        self.b_1 += -self.lr*d_b_1\n",
    "        #print(b_3,b_2,b_1)\n",
    "        \n",
    "    def get_acc(self,yhat,y) :\n",
    "        count = 0\n",
    "      \n",
    "        for a,b in zip(yhat,y) :\n",
    "            if a >= 0.5 :\n",
    "                if b == 1 :\n",
    "                    count+=1\n",
    "            else :\n",
    "                if b == 0:\n",
    "                    count +=1\n",
    "        \n",
    "        return count / len(yhat)\n",
    "\n",
    "    def show_loss(self) :\n",
    "        #print(self.train_loss_log)\n",
    "        #print(self.val_loss_log)\n",
    "        #print(self.epoch_log)\n",
    "        \n",
    "        tmp_1 = torch.tensor(self.train_loss_log)\n",
    "        tmp_2 = torch.tensor(self.epoch_log)\n",
    "       \n",
    "        t1 = plt.plot(self.epoch_log,self.train_loss_log, color='orange',label='Training Loss')\n",
    "        t2 = plt.plot(self.epoch_log,self.val_loss_log, color= 'red',label='Validation Loss')\n",
    "        plt.title(\"Loss\")\n",
    "        plt.legend(['Training Loss','Validation Loss'])\n",
    "        plt.show()\n",
    "    def show_acc(self) :\n",
    "        t1 = plt.plot(self.epoch_log,self.train_acc_log, color='orange',label='Training Acc')\n",
    "        t2 = plt.plot(self.epoch_log,self.val_acc_log, color= 'red',label='Validation Acc')\n",
    "        plt.title(\"Accuracy\")\n",
    "        plt.legend(['Training Acc','Validation Acc'])\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML Object initialized\n"
     ]
    }
   ],
   "source": [
    "\n",
    "activation_type = 0 # 0 = sigmoid\n",
    "learningRate = 0.00001\n",
    "min_loss_diff = 0.00001\n",
    "machine = ML(0,0,0,10,5,1,learningRate,min_loss_diff)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, loss : 2.7932775, tra_acc : 0.5159595959595961\n",
      "epoch : 0, loss : 3.29183, val_acc : 0.47119047619047616\n",
      "epoch : 1, loss : 2.8135302, tra_acc : 0.5110437710437711\n",
      "epoch : 1, loss : 3.1203105, val_acc : 0.4895238095238095\n",
      "epoch : 2, loss : 2.7115102, tra_acc : 0.5184175084175084\n",
      "epoch : 2, loss : 3.0435524, val_acc : 0.4947619047619048\n",
      "epoch : 3, loss : 2.792753, tra_acc : 0.5061279461279461\n",
      "epoch : 3, loss : 2.952422, val_acc : 0.5026190476190476\n",
      "epoch : 4, loss : 2.7727113, tra_acc : 0.5061279461279461\n",
      "epoch : 4, loss : 2.8353841, val_acc : 0.513095238095238\n",
      "epoch : 5, loss : 2.6739671, tra_acc : 0.515959595959596\n",
      "epoch : 5, loss : 2.9166088, val_acc : 0.5\n",
      "epoch : 6, loss : 2.6819627, tra_acc : 0.5085858585858586\n",
      "epoch : 6, loss : 2.9492786, val_acc : 0.49214285714285716\n",
      "epoch : 7, loss : 2.5949152, tra_acc : 0.5184175084175083\n",
      "epoch : 7, loss : 2.926522, val_acc : 0.49214285714285716\n",
      "epoch : 8, loss : 2.5516303, tra_acc : 0.520875420875421\n",
      "epoch : 8, loss : 2.945306, val_acc : 0.48690476190476195\n",
      "epoch : 9, loss : 2.6185453, tra_acc : 0.5085858585858586\n",
      "epoch : 9, loss : 2.833659, val_acc : 0.4973809523809524\n",
      "epoch : 10, loss : 2.5227487, tra_acc : 0.5184175084175083\n",
      "epoch : 10, loss : 2.8895972, val_acc : 0.48690476190476195\n",
      "epoch : 11, loss : 2.5531588, tra_acc : 0.5110437710437711\n",
      "epoch : 11, loss : 2.863227, val_acc : 0.48690476190476195\n",
      "epoch : 12, loss : 2.5162396, tra_acc : 0.5135016835016835\n",
      "epoch : 12, loss : 2.5710146, val_acc : 0.520952380952381\n",
      "epoch : 13, loss : 2.5386775, tra_acc : 0.5061279461279461\n",
      "epoch : 13, loss : 2.7509258, val_acc : 0.4947619047619048\n",
      "epoch : 14, loss : 2.563861, tra_acc : 0.5012121212121211\n",
      "epoch : 14, loss : 2.7302058, val_acc : 0.4947619047619048\n",
      "epoch : 15, loss : 2.44899, tra_acc : 0.5135016835016833\n",
      "epoch : 15, loss : 2.7617645, val_acc : 0.4869047619047618\n",
      "epoch : 16, loss : 2.4595687, tra_acc : 0.5085858585858586\n",
      "epoch : 16, loss : 2.723814, val_acc : 0.4895238095238095\n",
      "epoch : 17, loss : 2.434226, tra_acc : 0.5085858585858586\n",
      "epoch : 17, loss : 2.5981326, val_acc : 0.5026190476190476\n",
      "epoch : 18, loss : 2.344526, tra_acc : 0.5184175084175084\n",
      "epoch : 18, loss : 2.731088, val_acc : 0.4816666666666667\n",
      "epoch : 19, loss : 2.3960004, tra_acc : 0.5085858585858586\n",
      "epoch : 19, loss : 2.5523765, val_acc : 0.5026190476190476\n",
      "epoch : 20, loss : 2.383024, tra_acc : 0.5085858585858586\n",
      "epoch : 20, loss : 2.4489639, val_acc : 0.513095238095238\n",
      "epoch : 21, loss : 2.3004303, tra_acc : 0.515959595959596\n",
      "epoch : 21, loss : 2.5547545, val_acc : 0.4973809523809524\n",
      "epoch : 22, loss : 2.2589183, tra_acc : 0.5184175084175086\n",
      "epoch : 22, loss : 2.6033232, val_acc : 0.48690476190476195\n",
      "epoch : 23, loss : 2.3210647, tra_acc : 0.5061279461279461\n",
      "epoch : 23, loss : 2.5559857, val_acc : 0.4895238095238095\n",
      "epoch : 24, loss : 2.2615063, tra_acc : 0.5135016835016835\n",
      "epoch : 24, loss : 2.5155094, val_acc : 0.49214285714285716\n",
      "epoch : 25, loss : 2.2902398, tra_acc : 0.5061279461279461\n",
      "epoch : 25, loss : 2.4442806, val_acc : 0.5\n",
      "epoch : 26, loss : 2.1633027, tra_acc : 0.5208754208754208\n",
      "epoch : 26, loss : 2.4160585, val_acc : 0.5\n",
      "epoch : 27, loss : 2.1555824, tra_acc : 0.5184175084175083\n",
      "epoch : 27, loss : 2.399307, val_acc : 0.5\n",
      "epoch : 28, loss : 2.1271996, tra_acc : 0.5208754208754208\n",
      "epoch : 28, loss : 2.437767, val_acc : 0.49214285714285716\n",
      "epoch : 29, loss : 2.1171274, tra_acc : 0.5184175084175084\n",
      "epoch : 29, loss : 2.284672, val_acc : 0.5104761904761904\n",
      "epoch : 30, loss : 2.1088495, tra_acc : 0.5184175084175083\n",
      "epoch : 30, loss : 2.3342798, val_acc : 0.5\n",
      "epoch : 31, loss : 2.0834696, tra_acc : 0.5184175084175086\n",
      "epoch : 31, loss : 2.274731, val_acc : 0.5052380952380952\n",
      "epoch : 32, loss : 2.1718771, tra_acc : 0.5036700336700337\n",
      "epoch : 32, loss : 2.168125, val_acc : 0.5183333333333333\n",
      "epoch : 33, loss : 2.132363, tra_acc : 0.5061279461279461\n",
      "epoch : 33, loss : 2.3895648, val_acc : 0.48428571428571426\n",
      "epoch : 34, loss : 2.0309768, tra_acc : 0.5184175084175083\n",
      "epoch : 34, loss : 2.294626, val_acc : 0.4947619047619048\n",
      "epoch : 35, loss : 2.0072682, tra_acc : 0.5184175084175086\n",
      "epoch : 35, loss : 2.2034762, val_acc : 0.5052380952380952\n",
      "epoch : 36, loss : 2.0304024, tra_acc : 0.5135016835016835\n",
      "epoch : 36, loss : 2.202501, val_acc : 0.5026190476190476\n",
      "epoch : 37, loss : 2.0218632, tra_acc : 0.5110437710437711\n",
      "epoch : 37, loss : 2.2551715, val_acc : 0.49214285714285716\n",
      "epoch : 38, loss : 2.006943, tra_acc : 0.5110437710437711\n",
      "epoch : 38, loss : 2.220946, val_acc : 0.4947619047619048\n",
      "epoch : 39, loss : 1.9432102, tra_acc : 0.5184175084175086\n",
      "epoch : 39, loss : 2.1657398, val_acc : 0.5\n",
      "epoch : 40, loss : 1.9372895, tra_acc : 0.5159595959595961\n",
      "epoch : 40, loss : 2.0612485, val_acc : 0.513095238095238\n",
      "epoch : 41, loss : 1.9458679, tra_acc : 0.5135016835016836\n",
      "epoch : 41, loss : 2.1302357, val_acc : 0.5\n",
      "epoch : 42, loss : 1.9175789, tra_acc : 0.5159595959595958\n",
      "epoch : 42, loss : 2.0451953, val_acc : 0.5104761904761904\n",
      "epoch : 43, loss : 1.8320202, tra_acc : 0.5257912457912458\n",
      "epoch : 43, loss : 2.145406, val_acc : 0.49214285714285716\n",
      "epoch : 44, loss : 1.8727546, tra_acc : 0.5159595959595961\n",
      "epoch : 44, loss : 2.0775807, val_acc : 0.5\n",
      "epoch : 45, loss : 1.8397468, tra_acc : 0.5184175084175083\n",
      "epoch : 45, loss : 2.0071874, val_acc : 0.5078571428571429\n",
      "epoch : 46, loss : 1.8773576, tra_acc : 0.5110437710437711\n",
      "epoch : 46, loss : 1.9450833, val_acc : 0.5157142857142857\n",
      "epoch : 47, loss : 1.8004857, tra_acc : 0.5208754208754208\n",
      "epoch : 47, loss : 2.0322998, val_acc : 0.5\n",
      "epoch : 48, loss : 1.8216251, tra_acc : 0.5135016835016833\n",
      "epoch : 48, loss : 2.011865, val_acc : 0.5\n",
      "epoch : 49, loss : 1.7667019, tra_acc : 0.5208754208754208\n",
      "epoch : 49, loss : 1.9961411, val_acc : 0.5\n",
      "epoch : 50, loss : 1.8572364, tra_acc : 0.5036700336700336\n",
      "epoch : 50, loss : 2.0652351, val_acc : 0.48690476190476195\n",
      "epoch : 51, loss : 1.7747442, tra_acc : 0.5159595959595961\n",
      "epoch : 51, loss : 1.9802996, val_acc : 0.4973809523809524\n",
      "epoch : 52, loss : 1.808291, tra_acc : 0.5085858585858586\n",
      "epoch : 52, loss : 1.8990558, val_acc : 0.5078571428571429\n",
      "epoch : 53, loss : 1.800013, tra_acc : 0.5061279461279461\n",
      "epoch : 53, loss : 1.9127673, val_acc : 0.5026190476190476\n",
      "epoch : 54, loss : 1.7101277, tra_acc : 0.5184175084175083\n",
      "epoch : 54, loss : 1.920281, val_acc : 0.5\n",
      "epoch : 55, loss : 1.7536674, tra_acc : 0.5085858585858586\n",
      "epoch : 55, loss : 2.0186615, val_acc : 0.4816666666666667\n",
      "epoch : 56, loss : 1.752401, tra_acc : 0.5061279461279461\n",
      "epoch : 56, loss : 1.8853521, val_acc : 0.5\n",
      "epoch : 57, loss : 1.6905854, tra_acc : 0.5135016835016835\n",
      "epoch : 57, loss : 1.9003624, val_acc : 0.4947619047619048\n",
      "epoch : 58, loss : 1.6025063, tra_acc : 0.5257912457912458\n",
      "epoch : 58, loss : 1.8053198, val_acc : 0.5078571428571429\n",
      "epoch : 59, loss : 1.6818157, tra_acc : 0.5110437710437711\n",
      "epoch : 59, loss : 1.8909591, val_acc : 0.49214285714285716\n",
      "epoch : 60, loss : 1.7003684, tra_acc : 0.5061279461279462\n",
      "epoch : 60, loss : 1.8315841, val_acc : 0.5\n",
      "epoch : 61, loss : 1.6221138, tra_acc : 0.515959595959596\n",
      "epoch : 61, loss : 1.8632437, val_acc : 0.49214285714285716\n",
      "epoch : 62, loss : 1.6076916, tra_acc : 0.515959595959596\n",
      "epoch : 62, loss : 1.8304526, val_acc : 0.4947619047619048\n",
      "epoch : 63, loss : 1.5115203, tra_acc : 0.5307070707070707\n",
      "epoch : 63, loss : 1.8154999, val_acc : 0.4947619047619048\n",
      "epoch : 64, loss : 1.5857791, tra_acc : 0.515959595959596\n",
      "epoch : 64, loss : 1.70897, val_acc : 0.5104761904761904\n",
      "epoch : 65, loss : 1.6182461, tra_acc : 0.5085858585858586\n",
      "epoch : 65, loss : 1.761124, val_acc : 0.5\n",
      "epoch : 66, loss : 1.5469494, tra_acc : 0.5184175084175084\n",
      "epoch : 66, loss : 1.6666665, val_acc : 0.513095238095238\n",
      "epoch : 67, loss : 1.647483, tra_acc : 0.49875420875420884\n",
      "epoch : 67, loss : 1.8385888, val_acc : 0.4816666666666667\n",
      "epoch : 68, loss : 1.51916, tra_acc : 0.5184175084175084\n",
      "epoch : 68, loss : 1.7331858, val_acc : 0.4973809523809524\n",
      "epoch : 69, loss : 1.5615443, tra_acc : 0.5085858585858586\n",
      "epoch : 69, loss : 1.6845937, val_acc : 0.5026190476190476\n",
      "epoch : 70, loss : 1.5526925, tra_acc : 0.5085858585858586\n",
      "epoch : 70, loss : 1.7380663, val_acc : 0.49214285714285716\n",
      "epoch : 71, loss : 1.5251645, tra_acc : 0.5110437710437711\n",
      "epoch : 71, loss : 1.6783327, val_acc : 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 72, loss : 1.4954407, tra_acc : 0.5135016835016835\n",
      "epoch : 72, loss : 1.7423445, val_acc : 0.48690476190476195\n",
      "epoch : 73, loss : 1.4729037, tra_acc : 0.5159595959595958\n",
      "epoch : 73, loss : 1.591061, val_acc : 0.5104761904761904\n",
      "epoch : 74, loss : 1.5550007, tra_acc : 0.5012121212121212\n",
      "epoch : 74, loss : 1.5513164, val_acc : 0.5157142857142857\n",
      "epoch : 75, loss : 1.4771016, tra_acc : 0.511043771043771\n",
      "epoch : 75, loss : 1.6763731, val_acc : 0.49214285714285716\n",
      "epoch : 76, loss : 1.4372061, tra_acc : 0.5159595959595958\n",
      "epoch : 76, loss : 1.5712166, val_acc : 0.5078571428571429\n",
      "epoch : 77, loss : 1.4510207, tra_acc : 0.5110437710437711\n",
      "epoch : 77, loss : 1.6790414, val_acc : 0.48690476190476195\n",
      "epoch : 78, loss : 1.4265709, tra_acc : 0.5135016835016833\n",
      "epoch : 78, loss : 1.5604769, val_acc : 0.5052380952380952\n",
      "epoch : 79, loss : 1.3739651, tra_acc : 0.5208754208754208\n",
      "epoch : 79, loss : 1.5930524, val_acc : 0.4973809523809524\n",
      "epoch : 80, loss : 1.3956027, tra_acc : 0.515959595959596\n",
      "epoch : 80, loss : 1.5368468, val_acc : 0.5052380952380952\n",
      "epoch : 81, loss : 1.3547362, tra_acc : 0.5208754208754208\n",
      "epoch : 81, loss : 1.5711166, val_acc : 0.4973809523809524\n",
      "epoch : 82, loss : 1.3291906, tra_acc : 0.5233333333333333\n",
      "epoch : 82, loss : 1.5909098, val_acc : 0.49214285714285716\n",
      "epoch : 83, loss : 1.3587619, tra_acc : 0.515959595959596\n",
      "epoch : 83, loss : 1.5198331, val_acc : 0.5026190476190476\n",
      "epoch : 84, loss : 1.404422, tra_acc : 0.5061279461279461\n",
      "epoch : 84, loss : 1.4638585, val_acc : 0.5104761904761904\n",
      "epoch : 85, loss : 1.3745257, tra_acc : 0.5085858585858586\n",
      "epoch : 85, loss : 1.4973239, val_acc : 0.5026190476190476\n",
      "epoch : 86, loss : 1.3573402, tra_acc : 0.5110437710437711\n",
      "epoch : 86, loss : 1.5290002, val_acc : 0.4947619047619048\n",
      "epoch : 87, loss : 1.2880882, tra_acc : 0.5208754208754208\n",
      "epoch : 87, loss : 1.445635, val_acc : 0.5078571428571429\n",
      "epoch : 88, loss : 1.3073713, tra_acc : 0.5159595959595961\n",
      "epoch : 88, loss : 1.4181882, val_acc : 0.5104761904761904\n",
      "epoch : 89, loss : 1.2448331, tra_acc : 0.5257912457912458\n",
      "epoch : 89, loss : 1.4800485, val_acc : 0.4973809523809524\n",
      "epoch : 90, loss : 1.2351094, tra_acc : 0.5257912457912458\n",
      "epoch : 90, loss : 1.3995577, val_acc : 0.5104761904761904\n",
      "epoch : 91, loss : 1.2343311, tra_acc : 0.5233333333333333\n",
      "epoch : 91, loss : 1.4901842, val_acc : 0.49214285714285716\n",
      "epoch : 92, loss : 1.304371, tra_acc : 0.5085858585858586\n",
      "epoch : 92, loss : 1.3931924, val_acc : 0.5078571428571429\n",
      "epoch : 93, loss : 1.218081, tra_acc : 0.5233333333333333\n",
      "epoch : 93, loss : 1.4291922, val_acc : 0.5\n",
      "epoch : 94, loss : 1.2188641, tra_acc : 0.5208754208754208\n",
      "epoch : 94, loss : 1.3711876, val_acc : 0.5078571428571429\n",
      "epoch : 95, loss : 1.2652692, tra_acc : 0.5110437710437711\n",
      "epoch : 95, loss : 1.3746177, val_acc : 0.5052380952380952\n",
      "epoch : 96, loss : 1.2499242, tra_acc : 0.5110437710437711\n",
      "epoch : 96, loss : 1.4095583, val_acc : 0.4973809523809524\n",
      "epoch : 97, loss : 1.2574714, tra_acc : 0.5085858585858586\n",
      "epoch : 97, loss : 1.3130872, val_acc : 0.513095238095238\n",
      "epoch : 98, loss : 1.2069649, tra_acc : 0.515959595959596\n",
      "epoch : 98, loss : 1.3906494, val_acc : 0.4973809523809524\n",
      "epoch : 99, loss : 1.2873328, tra_acc : 0.49875420875420884\n",
      "epoch : 99, loss : 1.394495, val_acc : 0.4947619047619048\n",
      "epoch : 100, loss : 1.2017426, tra_acc : 0.5135016835016835\n",
      "epoch : 100, loss : 1.3563102, val_acc : 0.5\n",
      "epoch : 101, loss : 1.1814959, tra_acc : 0.515959595959596\n",
      "epoch : 101, loss : 1.4298792, val_acc : 0.48428571428571426\n",
      "epoch : 102, loss : 1.20047, tra_acc : 0.5110437710437711\n",
      "epoch : 102, loss : 1.3494428, val_acc : 0.4973809523809524\n",
      "epoch : 103, loss : 1.2376443, tra_acc : 0.5012121212121212\n",
      "epoch : 103, loss : 1.3122724, val_acc : 0.5026190476190476\n",
      "epoch : 104, loss : 1.1789632, tra_acc : 0.5110437710437711\n",
      "epoch : 104, loss : 1.304073, val_acc : 0.5026190476190476\n",
      "epoch : 105, loss : 1.1354011, tra_acc : 0.5184175084175084\n",
      "epoch : 105, loss : 1.2966429, val_acc : 0.5026190476190476\n",
      "epoch : 106, loss : 1.1488087, tra_acc : 0.5135016835016836\n",
      "epoch : 106, loss : 1.2878159, val_acc : 0.5026190476190476\n",
      "epoch : 107, loss : 1.1393692, tra_acc : 0.5135016835016836\n",
      "epoch : 107, loss : 1.3150377, val_acc : 0.4947619047619048\n"
     ]
    }
   ],
   "source": [
    "machine.training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "machine.show_loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine.show_acc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
