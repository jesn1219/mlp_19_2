{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "\n",
    "Submitter : JESOON KANG, 20170937\n",
    "Date : 2019. 10. \n",
    "\n",
    "\n",
    "    Assignment 4. \n",
    "\n",
    "-   -\n",
    "\n",
    "\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchvision\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Section 1. #### This Section is bringed Data_import_ex.py file.\n",
    "\n",
    "# Image Data import & resize\n",
    "\n",
    "transform = transforms.Compose([#transforms.Resize((256,256)),  \n",
    "                                transforms.Grayscale(),\t\t# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "                                transforms.ToTensor(),])\n",
    "\n",
    "#train_data_path = 'relative path of training data set'\n",
    "train_data_path = '../data/horse-or-human/train'\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "# if shuffle=True, the data reshuffled at every epoch \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1000000, shuffle=True, num_workers=0)  \n",
    "\n",
    "\n",
    "validation_data_path = '../data/horse-or-human/validation'\n",
    "valset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=1000000, shuffle=True, num_workers=0)  \n",
    "\n",
    "#### Section 1 END ####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sigmoid Function.\n",
    "def sigmoid(z) :\n",
    "    return 1 / (1 + torch.pow(math.e,-z)+0.000001)\n",
    "\n",
    "def tanh(z) :\n",
    "    ret = (2 / (1 + torch.pow(math.e,-2*z) + 0.000001)) - 1\n",
    "    return ret\n",
    "\n",
    "def derv_tanh(z) :\n",
    "    ret = (1 - (tanh(z)**2))\n",
    "    return ret\n",
    "\n",
    "def relu(z) :\n",
    "    ret = z.clone().detach()\n",
    "    #print(ret)\n",
    "    tmp = torch.zeros_like(ret)\n",
    "    ret = torch.where(ret<=0,tmp,ret)\n",
    "    return ret\n",
    "                                                                  \n",
    "def derv_relu(z) :\n",
    "    ret = z.clone().detach()\n",
    "    tmp_1 = torch.zeros_like(ret)\n",
    "    tmp_2 = torch.ones_like(ret)\n",
    "    ret = torch.where(ret<0,tmp_1,tmp_2)\n",
    "    #print(ret)\n",
    "    return ret\n",
    "    \n",
    "            \n",
    "def leakly_relu(z) :\n",
    "    ret = z.clone().detach()\n",
    "    tmp1 = torch.ones_like(ret)\n",
    "    ret = torch.where(ret<0,ret*0.01,ret)\n",
    "    return ret\n",
    "\n",
    "def derv_leakly_relu(z) :\n",
    "    ret = z.clone().detach()\n",
    "    tmp1 = torch.ones_like(ret)\n",
    "    ret = torch.where(ret<0, tmp1*0.01,tmp1)\n",
    "    \n",
    "    return ret\n",
    "\n",
    "def get_activation(z,type) :\n",
    "    if (type == 0) :\n",
    "        return sigmoid(z)\n",
    "    elif (type == 1) :\n",
    "        return tanh(z)\n",
    "    elif (type == 2) :\n",
    "        return relu(z)\n",
    "    elif (type == 3) :\n",
    "        return leakly_relu(z)\n",
    "    \n",
    "    else :\n",
    "        print(\"Error, get_activation\")\n",
    "        return 0\n",
    "\n",
    "def get_derv_activation(z,type) :\n",
    "    if (type == 0) :\n",
    "        return sigmoid(z)*(1-sigmoid(z))\n",
    "    elif (type == 1) :\n",
    "        return derv_tanh(z)\n",
    "    elif (type == 2) :\n",
    "        return derv_relu(z)\n",
    "    elif (type == 3) :\n",
    "        return derv_leakly_relu(z)    \n",
    "    else :\n",
    "        print(\"Error, get_derv_activation\")\n",
    "        return 0                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "GeForce GTX 1050\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(y,a) :\n",
    "    #print(y,a)\n",
    "    ret = -(torch.div(y,a+0.000001) - torch.div(1-y,1-a+0.000001))\n",
    "    \n",
    "    return ret\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "FEATURE_SIZE = 10000\n",
    "class ML :\n",
    "    def __init__(self,act1,act2,act3,L1_size,L2_size,L3_size,lr,min_loss_diff) :\n",
    "        self.act_type_1 = act1\n",
    "        self.act_type_2 = act2\n",
    "        self.act_type_3 = act3 \n",
    "        self.l1_size = L1_size\n",
    "        self.l2_size = L2_size\n",
    "        self.l3_size = L3_size\n",
    "        self.feature_size = 10000\n",
    "        self.epoch = 0\n",
    "        self.lr = lr\n",
    "        self.min_loss_diff = min_loss_diff\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "        print(\"ML Object initialized\")\n",
    "        self.iter = 0\n",
    "\n",
    "        self.val_acc_log = []\n",
    "        self.val_loss_log = []\n",
    "        self.train_acc_log = []\n",
    "        self.train_loss_log = []\n",
    "        self.epoch_log = []\n",
    "        self.val_acc_log.append(0)\n",
    "        self.val_loss_log.append(0)\n",
    "        self.train_acc_log.append(0)\n",
    "        self.train_loss_log.append(0)\n",
    "        self.epoch_log.append(0)\n",
    "        \n",
    "    def init_weights(self) :\n",
    "        self.w_1 = torch.FloatTensor(self.l1_size,self.feature_size).uniform_(-1,1).to(device)\n",
    "        \n",
    "        self.b_1 = torch.FloatTensor(1,self.l1_size).uniform_(-1,1).to(device)\n",
    "        \n",
    "        #torch.FloatTensor(a, b).uniform_(r1, r2)\n",
    "        \n",
    "        self.w_2 = torch.FloatTensor(self.l2_size,self.l1_size).uniform_(-1,1).to(device)\n",
    "        self.b_2 = torch.FloatTensor(1,self.l2_size).uniform_(-1,1).to(device)\n",
    "\n",
    "        self.w_3 = torch.FloatTensor(self.l3_size,self.l2_size).uniform_(-1,1).to(device)\n",
    "        self.b_3 = torch.FloatTensor(1,self.l3_size).uniform_(-1,1).to(device)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def training(self) :\n",
    "        \n",
    "        epoch = 0\n",
    "        for epoch in range(0,1000000):\n",
    "            train_acc_log_tmp = []\n",
    "            train_loss_log_tmp = []\n",
    "            val_acc_log_tmp = []\n",
    "            val_loss_log_tmp = []\n",
    "            \n",
    "\n",
    "        # load training images of the batch size for every iteration\n",
    "            for i, data in enumerate(trainloader):\n",
    "                \n",
    "                # inputs is the images\n",
    "                # labels is the class of the image\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.float() , labels.float()\n",
    "                # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "\n",
    "                # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "                \n",
    "                self.t_data_batch = torch.squeeze(torch.FloatTensor(data[0]),3)\n",
    "                \n",
    "                self.t_data_batch = self.t_data_batch.view(len(data[0]),FEATURE_SIZE).to(device)\n",
    "                self.z_1 = torch.matmul(self.t_data_batch,self.w_1.T) + self.b_1\n",
    "                #print(self.z_1)\n",
    "                self.a_1 = get_activation(self.z_1,self.act_type_1)\n",
    "                #print(self.a_1)\n",
    "                \n",
    "                self.z_2 = torch.matmul(self.a_1,self.w_2.T) + self.b_2\n",
    "\n",
    "                self.a_2 = get_activation(self.z_2,self.act_type_2) # 1027 x 50\n",
    "\n",
    "                self.z_3 = torch.matmul(self.a_2,self.w_3.T) + self.b_3\n",
    "                #print(self.z_3)\n",
    "                self.a_3 = get_activation(self.z_3,self.act_type_3) # 1027 x 1\n",
    "            \n",
    "                #print(self.a_3)\n",
    "                self.t_yh_batch = data[1].float().unsqueeze(1).to(device)\n",
    "\n",
    "                #print(self.a_3,self.t_yh_batch)\n",
    "                acc = self.get_acc(self.a_3,self.t_yh_batch)\n",
    "                loss = get_loss(self.t_yh_batch, self.a_3)\n",
    "                \n",
    "                train_acc_log_tmp.append(acc)\n",
    "                train_loss_log_tmp.append(loss)\n",
    "                \n",
    "                self.update_weights(self.t_yh_batch,self.a_3)\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            train_acc = np.array(train_acc_log_tmp).mean()\n",
    "            #train_loss = np.array(train_loss_log_tmp).mean()\n",
    "            train_loss = 0\n",
    "            print(\"epoch : %s, loss : %s, tra_acc : %s\"%(epoch,train_loss,train_acc))\n",
    "            \n",
    "           \n",
    "\n",
    "            # load validation images of the batch size for every iteration\n",
    "            for i, data in enumerate(valloader):\n",
    "\n",
    "                # inputs is the image\n",
    "                # labels is the class of the image\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.float() , labels.float()\n",
    "                # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "                \n",
    "                \n",
    "                # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "                \n",
    "                self.v_data_batch = torch.squeeze(torch.FloatTensor(data[0]),3)\n",
    "                \n",
    "                self.v_data_batch = self.v_data_batch.view(len(data[0]),FEATURE_SIZE).to(device)\n",
    "                \n",
    "                self.z_1 = torch.matmul(self.v_data_batch,self.w_1.T) + self.b_1\n",
    "                \n",
    "                self.a_1 = get_activation(self.z_1,self.act_type_1)\n",
    "                #print(self.a_1)\n",
    "\n",
    "                self.z_2 = torch.matmul(self.a_1,self.w_2.T) + self.b_2\n",
    "                self.a_2 = get_activation(self.z_2,self.act_type_2) # 1027 x 50\n",
    "\n",
    "                self.z_3 = torch.matmul(self.a_2,self.w_3.T) + self.b_3\n",
    "                self.a_3 = get_activation(self.z_3,self.act_type_3) # 1027 x 1\n",
    "\n",
    "                self.v_yh_batch = data[1].float().unsqueeze(1).to(device)\n",
    "                acc = self.get_acc(self.a_3,self.v_yh_batch)\n",
    "                \n",
    "                \n",
    "                loss = get_loss(self.v_yh_batch, self.a_3)\n",
    "                val_acc_log_tmp.append(acc)\n",
    "                val_loss_log_tmp.append(loss)\n",
    "            val_acc = np.array(val_acc_log_tmp).mean()\n",
    "            #val_loss = np.array(val_loss_log_tmp).mean()\n",
    "            val_loss = 0\n",
    "            print(\"epoch : %s, loss : %s, val_acc : %s\"%(epoch,val_loss,val_acc))\n",
    "\n",
    "            self.train_acc_log.append(train_acc)\n",
    "            self.train_loss_log.append(train_loss)\n",
    "            self.val_acc_log.append(val_acc)\n",
    "            self.val_loss_log.append(val_loss)\n",
    "            self.epoch_log.append(epoch)\n",
    "            epoch += 1\n",
    "            \n",
    "            tmp_idx = len(self.train_loss_log)-1\n",
    "            if ( abs(self.train_loss_log[tmp_idx]-self.train_loss_log[tmp_idx-1]) < self.min_loss_diff) :\n",
    "                print(\"Learning is terminated.\")\n",
    "                break\n",
    "\n",
    "        \n",
    "    def update_weights(self,t_y,a_3) :\n",
    "        error_wb3 = -(torch.div(t_y,a_3+ 0.00011) - torch.div(1.0-t_y,1.0-a_3+ 0.00001)) # sum ep\n",
    "        d_z_3 = error_wb3*get_derv_activation(self.z_3,self.act_type_3) #         \n",
    "        d_w_3 = torch.matmul(d_z_3.T,self.a_2)\n",
    "        d_b_3 = torch.sum(d_z_3, dim=0, keepdim=True) / self.a_2.shape[0] # mean도 됨\n",
    "        \n",
    "        #########\n",
    "        \n",
    "        error_wb2 = torch.matmul(d_z_3,self.w_3)\n",
    "        \n",
    "        d_z_2 = error_wb2*get_derv_activation(self.z_2,self.act_type_2)\n",
    "        \n",
    "        d_w_2 = torch.matmul(d_z_2.T,self.a_1)\n",
    "        d_b_2 = torch.sum(d_z_2, dim=0,keepdims=True) / self.a_1.shape[0]\n",
    "        \n",
    "   \n",
    "        error_wb1 = torch.matmul(d_z_2,self.w_2)\n",
    "        d_z_1 = error_wb1*get_derv_activation(self.z_1,self.act_type_1)\n",
    "        d_w_1 = torch.matmul(d_z_1.T,self.t_data_batch)\n",
    "        d_b_1 = torch.sum(d_z_1, dim=0,keepdims=True) / self.t_data_batch.shape[0]\n",
    "        \n",
    "        \n",
    "        self.w_3 += -self.lr*d_w_3\n",
    "        self.b_3 += -self.lr*d_b_3\n",
    "        \n",
    "        self.w_2 += -self.lr*d_w_2\n",
    "        self.b_2 += -self.lr*d_b_2\n",
    "        self.w_1 += -self.lr*d_w_1\n",
    "        self.b_1 += -self.lr*d_b_1\n",
    "        #print(b_3,b_2,b_1)\n",
    "        \n",
    "    def get_acc(self,yhat,y) :\n",
    "        count = 0\n",
    "      \n",
    "        for a,b in zip(yhat,y) :\n",
    "            if a >= 0.5 :\n",
    "                if b == 1 :\n",
    "                    count+=1\n",
    "            else :\n",
    "                if b == 0:\n",
    "                    count +=1\n",
    "        \n",
    "        return count / len(yhat)\n",
    "\n",
    "    def show_loss(self) :\n",
    "        #print(self.train_loss_log)\n",
    "        #print(self.val_loss_log)\n",
    "        #print(self.epoch_log)\n",
    "        \n",
    "        tmp_1 = torch.tensor(self.train_loss_log)\n",
    "        tmp_2 = torch.tensor(self.epoch_log)\n",
    "       \n",
    "        t1 = plt.plot(self.epoch_log,self.train_loss_log, color='orange',label='Training Loss')\n",
    "        t2 = plt.plot(self.epoch_log,self.val_loss_log, color= 'red',label='Validation Loss')\n",
    "        plt.title(\"Loss\")\n",
    "        plt.legend(['Training Loss','Validation Loss'])\n",
    "        plt.show()\n",
    "    def show_acc(self) :\n",
    "        t1 = plt.plot(self.epoch_log,self.train_acc_log, color='orange',label='Training Acc')\n",
    "        t2 = plt.plot(self.epoch_log,self.val_acc_log, color= 'red',label='Validation Acc')\n",
    "        plt.title(\"Accuracy\")\n",
    "        plt.legend(['Training Acc','Validation Acc'])\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML Object initialized\n"
     ]
    }
   ],
   "source": [
    "\n",
    "activation_type = 0 # 0 = sigmoid\n",
    "learningRate = 0.001\n",
    "min_loss_diff = 0\n",
    "machine = ML(0,0,0,10,5,1,learningRate,min_loss_diff)\n",
    "dtype = torch.FloatTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, loss : 0, tra_acc : 0.48685491723466406\n",
      "epoch : 0, loss : 0, val_acc : 0.4296875\n",
      "epoch : 1, loss : 0, tra_acc : 0.4459591041869523\n",
      "epoch : 1, loss : 0, val_acc : 0.49609375\n",
      "epoch : 2, loss : 0, tra_acc : 0.5920155793573515\n",
      "epoch : 2, loss : 0, val_acc : 0.4921875\n",
      "epoch : 3, loss : 0, tra_acc : 0.5920155793573515\n",
      "epoch : 3, loss : 0, val_acc : 0.4921875\n",
      "epoch : 4, loss : 0, tra_acc : 0.5890944498539435\n",
      "epoch : 4, loss : 0, val_acc : 0.4921875\n",
      "epoch : 5, loss : 0, tra_acc : 0.5910418695228822\n",
      "epoch : 5, loss : 0, val_acc : 0.48828125\n",
      "epoch : 6, loss : 0, tra_acc : 0.5920155793573515\n",
      "epoch : 6, loss : 0, val_acc : 0.4921875\n",
      "epoch : 7, loss : 0, tra_acc : 0.5939629990262901\n",
      "epoch : 7, loss : 0, val_acc : 0.48828125\n",
      "epoch : 8, loss : 0, tra_acc : 0.5920155793573515\n",
      "epoch : 8, loss : 0, val_acc : 0.48828125\n",
      "epoch : 9, loss : 0, tra_acc : 0.5910418695228822\n",
      "epoch : 9, loss : 0, val_acc : 0.48046875\n",
      "epoch : 10, loss : 0, tra_acc : 0.5920155793573515\n",
      "epoch : 10, loss : 0, val_acc : 0.4609375\n",
      "epoch : 11, loss : 0, tra_acc : 0.5968841285296982\n",
      "epoch : 11, loss : 0, val_acc : 0.46484375\n",
      "epoch : 12, loss : 0, tra_acc : 0.5959104186952289\n",
      "epoch : 12, loss : 0, val_acc : 0.46875\n",
      "epoch : 13, loss : 0, tra_acc : 0.5978578383641675\n",
      "epoch : 13, loss : 0, val_acc : 0.4765625\n",
      "epoch : 14, loss : 0, tra_acc : 0.5998052580331061\n",
      "epoch : 14, loss : 0, val_acc : 0.4765625\n",
      "epoch : 15, loss : 0, tra_acc : 0.6027263875365141\n",
      "epoch : 15, loss : 0, val_acc : 0.4765625\n",
      "epoch : 16, loss : 0, tra_acc : 0.6056475170399221\n",
      "epoch : 16, loss : 0, val_acc : 0.4765625\n",
      "epoch : 17, loss : 0, tra_acc : 0.6066212268743915\n",
      "epoch : 17, loss : 0, val_acc : 0.4765625\n",
      "epoch : 18, loss : 0, tra_acc : 0.6105160662122687\n",
      "epoch : 18, loss : 0, val_acc : 0.4765625\n",
      "epoch : 19, loss : 0, tra_acc : 0.6105160662122687\n",
      "epoch : 19, loss : 0, val_acc : 0.46875\n",
      "epoch : 20, loss : 0, tra_acc : 0.611489776046738\n",
      "epoch : 20, loss : 0, val_acc : 0.47265625\n",
      "epoch : 21, loss : 0, tra_acc : 0.611489776046738\n",
      "epoch : 21, loss : 0, val_acc : 0.46875\n",
      "epoch : 22, loss : 0, tra_acc : 0.611489776046738\n",
      "epoch : 22, loss : 0, val_acc : 0.46875\n",
      "epoch : 23, loss : 0, tra_acc : 0.6153846153846154\n",
      "epoch : 23, loss : 0, val_acc : 0.46875\n",
      "epoch : 24, loss : 0, tra_acc : 0.617332035053554\n",
      "epoch : 24, loss : 0, val_acc : 0.46875\n",
      "epoch : 25, loss : 0, tra_acc : 0.6183057448880234\n",
      "epoch : 25, loss : 0, val_acc : 0.47265625\n",
      "epoch : 26, loss : 0, tra_acc : 0.6212268743914313\n",
      "epoch : 26, loss : 0, val_acc : 0.47265625\n",
      "epoch : 27, loss : 0, tra_acc : 0.6222005842259006\n",
      "epoch : 27, loss : 0, val_acc : 0.4765625\n",
      "epoch : 28, loss : 0, tra_acc : 0.6231742940603701\n",
      "epoch : 28, loss : 0, val_acc : 0.4765625\n",
      "epoch : 29, loss : 0, tra_acc : 0.6231742940603701\n",
      "epoch : 29, loss : 0, val_acc : 0.4765625\n",
      "epoch : 30, loss : 0, tra_acc : 0.629016553067186\n",
      "epoch : 30, loss : 0, val_acc : 0.4765625\n",
      "epoch : 31, loss : 0, tra_acc : 0.631937682570594\n",
      "epoch : 31, loss : 0, val_acc : 0.4765625\n",
      "epoch : 32, loss : 0, tra_acc : 0.6358325219084713\n",
      "epoch : 32, loss : 0, val_acc : 0.4765625\n",
      "epoch : 33, loss : 0, tra_acc : 0.6368062317429406\n",
      "epoch : 33, loss : 0, val_acc : 0.47265625\n",
      "epoch : 34, loss : 0, tra_acc : 0.6377799415774099\n",
      "epoch : 34, loss : 0, val_acc : 0.4765625\n",
      "epoch : 35, loss : 0, tra_acc : 0.6387536514118792\n",
      "epoch : 35, loss : 0, val_acc : 0.4765625\n",
      "epoch : 36, loss : 0, tra_acc : 0.6397273612463485\n",
      "epoch : 36, loss : 0, val_acc : 0.4765625\n",
      "epoch : 37, loss : 0, tra_acc : 0.6426484907497566\n",
      "epoch : 37, loss : 0, val_acc : 0.4765625\n",
      "epoch : 38, loss : 0, tra_acc : 0.6445959104186952\n",
      "epoch : 38, loss : 0, val_acc : 0.4765625\n",
      "epoch : 39, loss : 0, tra_acc : 0.6455696202531646\n",
      "epoch : 39, loss : 0, val_acc : 0.4765625\n",
      "epoch : 40, loss : 0, tra_acc : 0.6455696202531646\n",
      "epoch : 40, loss : 0, val_acc : 0.4765625\n",
      "epoch : 41, loss : 0, tra_acc : 0.6436222005842259\n",
      "epoch : 41, loss : 0, val_acc : 0.48046875\n",
      "epoch : 42, loss : 0, tra_acc : 0.6436222005842259\n",
      "epoch : 42, loss : 0, val_acc : 0.48046875\n",
      "epoch : 43, loss : 0, tra_acc : 0.6436222005842259\n",
      "epoch : 43, loss : 0, val_acc : 0.48046875\n",
      "epoch : 44, loss : 0, tra_acc : 0.6445959104186952\n",
      "epoch : 44, loss : 0, val_acc : 0.48046875\n",
      "epoch : 45, loss : 0, tra_acc : 0.6465433300876339\n",
      "epoch : 45, loss : 0, val_acc : 0.484375\n",
      "epoch : 46, loss : 0, tra_acc : 0.6465433300876339\n",
      "epoch : 46, loss : 0, val_acc : 0.484375\n",
      "epoch : 47, loss : 0, tra_acc : 0.6475170399221032\n",
      "epoch : 47, loss : 0, val_acc : 0.484375\n",
      "epoch : 48, loss : 0, tra_acc : 0.6484907497565725\n",
      "epoch : 48, loss : 0, val_acc : 0.484375\n",
      "epoch : 49, loss : 0, tra_acc : 0.6494644595910418\n",
      "epoch : 49, loss : 0, val_acc : 0.48828125\n",
      "epoch : 50, loss : 0, tra_acc : 0.6484907497565725\n",
      "epoch : 50, loss : 0, val_acc : 0.48828125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5b50f3175314>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmachine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-1abb0c1fe16f>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# load training images of the batch size for every iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0;31m# inputs is the images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[1;32m    137\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    877\u001b[0m         \"\"\"\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "machine.training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "machine.show_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine.show_acc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
