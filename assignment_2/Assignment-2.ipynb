{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "\n",
    "Submitter : JESOON KANG, 20170937\n",
    "Date : 2019. 10. 3\n",
    "\n",
    "\n",
    "    Assignment 2. \n",
    "\n",
    "- Binary classification based on logistic regression -\n",
    "\n",
    "\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Image Data import & resize\n",
    "\n",
    "transform = transforms.Compose([#transforms.Resize((256,256)),  \n",
    "                                transforms.Grayscale(),\t\t# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "                                transforms.ToTensor(),])\n",
    "\n",
    "#train_data_path = 'relative path of training data set'\n",
    "train_data_path = './data/horse-or-human/train'\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "# if shuffle=True, the data reshuffled at every epoch \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=False, num_workers=1)  \n",
    "\n",
    "\n",
    "validation_data_path = './data/horse-or-human/validation'\n",
    "valset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=1, shuffle=False, num_workers=1)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid Function.\n",
    "def sigmoid(z) :\n",
    "    return 1 / (1 + math.e ** (-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h(x) Function. hypothesis Func.\n",
    "def hypothesis(weight,X) :\n",
    "    theta = np.array(weight)\n",
    "    z = np.dot(X,theta)\n",
    "    h = sigmoid(z)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "def lossFunction(h,y) :\n",
    "    # if i = 1, it occurs ZeroDivisionError ,\n",
    "    # So, adjust value to 0.995\n",
    "    for i in h :\n",
    "        if i == 1 :\n",
    "            i = 0.995\n",
    "    try : \n",
    "        ret = (-y * np.log(h) - (1-y) * np.log(1-h)).mean()\n",
    "    except ZeroDivisionError :\n",
    "        print(\"Error\")\n",
    "    finally :\n",
    "        return (-y * np.log(h) - (1-y) * np.log(1-h)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict Function. if h(x) returns >=0.5, set to 1. other cases, set to 0.\n",
    "def predict(h, labels) :\n",
    "    mount = len(h)\n",
    "    correct = 0\n",
    "    \n",
    "    for i in range(0,mount) :\n",
    "        if h[i] >= 0.5 :\n",
    "            if labels[i] == 1 :\n",
    "                correct +=1\n",
    "        else :\n",
    "            if labels[i] == 0 :\n",
    "                correct +=1\n",
    "    return correct * (1/mount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data reconstruct. vectorize\n",
    "\n",
    "# Each Image file will be stored shape of a row\n",
    "training_vectorized = []\n",
    "training_labels = []\n",
    "\n",
    "validation_vectorized = []\n",
    "validation_labels = []\n",
    "\n",
    "\n",
    "# Training data vectorizing\n",
    "for i, data in enumerate(trainloader) :\n",
    "    train_data = []\n",
    "    inputs, labels = data\n",
    "\n",
    "    for u in inputs :\n",
    "        for col in u[0] :\n",
    "            train_data += list(col)\n",
    "    training_vectorized.append(train_data)\n",
    "    training_labels.append([labels])\n",
    "\n",
    "training_vectorized = np.array(training_vectorized)\n",
    "training_labels = np.array(training_labels)\n",
    "\n",
    "# Validation data vectorizing\n",
    "for i, data in enumerate(valloader) :\n",
    "    val_data = []\n",
    "    inputs, labels = data\n",
    "    for u in inputs :\n",
    "        for col in u[0] :\n",
    "            val_data += list(col)\n",
    "    validation_vectorized.append(val_data)\n",
    "    validation_labels.append([labels])\n",
    "validation_vectorized = np.array(validation_vectorized)\n",
    "validation_labels = np.array(validation_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initial Setting\n",
    "\n",
    "# Initial Weight Value\n",
    "weight = np.zeros((10000,1),dtype=float)\n",
    "\n",
    "# Learning rate \n",
    "learning_rate = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Log variables setting\n",
    "log_training_loss = []\n",
    "log_validation_loss = []\n",
    "log_iter = []\n",
    "log_training_acc = []\n",
    "log_validation_acc = []\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "log_training_loss.append(1)\n",
    "# Training & Validation\n",
    "\n",
    "while (True):\n",
    "    i += 1\n",
    "    h = hypothesis(weight,training_vectorized)\n",
    "    \n",
    "    gradient = np.dot(training_vectorized.T,h-training_labels) / len(training_vectorized)\n",
    "    \n",
    "    # adjust weight values with gradient value\n",
    "    weight-= learning_rate*gradient    \n",
    "    \n",
    "    # get train loss value\n",
    "    training_loss = lossFunction(h,training_labels)\n",
    "    \n",
    "    # get accuracy\n",
    "    training_acc = predict(h,training_labels)\n",
    "    \n",
    "    \n",
    "    h_validation = hypothesis(weight, validation_vectorized)\n",
    "    validation_loss = lossFunction(h_validation, validation_labels)\n",
    "    validation_acc = predict(h_validation, validation_labels)\n",
    "    \n",
    "    # add log data\n",
    "    log_training_loss.append(training_loss)\n",
    "    log_training_acc.append(training_acc)\n",
    "    \n",
    "    log_validation_loss.append(validation_loss)\n",
    "    log_validation_acc.append(validation_acc)\n",
    "    log_iter.append(i)\n",
    "    \n",
    "    #print(\"iter : \",i, \"  t_loss : \",training_loss,\"  t_acc : \", training_acc,\"  v_loss: \",validation_loss, \"  v_acc: \", validation_acc)\n",
    "    #print(loss_log_train[-1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    if ( (abs(training_loss - log_training_loss[-2]) < 0.0000001) ) :\n",
    "        print(\"loss val is convergenced\")\n",
    "        break\n",
    "    if (i == 10000) :\n",
    "        print(\"EPOCH reached 10000. terminate process\")\n",
    "        break\n",
    "    if (i%100 == 0) :\n",
    "        print(\"Current num_epoch : \",i)\n",
    "    \n",
    "    \n",
    "    \n",
    "print(\"Finished\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log_training_loss[0].remov\n",
    "t1 = plt.plot(log_iter,log_training_loss, color='orange',label='Training Loss')\n",
    "t2 = plt.plot(log_iter,log_validation_loss, color= 'red',label='Validation Loss')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend(['Training Loss','Validation Loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = plt.plot(log_iter,log_training_acc, color='orange',label='Training Acc')\n",
    "t2 = plt.plot(log_iter,log_validation_acc, color= 'red',label='Validation Acc')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(['Training Acc','Validation Acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commit Point."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
