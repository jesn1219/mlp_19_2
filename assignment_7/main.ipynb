{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# import packages\n",
    "# -----------------------------------------------------------------------------\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime \n",
    "import csv\n",
    "import configparser\n",
    "import argparse\n",
    "import platform\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from random import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "GeForce GTX 1050\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "### Setting up Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Below codes activates when want to use cpu\n",
    "#device = torch.device('cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "\n",
    "        super(Linear, self).__init__()\n",
    "\n",
    "        self.number_class   = num_classes\n",
    "\n",
    "        _size_image     = 100* 100\n",
    "        _num1           = 5000\n",
    "        _num2           = 1000\n",
    "        \n",
    "        self.fc1        = nn.Linear(_size_image, _num1, bias=True)\n",
    "        self.fc2        = nn.Linear(_num1, _num2, bias=True)\n",
    "        self.fc3        = nn.Linear(_num2, num_classes, bias=True)\n",
    "        \n",
    "        self.fc_layer1  = nn.Sequential(self.fc1, nn.ReLU(True))\n",
    "        self.fc_layer2  = nn.Sequential(self.fc2, nn.ReLU(True))\n",
    "        self.fc_layer3  = nn.Sequential(self.fc3, nn.ReLU(True))\n",
    "        self.classifier = nn.Sequential(self.fc_layer1, self.fc_layer2, self.fc_layer3)\n",
    "        \n",
    "        self._initialize_weight()        \n",
    "    \n",
    "    def _initialize_weight(self) :\n",
    "        for m in self.modules() :\n",
    "            n = m.in_features\n",
    "            m.weight.data.uniform_(-1.0 / math.sqrt(n), 1.0/math.sqrt(n))\n",
    "            if m.bias is not None :\n",
    "                m.bias.data.zero_()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "    '''\n",
    "    def forward(self, x) :\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    '''\n",
    "    def modules(self) :\n",
    "        return [self.fc1,self.fc2,self.fc3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# load dataset\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "transform = transforms.Compose([#transforms.Resize((256,256)),  \n",
    "                                transforms.Grayscale(),\t\t# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "                                transforms.ToTensor(),])\n",
    "\n",
    "train_data_path = '../data/horse-or-human/train'\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "# if shuffle=True, the data reshuffled at every epoch \n",
    "loader_train = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=3)  \n",
    "\n",
    "\n",
    "validation_data_path = '../data/horse-or-human/validation'\n",
    "valset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "loader_test = torch.utils.data.DataLoader(valset, batch_size=100, shuffle=False, num_workers=3)  \n",
    "\n",
    "\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# load neural network model\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "model = Linear(num_classes=num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Set the flag for using cuda\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "bCuda = 1\n",
    "\n",
    "if bCuda:\n",
    " \n",
    "    model.cuda()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# optimization algorithm\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "learning_rate = 0.0005\n",
    "\n",
    "# weight decay applyed\n",
    "optimizer   = optim.SGD(model.parameters(), lr = learning_rate, weight_decay = 0.00001 )\n",
    "objective   = nn.CrossEntropyLoss()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# function for training the model\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def train():\n",
    "\n",
    "    # print('train the model at given epoch')\n",
    "\n",
    "    loss_train = []\n",
    "\n",
    "    accuracy_train   = []\n",
    "    correct          = 0\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for idx_batch, (data, target) in enumerate(loader_train):\n",
    "\n",
    "        if bCuda:\n",
    "        \n",
    "            data, target    = data.cuda(), target.cuda()\n",
    "\n",
    "        data, target    = Variable(data), Variable(target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output  = model(data)\n",
    "        loss    = objective(output, target)\n",
    "\n",
    "        # train acc\n",
    "        pred        = output.data.max(1)[1]\n",
    "        correct     += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "        accuracy_train.append(correct / len(data))\n",
    "        ##\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train_batch    = loss.item() / len(data)\n",
    "        loss_train.append(loss_train_batch)\n",
    "        \n",
    "              \n",
    "        \n",
    "    loss_train_epoch     = np.mean(loss_train)\n",
    "    loss_train_std      = np.std(loss_train)\n",
    "    accuracy_train_std = np.std(accuracy_train)\n",
    "    accuracy_train_epoch   = 100. * float(correct) / len(loader_train.dataset)\n",
    "    return {'loss_train_epoch': loss_train_epoch, 'loss_train_std': loss_train_std, 'accuracy_train_epoch' : accuracy_train_epoch, 'accuracy_train_std' : accuracy_train_std}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   0| loss : (train) 0.00860963 (testing) 0.00797729 | accuracy : (train) 54.0408958 (testing)  52.734375\n",
      "epoch :   1| loss : (train) 0.00854068 (testing) 0.00791385 | accuracy : (train) 55.3067185 (testing)    51.5625\n",
      "epoch :   2| loss : (train) 0.00850175 (testing) 0.00786009 | accuracy : (train) 54.3330087 (testing)       50.0\n",
      "epoch :   3| loss : (train) 0.00853291 (testing) 0.00781809 | accuracy : (train) 52.9698149 (testing)       50.0\n",
      "epoch :   4| loss : (train) 0.00843607 (testing) 0.00777336 | accuracy : (train) 53.2619279 (testing)       50.0\n",
      "epoch :   5| loss : (train) 0.00843958 (testing) 0.00773624 | accuracy : (train) 53.0671859 (testing)       50.0\n",
      "epoch :   6| loss : (train) 0.00842845 (testing) 0.00770167 | accuracy : (train) 52.8724440 (testing)       50.0\n",
      "epoch :   7| loss : (train) 0.00845865 (testing) 0.00767236 | accuracy : (train) 53.8461538 (testing)  50.390625\n",
      "epoch :   8| loss : (train) 0.00840421 (testing) 0.00763865 | accuracy : (train) 54.4303797 (testing)  50.390625\n",
      "epoch :   9| loss : (train) 0.00833262 (testing) 0.00760628 | accuracy : (train) 54.6251217 (testing)  50.390625\n",
      "epoch :  10| loss : (train) 0.00829972 (testing) 0.00757645 | accuracy : (train) 54.4303797 (testing)   50.78125\n",
      "epoch :  11| loss : (train) 0.00838556 (testing) 0.00755381 | accuracy : (train) 54.8198636 (testing)   52.34375\n",
      "epoch :  12| loss : (train) 0.00841389 (testing) 0.00753175 | accuracy : (train) 55.0146056 (testing)     53.125\n",
      "epoch :  13| loss : (train) 0.00841714 (testing) 0.00750518 | accuracy : (train) 55.6962025 (testing)  54.296875\n",
      "epoch :  14| loss : (train) 0.00828967 (testing) 0.00747124 | accuracy : (train) 55.6962025 (testing)     53.125\n",
      "epoch :  15| loss : (train) 0.00829456 (testing) 0.00744986 | accuracy : (train) 55.7935735 (testing)  55.859375\n",
      "epoch :  16| loss : (train) 0.00818991 (testing) 0.00740951 | accuracy : (train) 58.2278481 (testing)  53.515625\n",
      "epoch :  17| loss : (train) 0.00821423 (testing) 0.00738370 | accuracy : (train) 55.9883154 (testing)  54.296875\n",
      "epoch :  18| loss : (train) 0.00821334 (testing) 0.00735841 | accuracy : (train) 56.2804284 (testing)  55.859375\n",
      "epoch :  19| loss : (train) 0.00827584 (testing) 0.00733961 | accuracy : (train) 57.1567672 (testing)    60.9375\n",
      "epoch :  20| loss : (train) 0.00821542 (testing) 0.00730945 | accuracy : (train) 59.0068159 (testing)    60.9375\n",
      "epoch :  21| loss : (train) 0.00820863 (testing) 0.00728606 | accuracy : (train) 59.2015579 (testing)  62.890625\n",
      "epoch :  22| loss : (train) 0.00821054 (testing) 0.00725783 | accuracy : (train) 60.8568646 (testing)       62.5\n",
      "epoch :  23| loss : (train) 0.00811681 (testing) 0.00722664 | accuracy : (train) 60.8568646 (testing)    60.9375\n",
      "epoch :  24| loss : (train) 0.00822696 (testing) 0.00720509 | accuracy : (train) 60.2726387 (testing)  64.453125\n",
      "epoch :  25| loss : (train) 0.00816763 (testing) 0.00718192 | accuracy : (train) 60.4673807 (testing)     65.625\n",
      "epoch :  26| loss : (train) 0.00812723 (testing) 0.00715449 | accuracy : (train) 61.7332035 (testing)   64.84375\n",
      "epoch :  27| loss : (train) 0.00809060 (testing) 0.00712902 | accuracy : (train) 62.0253164 (testing)   64.84375\n",
      "epoch :  28| loss : (train) 0.00803844 (testing) 0.00710767 | accuracy : (train) 60.7594936 (testing)  68.359375\n",
      "epoch :  29| loss : (train) 0.00800004 (testing) 0.00708152 | accuracy : (train) 62.3174294 (testing)  69.140625\n",
      "epoch :  30| loss : (train) 0.00807463 (testing) 0.00706205 | accuracy : (train) 62.0253164 (testing)   74.21875\n",
      "epoch :  31| loss : (train) 0.00808272 (testing) 0.00703901 | accuracy : (train) 63.5832521 (testing)   74.21875\n",
      "epoch :  32| loss : (train) 0.00802062 (testing) 0.00701354 | accuracy : (train) 64.0701071 (testing)   74.21875\n",
      "epoch :  33| loss : (train) 0.00805852 (testing) 0.00699311 | accuracy : (train) 64.0701071 (testing)  76.171875\n",
      "epoch :  34| loss : (train) 0.00806885 (testing) 0.00697036 | accuracy : (train) 65.2385589 (testing)  76.953125\n",
      "epoch :  35| loss : (train) 0.00797352 (testing) 0.00694527 | accuracy : (train) 66.1148977 (testing)    76.5625\n",
      "epoch :  36| loss : (train) 0.00800676 (testing) 0.00692636 | accuracy : (train) 65.3359298 (testing)    79.6875\n",
      "epoch :  37| loss : (train) 0.00794762 (testing) 0.00689853 | accuracy : (train) 67.5754625 (testing)     78.125\n",
      "epoch :  38| loss : (train) 0.00792505 (testing) 0.00687479 | accuracy : (train) 66.1148977 (testing)  78.515625\n",
      "epoch :  39| loss : (train) 0.00796192 (testing) 0.00685401 | accuracy : (train) 66.5043816 (testing)  80.078125\n",
      "epoch :  40| loss : (train) 0.00797219 (testing) 0.00683320 | accuracy : (train) 66.7964946 (testing)  82.421875\n",
      "epoch :  41| loss : (train) 0.00800731 (testing) 0.00681303 | accuracy : (train) 67.7702044 (testing)    82.8125\n",
      "epoch :  42| loss : (train) 0.00791544 (testing) 0.00678666 | accuracy : (train) 69.1333982 (testing)  82.421875\n",
      "epoch :  43| loss : (train) 0.00785173 (testing) 0.00676361 | accuracy : (train) 68.9386562 (testing)  82.421875\n",
      "epoch :  44| loss : (train) 0.00788508 (testing) 0.00674129 | accuracy : (train) 68.5491723 (testing)  83.203125\n",
      "epoch :  45| loss : (train) 0.00780058 (testing) 0.00671614 | accuracy : (train) 69.5228821 (testing)  82.421875\n",
      "epoch :  46| loss : (train) 0.00792613 (testing) 0.00670440 | accuracy : (train) 68.4518013 (testing)  84.765625\n",
      "epoch :  47| loss : (train) 0.00785273 (testing) 0.00668040 | accuracy : (train) 70.3992210 (testing)   85.15625\n",
      "epoch :  48| loss : (train) 0.00772846 (testing) 0.00665067 | accuracy : (train) 71.3729308 (testing)  83.984375\n",
      "epoch :  49| loss : (train) 0.00776546 (testing) 0.00662756 | accuracy : (train) 70.2044790 (testing)  83.984375\n",
      "epoch :  50| loss : (train) 0.00780769 (testing) 0.00661310 | accuracy : (train) 70.1071080 (testing)   85.15625\n",
      "epoch :  51| loss : (train) 0.00781187 (testing) 0.00658913 | accuracy : (train) 72.2492697 (testing)   85.15625\n",
      "epoch :  52| loss : (train) 0.00773511 (testing) 0.00656600 | accuracy : (train) 71.5676728 (testing)   85.15625\n",
      "epoch :  53| loss : (train) 0.00774062 (testing) 0.00654646 | accuracy : (train) 71.4703018 (testing)   85.15625\n",
      "epoch :  54| loss : (train) 0.00778913 (testing) 0.00652843 | accuracy : (train) 71.2755598 (testing)  85.546875\n",
      "epoch :  55| loss : (train) 0.00773739 (testing) 0.00649970 | accuracy : (train) 73.4177215 (testing)   85.15625\n",
      "epoch :  56| loss : (train) 0.00777342 (testing) 0.00647869 | accuracy : (train) 72.1518987 (testing)   85.15625\n",
      "epoch :  57| loss : (train) 0.00764898 (testing) 0.00645577 | accuracy : (train) 72.2492697 (testing)   85.15625\n",
      "epoch :  58| loss : (train) 0.00768784 (testing) 0.00643153 | accuracy : (train) 71.9571567 (testing)   85.15625\n",
      "epoch :  59| loss : (train) 0.00758727 (testing) 0.00640639 | accuracy : (train) 72.1518987 (testing)     84.375\n",
      "epoch :  60| loss : (train) 0.00779431 (testing) 0.00639944 | accuracy : (train) 71.3729308 (testing)    85.9375\n",
      "epoch :  61| loss : (train) 0.00758860 (testing) 0.00637141 | accuracy : (train) 72.8334956 (testing)  85.546875\n",
      "epoch :  62| loss : (train) 0.00766747 (testing) 0.00634840 | accuracy : (train) 72.8334956 (testing)  85.546875\n",
      "epoch :  63| loss : (train) 0.00742685 (testing) 0.00632571 | accuracy : (train) 72.6387536 (testing)  85.546875\n",
      "epoch :  64| loss : (train) 0.00757867 (testing) 0.00629758 | accuracy : (train) 73.1256085 (testing)   85.15625\n",
      "epoch :  65| loss : (train) 0.00754882 (testing) 0.00628463 | accuracy : (train) 71.4703018 (testing)    85.9375\n",
      "epoch :  66| loss : (train) 0.00756498 (testing) 0.00625898 | accuracy : (train) 73.3203505 (testing)  85.546875\n",
      "epoch :  67| loss : (train) 0.00742492 (testing) 0.00623431 | accuracy : (train) 72.8334956 (testing)   85.15625\n",
      "epoch :  68| loss : (train) 0.00754940 (testing) 0.00621875 | accuracy : (train) 72.6387536 (testing)    85.9375\n",
      "epoch :  69| loss : (train) 0.00756523 (testing) 0.00619370 | accuracy : (train) 73.6124634 (testing)  85.546875\n",
      "epoch :  70| loss : (train) 0.00749650 (testing) 0.00617467 | accuracy : (train) 73.0282375 (testing)  85.546875\n",
      "epoch :  71| loss : (train) 0.00763791 (testing) 0.00617000 | accuracy : (train) 72.9308666 (testing)    85.9375\n",
      "epoch :  72| loss : (train) 0.00730511 (testing) 0.00613964 | accuracy : (train) 73.9045764 (testing)  85.546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  73| loss : (train) 0.00758884 (testing) 0.00611415 | accuracy : (train) 74.0019474 (testing)  86.328125\n",
      "epoch :  74| loss : (train) 0.00739481 (testing) 0.00609453 | accuracy : (train) 74.1966893 (testing)  85.546875\n",
      "epoch :  75| loss : (train) 0.00735205 (testing) 0.00607114 | accuracy : (train) 73.3203505 (testing)  86.328125\n",
      "epoch :  76| loss : (train) 0.00734394 (testing) 0.00605151 | accuracy : (train) 74.1966893 (testing)    85.9375\n",
      "epoch :  77| loss : (train) 0.00750058 (testing) 0.00603203 | accuracy : (train) 74.0993184 (testing)  85.546875\n",
      "epoch :  78| loss : (train) 0.00747058 (testing) 0.00602701 | accuracy : (train) 74.1966893 (testing)   86.71875\n",
      "epoch :  79| loss : (train) 0.00752651 (testing) 0.00599085 | accuracy : (train) 74.7809152 (testing)  85.546875\n",
      "epoch :  80| loss : (train) 0.00730582 (testing) 0.00597249 | accuracy : (train) 74.0993184 (testing)    85.9375\n",
      "epoch :  81| loss : (train) 0.00735085 (testing) 0.00595761 | accuracy : (train) 74.3914313 (testing)   86.71875\n",
      "epoch :  82| loss : (train) 0.00728111 (testing) 0.00592765 | accuracy : (train) 74.6835443 (testing)    85.9375\n",
      "epoch :  83| loss : (train) 0.00751596 (testing) 0.00592874 | accuracy : (train) 74.0019474 (testing)   86.71875\n",
      "epoch :  84| loss : (train) 0.00735101 (testing) 0.00590058 | accuracy : (train) 74.3914313 (testing)  86.328125\n",
      "epoch :  85| loss : (train) 0.00746910 (testing) 0.00588424 | accuracy : (train) 74.9756572 (testing)   86.71875\n",
      "epoch :  86| loss : (train) 0.00739474 (testing) 0.00586684 | accuracy : (train) 75.1703992 (testing)   86.71875\n",
      "epoch :  87| loss : (train) 0.00721334 (testing) 0.00583332 | accuracy : (train) 75.1703992 (testing)   86.71875\n",
      "epoch :  88| loss : (train) 0.00721955 (testing) 0.00582596 | accuracy : (train) 74.6835443 (testing)       87.5\n",
      "epoch :  89| loss : (train) 0.00732202 (testing) 0.00580986 | accuracy : (train) 75.2677702 (testing)  87.890625\n",
      "epoch :  90| loss : (train) 0.00738110 (testing) 0.00577441 | accuracy : (train) 75.1703992 (testing)   86.71875\n",
      "epoch :  91| loss : (train) 0.00732637 (testing) 0.00576740 | accuracy : (train) 75.1703992 (testing)   88.28125\n",
      "epoch :  92| loss : (train) 0.00732025 (testing) 0.00572801 | accuracy : (train) 75.0730282 (testing)  86.328125\n",
      "epoch :  93| loss : (train) 0.00739542 (testing) 0.00571453 | accuracy : (train) 75.2677702 (testing)   86.71875\n",
      "epoch :  94| loss : (train) 0.00718838 (testing) 0.00568484 | accuracy : (train) 75.0730282 (testing)  86.328125\n",
      "epoch :  95| loss : (train) 0.00723952 (testing) 0.00566408 | accuracy : (train) 74.7809152 (testing)  86.328125\n",
      "epoch :  96| loss : (train) 0.00729831 (testing) 0.00564862 | accuracy : (train) 74.7809152 (testing)   86.71875\n",
      "epoch :  97| loss : (train) 0.00717744 (testing) 0.00563598 | accuracy : (train) 75.2677702 (testing)       87.5\n",
      "epoch :  98| loss : (train) 0.00726390 (testing) 0.00563588 | accuracy : (train) 75.5598831 (testing)  87.890625\n",
      "epoch :  99| loss : (train) 0.00712801 (testing) 0.00560551 | accuracy : (train) 75.7546251 (testing)       87.5\n",
      "epoch : 100| loss : (train) 0.00716800 (testing) 0.00558974 | accuracy : (train) 75.4625121 (testing)  87.890625\n",
      "epoch : 101| loss : (train) 0.00722010 (testing) 0.00556450 | accuracy : (train) 75.3651411 (testing)       87.5\n",
      "epoch : 102| loss : (train) 0.00713824 (testing) 0.00555257 | accuracy : (train) 75.6572541 (testing)   88.28125\n",
      "epoch : 103| loss : (train) 0.00709732 (testing) 0.00551093 | accuracy : (train) 76.1441090 (testing)   88.28125\n",
      "epoch : 104| loss : (train) 0.00717208 (testing) 0.00547365 | accuracy : (train) 75.3651411 (testing)  86.328125\n",
      "epoch : 105| loss : (train) 0.00709141 (testing) 0.00546923 | accuracy : (train) 74.9756572 (testing)   88.28125\n",
      "epoch : 106| loss : (train) 0.00711145 (testing) 0.00544835 | accuracy : (train) 75.3651411 (testing)   88.28125\n",
      "epoch : 107| loss : (train) 0.00715336 (testing) 0.00543302 | accuracy : (train) 75.3651411 (testing)  87.890625\n",
      "epoch : 108| loss : (train) 0.00722658 (testing) 0.00541723 | accuracy : (train) 75.8519961 (testing)       87.5\n",
      "epoch : 109| loss : (train) 0.00700842 (testing) 0.00537485 | accuracy : (train) 75.6572541 (testing)   86.71875\n",
      "epoch : 110| loss : (train) 0.00703780 (testing) 0.00537475 | accuracy : (train) 75.1703992 (testing)       87.5\n",
      "epoch : 111| loss : (train) 0.00711614 (testing) 0.00535241 | accuracy : (train) 76.3388510 (testing)  87.890625\n",
      "epoch : 112| loss : (train) 0.00700904 (testing) 0.00533871 | accuracy : (train) 75.8519961 (testing)       87.5\n",
      "epoch : 113| loss : (train) 0.00699854 (testing) 0.00530532 | accuracy : (train) 76.0467380 (testing)   88.28125\n",
      "epoch : 114| loss : (train) 0.00697923 (testing) 0.00527900 | accuracy : (train) 76.2414800 (testing)       87.5\n",
      "epoch : 115| loss : (train) 0.00699097 (testing) 0.00526219 | accuracy : (train) 75.5598831 (testing)       87.5\n",
      "epoch : 116| loss : (train) 0.00700947 (testing) 0.00524185 | accuracy : (train) 76.3388510 (testing)       87.5\n",
      "epoch : 117| loss : (train) 0.00695806 (testing) 0.00522033 | accuracy : (train) 76.1441090 (testing)       87.5\n",
      "epoch : 118| loss : (train) 0.00690855 (testing) 0.00519583 | accuracy : (train) 75.9493670 (testing)   86.71875\n",
      "epoch : 119| loss : (train) 0.00694968 (testing) 0.00517662 | accuracy : (train) 75.7546251 (testing)   86.71875\n",
      "epoch : 120| loss : (train) 0.00712120 (testing) 0.00519593 | accuracy : (train) 75.3651411 (testing)  88.671875\n",
      "epoch : 121| loss : (train) 0.00686328 (testing) 0.00519803 | accuracy : (train) 76.4362220 (testing)    89.0625\n",
      "epoch : 122| loss : (train) 0.00698350 (testing) 0.00517360 | accuracy : (train) 76.7283349 (testing)  88.671875\n",
      "epoch : 123| loss : (train) 0.00669349 (testing) 0.00511038 | accuracy : (train) 77.4099318 (testing)   88.28125\n",
      "epoch : 124| loss : (train) 0.00693247 (testing) 0.00509810 | accuracy : (train) 76.3388510 (testing)       87.5\n",
      "epoch : 125| loss : (train) 0.00685049 (testing) 0.00510485 | accuracy : (train) 76.2414800 (testing)  88.671875\n",
      "epoch : 126| loss : (train) 0.00683313 (testing) 0.00510119 | accuracy : (train) 76.7283349 (testing)    89.0625\n",
      "epoch : 127| loss : (train) 0.00671268 (testing) 0.00505290 | accuracy : (train) 77.1178188 (testing)   88.28125\n",
      "epoch : 128| loss : (train) 0.00676081 (testing) 0.00504546 | accuracy : (train) 76.8257059 (testing)  88.671875\n",
      "epoch : 129| loss : (train) 0.00680309 (testing) 0.00501253 | accuracy : (train) 77.6046738 (testing)  87.890625\n",
      "epoch : 130| loss : (train) 0.00690082 (testing) 0.00501187 | accuracy : (train) 76.8257059 (testing)  88.671875\n",
      "epoch : 131| loss : (train) 0.00674492 (testing) 0.00498355 | accuracy : (train) 77.5073028 (testing)  88.671875\n",
      "epoch : 132| loss : (train) 0.00688090 (testing) 0.00495932 | accuracy : (train) 77.5073028 (testing)   88.28125\n",
      "epoch : 133| loss : (train) 0.00688094 (testing) 0.00497693 | accuracy : (train) 77.3125608 (testing)  87.890625\n",
      "epoch : 134| loss : (train) 0.00687873 (testing) 0.00494260 | accuracy : (train) 77.7994157 (testing)  88.671875\n",
      "epoch : 135| loss : (train) 0.00674564 (testing) 0.00490408 | accuracy : (train) 77.7994157 (testing)   88.28125\n",
      "epoch : 136| loss : (train) 0.00676064 (testing) 0.00492700 | accuracy : (train) 76.7283349 (testing)       87.5\n",
      "epoch : 137| loss : (train) 0.00643850 (testing) 0.00485666 | accuracy : (train) 77.9941577 (testing)       87.5\n",
      "epoch : 138| loss : (train) 0.00667236 (testing) 0.00484956 | accuracy : (train) 77.2151898 (testing)   88.28125\n",
      "epoch : 139| loss : (train) 0.00679342 (testing) 0.00485584 | accuracy : (train) 77.1178188 (testing)  88.671875\n",
      "epoch : 140| loss : (train) 0.00643635 (testing) 0.00480806 | accuracy : (train) 77.4099318 (testing)  87.890625\n",
      "epoch : 141| loss : (train) 0.00663290 (testing) 0.00480827 | accuracy : (train) 77.2151898 (testing)  88.671875\n",
      "epoch : 142| loss : (train) 0.00665305 (testing) 0.00477191 | accuracy : (train) 77.9941577 (testing)  87.890625\n",
      "epoch : 143| loss : (train) 0.00660794 (testing) 0.00475575 | accuracy : (train) 77.3125608 (testing)   88.28125\n",
      "epoch : 144| loss : (train) 0.00671683 (testing) 0.00478091 | accuracy : (train) 77.1178188 (testing)  87.890625\n",
      "epoch : 145| loss : (train) 0.00662053 (testing) 0.00474695 | accuracy : (train) 78.0915287 (testing)  88.671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 146| loss : (train) 0.00663169 (testing) 0.00473132 | accuracy : (train) 78.1888997 (testing)  88.671875\n",
      "epoch : 147| loss : (train) 0.00654989 (testing) 0.00471005 | accuracy : (train) 78.2862706 (testing)  88.671875\n",
      "epoch : 148| loss : (train) 0.00678678 (testing) 0.00473932 | accuracy : (train) 77.7020447 (testing)       87.5\n",
      "epoch : 149| loss : (train) 0.00662116 (testing) 0.00467789 | accuracy : (train) 78.5783836 (testing)  88.671875\n",
      "epoch : 150| loss : (train) 0.00670485 (testing) 0.00466708 | accuracy : (train) 78.0915287 (testing)  88.671875\n",
      "epoch : 151| loss : (train) 0.00665779 (testing) 0.00465107 | accuracy : (train) 78.1888997 (testing)  88.671875\n",
      "epoch : 152| loss : (train) 0.00666981 (testing) 0.00463678 | accuracy : (train) 78.3836416 (testing)    89.0625\n",
      "epoch : 153| loss : (train) 0.00634720 (testing) 0.00463466 | accuracy : (train) 77.9941577 (testing)       87.5\n",
      "epoch : 154| loss : (train) 0.00641564 (testing) 0.00458921 | accuracy : (train) 78.5783836 (testing)  88.671875\n",
      "epoch : 155| loss : (train) 0.00663800 (testing) 0.00458952 | accuracy : (train) 78.4810126 (testing)   88.28125\n",
      "epoch : 156| loss : (train) 0.00646028 (testing) 0.00458013 | accuracy : (train) 78.4810126 (testing)       87.5\n",
      "epoch : 157| loss : (train) 0.00660540 (testing) 0.00458052 | accuracy : (train) 78.4810126 (testing)       87.5\n",
      "epoch : 158| loss : (train) 0.00637616 (testing) 0.00457186 | accuracy : (train) 78.1888997 (testing)  87.109375\n",
      "epoch : 159| loss : (train) 0.00642215 (testing) 0.00453994 | accuracy : (train) 78.6757546 (testing)  87.109375\n",
      "epoch : 160| loss : (train) 0.00659531 (testing) 0.00451536 | accuracy : (train) 78.7731256 (testing)       87.5\n",
      "epoch : 161| loss : (train) 0.00663783 (testing) 0.00447948 | accuracy : (train) 78.4810126 (testing)  88.671875\n",
      "epoch : 162| loss : (train) 0.00656153 (testing) 0.00447953 | accuracy : (train) 78.0915287 (testing)  87.890625\n",
      "epoch : 163| loss : (train) 0.00664791 (testing) 0.00445488 | accuracy : (train) 79.0652385 (testing)  88.671875\n",
      "epoch : 164| loss : (train) 0.00642856 (testing) 0.00446703 | accuracy : (train) 78.4810126 (testing)       87.5\n",
      "epoch : 165| loss : (train) 0.00652827 (testing) 0.00444694 | accuracy : (train) 78.6757546 (testing)  87.109375\n",
      "epoch : 166| loss : (train) 0.00659002 (testing) 0.00443905 | accuracy : (train) 78.7731256 (testing)       87.5\n",
      "epoch : 167| loss : (train) 0.00614983 (testing) 0.00441634 | accuracy : (train) 79.1626095 (testing)  87.109375\n",
      "epoch : 168| loss : (train) 0.00634619 (testing) 0.00439024 | accuracy : (train) 78.8704965 (testing)       87.5\n",
      "epoch : 169| loss : (train) 0.00624515 (testing) 0.00437620 | accuracy : (train) 78.9678675 (testing)       87.5\n",
      "epoch : 170| loss : (train) 0.00643674 (testing) 0.00437508 | accuracy : (train) 78.8704965 (testing)       87.5\n",
      "epoch : 171| loss : (train) 0.00625205 (testing) 0.00438272 | accuracy : (train) 78.3836416 (testing)  87.109375\n",
      "epoch : 172| loss : (train) 0.00636262 (testing) 0.00437561 | accuracy : (train) 79.3573515 (testing)  87.109375\n",
      "epoch : 173| loss : (train) 0.00640150 (testing) 0.00431133 | accuracy : (train) 79.0652385 (testing)  87.890625\n",
      "epoch : 174| loss : (train) 0.00626508 (testing) 0.00434779 | accuracy : (train) 78.7731256 (testing)  87.109375\n",
      "epoch : 175| loss : (train) 0.00621315 (testing) 0.00429612 | accuracy : (train) 79.2599805 (testing)       87.5\n",
      "epoch : 176| loss : (train) 0.00621829 (testing) 0.00427319 | accuracy : (train) 79.1626095 (testing)       87.5\n",
      "epoch : 177| loss : (train) 0.00608141 (testing) 0.00429083 | accuracy : (train) 79.0652385 (testing)  87.109375\n",
      "epoch : 178| loss : (train) 0.00606404 (testing) 0.00429654 | accuracy : (train) 79.2599805 (testing)  87.109375\n",
      "epoch : 179| loss : (train) 0.00631978 (testing) 0.00425557 | accuracy : (train) 79.4547224 (testing)       87.5\n",
      "epoch : 180| loss : (train) 0.00638125 (testing) 0.00422010 | accuracy : (train) 78.9678675 (testing)       87.5\n",
      "epoch : 181| loss : (train) 0.00604958 (testing) 0.00419602 | accuracy : (train) 78.6757546 (testing)       87.5\n",
      "epoch : 182| loss : (train) 0.00627682 (testing) 0.00417757 | accuracy : (train) 79.2599805 (testing)   88.28125\n",
      "epoch : 183| loss : (train) 0.00616951 (testing) 0.00419264 | accuracy : (train) 79.1626095 (testing)       87.5\n",
      "epoch : 184| loss : (train) 0.00609728 (testing) 0.00421769 | accuracy : (train) 79.2599805 (testing)  87.109375\n",
      "epoch : 185| loss : (train) 0.00599455 (testing) 0.00415728 | accuracy : (train) 79.7468354 (testing)       87.5\n",
      "epoch : 186| loss : (train) 0.00644801 (testing) 0.00416020 | accuracy : (train) 79.3573515 (testing)       87.5\n",
      "epoch : 187| loss : (train) 0.00626471 (testing) 0.00417703 | accuracy : (train) 79.4547224 (testing)  87.109375\n",
      "epoch : 188| loss : (train) 0.00602044 (testing) 0.00413562 | accuracy : (train) 79.5520934 (testing)       87.5\n",
      "epoch : 189| loss : (train) 0.00615639 (testing) 0.00412549 | accuracy : (train) 79.5520934 (testing)       87.5\n",
      "epoch : 190| loss : (train) 0.00609692 (testing) 0.00413913 | accuracy : (train) 79.2599805 (testing)  87.109375\n",
      "epoch : 191| loss : (train) 0.00609777 (testing) 0.00407655 | accuracy : (train) 79.6494644 (testing)       87.5\n",
      "epoch : 192| loss : (train) 0.00619356 (testing) 0.00407685 | accuracy : (train) 79.3573515 (testing)       87.5\n",
      "epoch : 193| loss : (train) 0.00592111 (testing) 0.00408835 | accuracy : (train) 79.7468354 (testing)  87.109375\n",
      "epoch : 194| loss : (train) 0.00612857 (testing) 0.00406842 | accuracy : (train) 79.7468354 (testing)       87.5\n",
      "epoch : 195| loss : (train) 0.00603732 (testing) 0.00400994 | accuracy : (train) 79.7468354 (testing)  87.890625\n",
      "epoch : 196| loss : (train) 0.00613583 (testing) 0.00403661 | accuracy : (train) 79.5520934 (testing)       87.5\n",
      "epoch : 197| loss : (train) 0.00593002 (testing) 0.00397910 | accuracy : (train) 79.6494644 (testing)  87.890625\n",
      "epoch : 198| loss : (train) 0.00592572 (testing) 0.00396455 | accuracy : (train) 79.3573515 (testing)   88.28125\n",
      "epoch : 199| loss : (train) 0.00619177 (testing) 0.00402189 | accuracy : (train) 78.9678675 (testing)       87.5\n",
      "epoch : 200| loss : (train) 0.00616224 (testing) 0.00409007 | accuracy : (train) 79.7468354 (testing)  87.109375\n",
      "epoch : 201| loss : (train) 0.00590468 (testing) 0.00399998 | accuracy : (train) 79.8442064 (testing)  87.109375\n",
      "epoch : 202| loss : (train) 0.00585586 (testing) 0.00399498 | accuracy : (train) 80.0389483 (testing)  87.109375\n",
      "epoch : 203| loss : (train) 0.00587493 (testing) 0.00392049 | accuracy : (train) 80.0389483 (testing)  87.890625\n",
      "epoch : 204| loss : (train) 0.00622016 (testing) 0.00394353 | accuracy : (train) 79.5520934 (testing)       87.5\n",
      "epoch : 205| loss : (train) 0.00602565 (testing) 0.00398208 | accuracy : (train) 79.9415774 (testing)  86.328125\n",
      "epoch : 206| loss : (train) 0.00602545 (testing) 0.00397429 | accuracy : (train) 79.9415774 (testing)  86.328125\n",
      "epoch : 207| loss : (train) 0.00609306 (testing) 0.00403059 | accuracy : (train) 80.1363193 (testing)       87.5\n",
      "epoch : 208| loss : (train) 0.00602228 (testing) 0.00399901 | accuracy : (train) 79.9415774 (testing)  87.109375\n",
      "epoch : 209| loss : (train) 0.00580699 (testing) 0.00394610 | accuracy : (train) 79.7468354 (testing)  86.328125\n",
      "epoch : 210| loss : (train) 0.00585914 (testing) 0.00387635 | accuracy : (train) 80.2336903 (testing)       87.5\n",
      "epoch : 211| loss : (train) 0.00594230 (testing) 0.00387599 | accuracy : (train) 80.0389483 (testing)       87.5\n",
      "epoch : 212| loss : (train) 0.00597607 (testing) 0.00391557 | accuracy : (train) 80.0389483 (testing)  86.328125\n",
      "epoch : 213| loss : (train) 0.00583542 (testing) 0.00385218 | accuracy : (train) 80.1363193 (testing)       87.5\n",
      "epoch : 214| loss : (train) 0.00553522 (testing) 0.00390652 | accuracy : (train) 80.0389483 (testing)  86.328125\n",
      "epoch : 215| loss : (train) 0.00606771 (testing) 0.00390042 | accuracy : (train) 80.1363193 (testing)  86.328125\n",
      "epoch : 216| loss : (train) 0.00591818 (testing) 0.00387980 | accuracy : (train) 80.0389483 (testing)  86.328125\n",
      "epoch : 217| loss : (train) 0.00573172 (testing) 0.00382792 | accuracy : (train) 80.1363193 (testing)  87.109375\n",
      "epoch : 218| loss : (train) 0.00602811 (testing) 0.00381596 | accuracy : (train) 80.2336903 (testing)       87.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 219| loss : (train) 0.00571580 (testing) 0.00382803 | accuracy : (train) 80.2336903 (testing)   86.71875\n",
      "epoch : 220| loss : (train) 0.00587462 (testing) 0.00384142 | accuracy : (train) 80.0389483 (testing)  86.328125\n",
      "epoch : 221| loss : (train) 0.00621919 (testing) 0.00377760 | accuracy : (train) 80.2336903 (testing)  87.890625\n",
      "epoch : 222| loss : (train) 0.00589882 (testing) 0.00378297 | accuracy : (train) 80.2336903 (testing)  87.109375\n",
      "epoch : 223| loss : (train) 0.00598662 (testing) 0.00379059 | accuracy : (train) 80.3310613 (testing)   86.71875\n",
      "epoch : 224| loss : (train) 0.00549971 (testing) 0.00374842 | accuracy : (train) 80.1363193 (testing)  87.890625\n",
      "epoch : 225| loss : (train) 0.00573201 (testing) 0.00376876 | accuracy : (train) 80.2336903 (testing)   86.71875\n",
      "epoch : 226| loss : (train) 0.00567930 (testing) 0.00382973 | accuracy : (train) 80.9152872 (testing)  87.109375\n",
      "epoch : 227| loss : (train) 0.00561013 (testing) 0.00376674 | accuracy : (train) 80.5258033 (testing)  86.328125\n",
      "epoch : 228| loss : (train) 0.00580596 (testing) 0.00373244 | accuracy : (train) 80.5258033 (testing)   86.71875\n",
      "epoch : 229| loss : (train) 0.00578518 (testing) 0.00373194 | accuracy : (train) 80.1363193 (testing)   86.71875\n",
      "epoch : 230| loss : (train) 0.00588578 (testing) 0.00372688 | accuracy : (train) 80.1363193 (testing)   86.71875\n",
      "epoch : 231| loss : (train) 0.00591148 (testing) 0.00372587 | accuracy : (train) 80.8179162 (testing)   86.71875\n",
      "epoch : 232| loss : (train) 0.00575249 (testing) 0.00368350 | accuracy : (train) 80.7205452 (testing)  87.890625\n",
      "epoch : 233| loss : (train) 0.00595821 (testing) 0.00364806 | accuracy : (train) 80.6231742 (testing)   88.28125\n",
      "epoch : 234| loss : (train) 0.00579927 (testing) 0.00366377 | accuracy : (train) 80.3310613 (testing)  87.890625\n",
      "epoch : 235| loss : (train) 0.00566968 (testing) 0.00367328 | accuracy : (train) 80.9152872 (testing)   86.71875\n",
      "epoch : 236| loss : (train) 0.00563333 (testing) 0.00370871 | accuracy : (train) 80.7205452 (testing)  86.328125\n",
      "epoch : 237| loss : (train) 0.00569309 (testing) 0.00371177 | accuracy : (train) 80.8179162 (testing)   86.71875\n",
      "epoch : 238| loss : (train) 0.00549546 (testing) 0.00367942 | accuracy : (train) 80.6231742 (testing)  86.328125\n",
      "epoch : 239| loss : (train) 0.00552643 (testing) 0.00365993 | accuracy : (train) 80.7205452 (testing)   86.71875\n",
      "epoch : 240| loss : (train) 0.00545873 (testing) 0.00363813 | accuracy : (train) 80.9152872 (testing)   86.71875\n",
      "epoch : 241| loss : (train) 0.00570170 (testing) 0.00362743 | accuracy : (train) 81.1100292 (testing)   86.71875\n",
      "epoch : 242| loss : (train) 0.00544542 (testing) 0.00363771 | accuracy : (train) 81.0126582 (testing)   86.71875\n",
      "epoch : 243| loss : (train) 0.00597678 (testing) 0.00364588 | accuracy : (train) 80.6231742 (testing)  86.328125\n",
      "epoch : 244| loss : (train) 0.00567638 (testing) 0.00361866 | accuracy : (train) 80.7205452 (testing)   86.71875\n",
      "epoch : 245| loss : (train) 0.00572060 (testing) 0.00362277 | accuracy : (train) 80.8179162 (testing)  86.328125\n",
      "epoch : 246| loss : (train) 0.00583442 (testing) 0.00355258 | accuracy : (train) 80.7205452 (testing)  87.890625\n",
      "epoch : 247| loss : (train) 0.00557098 (testing) 0.00355790 | accuracy : (train) 80.7205452 (testing)  87.890625\n",
      "epoch : 248| loss : (train) 0.00517761 (testing) 0.00355150 | accuracy : (train) 81.2074001 (testing)  87.890625\n",
      "epoch : 249| loss : (train) 0.00572510 (testing) 0.00361368 | accuracy : (train) 80.9152872 (testing)   86.71875\n",
      "epoch : 250| loss : (train) 0.00547618 (testing) 0.00356571 | accuracy : (train) 80.9152872 (testing)   86.71875\n",
      "epoch : 251| loss : (train) 0.00576752 (testing) 0.00357878 | accuracy : (train) 81.0126582 (testing)  86.328125\n",
      "epoch : 252| loss : (train) 0.00545936 (testing) 0.00355935 | accuracy : (train) 81.2074001 (testing)   86.71875\n",
      "epoch : 253| loss : (train) 0.00557098 (testing) 0.00357556 | accuracy : (train) 81.0126582 (testing)  86.328125\n",
      "epoch : 254| loss : (train) 0.00541317 (testing) 0.00351917 | accuracy : (train) 81.3047711 (testing)  87.109375\n",
      "epoch : 255| loss : (train) 0.00538823 (testing) 0.00361605 | accuracy : (train) 81.2074001 (testing)       87.5\n",
      "epoch : 256| loss : (train) 0.00551967 (testing) 0.00358959 | accuracy : (train) 81.1100292 (testing)  87.109375\n",
      "epoch : 257| loss : (train) 0.00585367 (testing) 0.00361315 | accuracy : (train) 81.1100292 (testing)       87.5\n",
      "epoch : 258| loss : (train) 0.00558229 (testing) 0.00356585 | accuracy : (train) 81.2074001 (testing)   86.71875\n",
      "epoch : 259| loss : (train) 0.00539827 (testing) 0.00352860 | accuracy : (train) 81.1100292 (testing)  86.328125\n",
      "epoch : 260| loss : (train) 0.00522861 (testing) 0.00348658 | accuracy : (train) 81.4021421 (testing)  87.109375\n",
      "epoch : 261| loss : (train) 0.00578318 (testing) 0.00355556 | accuracy : (train) 81.4021421 (testing)  87.109375\n",
      "epoch : 262| loss : (train) 0.00567666 (testing) 0.00355124 | accuracy : (train) 81.4995131 (testing)  87.109375\n",
      "epoch : 263| loss : (train) 0.00549282 (testing) 0.00349947 | accuracy : (train) 81.3047711 (testing)   86.71875\n",
      "epoch : 264| loss : (train) 0.00543749 (testing) 0.00360731 | accuracy : (train) 81.3047711 (testing)       87.5\n",
      "epoch : 265| loss : (train) 0.00536267 (testing) 0.00347949 | accuracy : (train) 81.2074001 (testing)   86.71875\n",
      "epoch : 266| loss : (train) 0.00537823 (testing) 0.00345645 | accuracy : (train) 81.6942551 (testing)   86.71875\n",
      "epoch : 267| loss : (train) 0.00554565 (testing) 0.00360179 | accuracy : (train) 81.4021421 (testing)       87.5\n",
      "epoch : 268| loss : (train) 0.00522848 (testing) 0.00351760 | accuracy : (train) 81.4021421 (testing)  87.109375\n",
      "epoch : 269| loss : (train) 0.00504406 (testing) 0.00351362 | accuracy : (train) 81.4995131 (testing)  87.109375\n",
      "epoch : 270| loss : (train) 0.00556469 (testing) 0.00355242 | accuracy : (train) 81.4021421 (testing)       87.5\n",
      "epoch : 271| loss : (train) 0.00537016 (testing) 0.00348930 | accuracy : (train) 81.8889970 (testing)  87.109375\n",
      "epoch : 272| loss : (train) 0.00562527 (testing) 0.00344514 | accuracy : (train) 81.6942551 (testing)   86.71875\n",
      "epoch : 273| loss : (train) 0.00528490 (testing) 0.00344834 | accuracy : (train) 81.7916260 (testing)  86.328125\n",
      "epoch : 274| loss : (train) 0.00514977 (testing) 0.00343637 | accuracy : (train) 81.8889970 (testing)   86.71875\n",
      "epoch : 275| loss : (train) 0.00515808 (testing) 0.00340135 | accuracy : (train) 81.4995131 (testing)   86.71875\n",
      "epoch : 276| loss : (train) 0.00514013 (testing) 0.00345749 | accuracy : (train) 82.2784810 (testing)  87.109375\n",
      "epoch : 277| loss : (train) 0.00532078 (testing) 0.00345145 | accuracy : (train) 81.7916260 (testing)  87.109375\n",
      "epoch : 278| loss : (train) 0.00533022 (testing) 0.00350245 | accuracy : (train) 81.8889970 (testing)       87.5\n",
      "epoch : 279| loss : (train) 0.00528828 (testing) 0.00345987 | accuracy : (train) 81.7916260 (testing)  87.109375\n",
      "epoch : 280| loss : (train) 0.00505589 (testing) 0.00342662 | accuracy : (train) 81.9863680 (testing)   86.71875\n",
      "epoch : 281| loss : (train) 0.00502884 (testing) 0.00335037 | accuracy : (train) 81.8889970 (testing)  87.109375\n",
      "epoch : 282| loss : (train) 0.00517666 (testing) 0.00340199 | accuracy : (train) 81.7916260 (testing)   86.71875\n",
      "epoch : 283| loss : (train) 0.00521012 (testing) 0.00344364 | accuracy : (train) 82.0837390 (testing)       87.5\n",
      "epoch : 284| loss : (train) 0.00503320 (testing) 0.00341294 | accuracy : (train) 82.3758519 (testing)  87.109375\n",
      "epoch : 285| loss : (train) 0.00526914 (testing) 0.00341509 | accuracy : (train) 82.1811100 (testing)  87.109375\n",
      "epoch : 286| loss : (train) 0.00481165 (testing) 0.00333529 | accuracy : (train) 82.3758519 (testing)  87.109375\n",
      "epoch : 287| loss : (train) 0.00525402 (testing) 0.00342195 | accuracy : (train) 81.7916260 (testing)  87.109375\n",
      "epoch : 288| loss : (train) 0.00530436 (testing) 0.00335854 | accuracy : (train) 82.3758519 (testing)   86.71875\n",
      "epoch : 289| loss : (train) 0.00551122 (testing) 0.00335521 | accuracy : (train) 81.9863680 (testing)   86.71875\n",
      "epoch : 290| loss : (train) 0.00515469 (testing) 0.00339670 | accuracy : (train) 82.1811100 (testing)  87.109375\n",
      "epoch : 291| loss : (train) 0.00547401 (testing) 0.00336739 | accuracy : (train) 82.1811100 (testing)   86.71875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 292| loss : (train) 0.00500479 (testing) 0.00337696 | accuracy : (train) 82.3758519 (testing)  87.109375\n",
      "epoch : 293| loss : (train) 0.00519363 (testing) 0.00337824 | accuracy : (train) 82.2784810 (testing)  87.109375\n",
      "epoch : 294| loss : (train) 0.00518286 (testing) 0.00334969 | accuracy : (train) 82.2784810 (testing)   86.71875\n",
      "epoch : 295| loss : (train) 0.00488781 (testing) 0.00333915 | accuracy : (train) 82.0837390 (testing)   86.71875\n",
      "epoch : 296| loss : (train) 0.00498800 (testing) 0.00328100 | accuracy : (train) 82.0837390 (testing)  87.109375\n",
      "epoch : 297| loss : (train) 0.00549691 (testing) 0.00339586 | accuracy : (train) 82.2784810 (testing)       87.5\n",
      "epoch : 298| loss : (train) 0.00504585 (testing) 0.00340872 | accuracy : (train) 82.5705939 (testing)       87.5\n",
      "epoch : 299| loss : (train) 0.00511640 (testing) 0.00340809 | accuracy : (train) 82.1811100 (testing)       87.5\n",
      "epoch : 300| loss : (train) 0.00518154 (testing) 0.00343197 | accuracy : (train) 82.7653359 (testing)  87.109375\n",
      "epoch : 301| loss : (train) 0.00506449 (testing) 0.00330589 | accuracy : (train) 82.6679649 (testing)   86.71875\n",
      "epoch : 302| loss : (train) 0.00518719 (testing) 0.00324234 | accuracy : (train) 82.4732229 (testing)       87.5\n",
      "epoch : 303| loss : (train) 0.00498625 (testing) 0.00330800 | accuracy : (train) 82.1811100 (testing)  87.109375\n",
      "epoch : 304| loss : (train) 0.00513638 (testing) 0.00343227 | accuracy : (train) 82.4732229 (testing)  87.109375\n",
      "epoch : 305| loss : (train) 0.00479108 (testing) 0.00331354 | accuracy : (train) 82.7653359 (testing)   86.71875\n",
      "epoch : 306| loss : (train) 0.00529802 (testing) 0.00331254 | accuracy : (train) 82.4732229 (testing)   86.71875\n",
      "epoch : 307| loss : (train) 0.00500905 (testing) 0.00329557 | accuracy : (train) 82.2784810 (testing)  87.109375\n",
      "epoch : 308| loss : (train) 0.00510470 (testing) 0.00332229 | accuracy : (train) 82.6679649 (testing)  87.109375\n",
      "epoch : 309| loss : (train) 0.00502691 (testing) 0.00334523 | accuracy : (train) 82.6679649 (testing)       87.5\n",
      "epoch : 310| loss : (train) 0.00496247 (testing) 0.00329198 | accuracy : (train) 82.9600778 (testing)   86.71875\n",
      "epoch : 311| loss : (train) 0.00495078 (testing) 0.00326311 | accuracy : (train) 82.8627069 (testing)   86.71875\n",
      "epoch : 312| loss : (train) 0.00516498 (testing) 0.00332300 | accuracy : (train) 83.3495618 (testing)  87.109375\n",
      "epoch : 313| loss : (train) 0.00519797 (testing) 0.00330557 | accuracy : (train) 82.8627069 (testing)  87.109375\n",
      "epoch : 314| loss : (train) 0.00487217 (testing) 0.00335292 | accuracy : (train) 82.8627069 (testing)       87.5\n",
      "epoch : 315| loss : (train) 0.00539606 (testing) 0.00324483 | accuracy : (train) 83.0574488 (testing)   86.71875\n",
      "epoch : 316| loss : (train) 0.00501851 (testing) 0.00322031 | accuracy : (train) 82.5705939 (testing)  87.109375\n",
      "epoch : 317| loss : (train) 0.00501160 (testing) 0.00327780 | accuracy : (train) 82.7653359 (testing)   86.71875\n",
      "epoch : 318| loss : (train) 0.00503328 (testing) 0.00332155 | accuracy : (train) 82.9600778 (testing)       87.5\n",
      "epoch : 319| loss : (train) 0.00531039 (testing) 0.00336504 | accuracy : (train) 82.9600778 (testing)       87.5\n",
      "epoch : 320| loss : (train) 0.00512968 (testing) 0.00328783 | accuracy : (train) 83.2521908 (testing)  87.109375\n",
      "epoch : 321| loss : (train) 0.00529548 (testing) 0.00329465 | accuracy : (train) 82.9600778 (testing)       87.5\n",
      "epoch : 322| loss : (train) 0.00511374 (testing) 0.00329467 | accuracy : (train) 82.9600778 (testing)       87.5\n",
      "epoch : 323| loss : (train) 0.00533677 (testing) 0.00326489 | accuracy : (train) 83.1548198 (testing)  87.109375\n",
      "epoch : 324| loss : (train) 0.00519008 (testing) 0.00334139 | accuracy : (train) 83.1548198 (testing)       87.5\n",
      "epoch : 325| loss : (train) 0.00498802 (testing) 0.00328267 | accuracy : (train) 83.2521908 (testing)       87.5\n",
      "epoch : 326| loss : (train) 0.00494278 (testing) 0.00323741 | accuracy : (train) 83.2521908 (testing)  87.109375\n",
      "epoch : 327| loss : (train) 0.00504657 (testing) 0.00320531 | accuracy : (train) 83.3495618 (testing)   86.71875\n",
      "epoch : 328| loss : (train) 0.00505172 (testing) 0.00330790 | accuracy : (train) 83.4469328 (testing)       87.5\n",
      "epoch : 329| loss : (train) 0.00488248 (testing) 0.00322976 | accuracy : (train) 83.2521908 (testing)  87.109375\n",
      "epoch : 330| loss : (train) 0.00481386 (testing) 0.00321351 | accuracy : (train) 83.0574488 (testing)   86.71875\n",
      "epoch : 331| loss : (train) 0.00484621 (testing) 0.00326881 | accuracy : (train) 83.5443037 (testing)       87.5\n",
      "epoch : 332| loss : (train) 0.00492997 (testing) 0.00325985 | accuracy : (train) 83.4469328 (testing)  87.109375\n",
      "epoch : 333| loss : (train) 0.00492111 (testing) 0.00321962 | accuracy : (train) 83.6416747 (testing)  87.109375\n",
      "epoch : 334| loss : (train) 0.00471577 (testing) 0.00331554 | accuracy : (train) 83.4469328 (testing)       87.5\n",
      "epoch : 335| loss : (train) 0.00517615 (testing) 0.00323216 | accuracy : (train) 83.5443037 (testing)  87.109375\n",
      "epoch : 336| loss : (train) 0.00475033 (testing) 0.00327538 | accuracy : (train) 83.6416747 (testing)       87.5\n",
      "epoch : 337| loss : (train) 0.00477503 (testing) 0.00319147 | accuracy : (train) 83.5443037 (testing)   86.71875\n",
      "epoch : 338| loss : (train) 0.00518679 (testing) 0.00322898 | accuracy : (train) 83.6416747 (testing)  87.109375\n",
      "epoch : 339| loss : (train) 0.00474481 (testing) 0.00319733 | accuracy : (train) 83.5443037 (testing)  87.109375\n",
      "epoch : 340| loss : (train) 0.00470018 (testing) 0.00327540 | accuracy : (train) 83.8364167 (testing)       87.5\n",
      "epoch : 341| loss : (train) 0.00528152 (testing) 0.00317296 | accuracy : (train) 83.6416747 (testing)   86.71875\n",
      "epoch : 342| loss : (train) 0.00480324 (testing) 0.00331108 | accuracy : (train) 83.7390457 (testing)       87.5\n",
      "epoch : 343| loss : (train) 0.00456622 (testing) 0.00330571 | accuracy : (train) 83.0574488 (testing)       87.5\n",
      "epoch : 344| loss : (train) 0.00459168 (testing) 0.00329978 | accuracy : (train) 83.5443037 (testing)       87.5\n",
      "epoch : 345| loss : (train) 0.00492450 (testing) 0.00315484 | accuracy : (train) 83.6416747 (testing)  87.109375\n",
      "epoch : 346| loss : (train) 0.00467632 (testing) 0.00318497 | accuracy : (train) 84.2259006 (testing)  87.109375\n",
      "epoch : 347| loss : (train) 0.00464562 (testing) 0.00320533 | accuracy : (train) 84.1285296 (testing)  87.109375\n",
      "epoch : 348| loss : (train) 0.00512352 (testing) 0.00333202 | accuracy : (train) 84.0311587 (testing)  87.890625\n",
      "epoch : 349| loss : (train) 0.00458770 (testing) 0.00320653 | accuracy : (train) 83.4469328 (testing)  87.109375\n",
      "epoch : 350| loss : (train) 0.00462328 (testing) 0.00318782 | accuracy : (train) 84.4206426 (testing)  87.109375\n",
      "epoch : 351| loss : (train) 0.00499250 (testing) 0.00341848 | accuracy : (train) 84.4206426 (testing)  86.328125\n",
      "epoch : 352| loss : (train) 0.00482142 (testing) 0.00323870 | accuracy : (train) 83.6416747 (testing)       87.5\n",
      "epoch : 353| loss : (train) 0.00479900 (testing) 0.00321730 | accuracy : (train) 84.0311587 (testing)  87.890625\n",
      "epoch : 354| loss : (train) 0.00467154 (testing) 0.00317289 | accuracy : (train) 84.2259006 (testing)  87.109375\n",
      "epoch : 355| loss : (train) 0.00473064 (testing) 0.00320390 | accuracy : (train) 84.4206426 (testing)  87.890625\n",
      "epoch : 356| loss : (train) 0.00461846 (testing) 0.00319191 | accuracy : (train) 84.0311587 (testing)  87.109375\n",
      "epoch : 357| loss : (train) 0.00461196 (testing) 0.00328616 | accuracy : (train) 84.6153846 (testing)       87.5\n",
      "epoch : 358| loss : (train) 0.00492891 (testing) 0.00321902 | accuracy : (train) 84.4206426 (testing)       87.5\n",
      "epoch : 359| loss : (train) 0.00473376 (testing) 0.00316035 | accuracy : (train) 84.4206426 (testing)  87.109375\n",
      "epoch : 360| loss : (train) 0.00498729 (testing) 0.00329425 | accuracy : (train) 85.0048685 (testing)       87.5\n",
      "epoch : 361| loss : (train) 0.00484746 (testing) 0.00320177 | accuracy : (train) 84.2259006 (testing)       87.5\n",
      "epoch : 362| loss : (train) 0.00466143 (testing) 0.00314671 | accuracy : (train) 84.3232716 (testing)  87.109375\n",
      "epoch : 363| loss : (train) 0.00486727 (testing) 0.00326963 | accuracy : (train) 84.8101265 (testing)       87.5\n",
      "epoch : 364| loss : (train) 0.00455396 (testing) 0.00317269 | accuracy : (train) 84.6153846 (testing)       87.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 365| loss : (train) 0.00449750 (testing) 0.00320782 | accuracy : (train) 84.5180136 (testing)       87.5\n",
      "epoch : 366| loss : (train) 0.00456170 (testing) 0.00315431 | accuracy : (train) 84.6153846 (testing)  87.109375\n",
      "epoch : 367| loss : (train) 0.00471230 (testing) 0.00313433 | accuracy : (train) 84.7127555 (testing)  87.109375\n",
      "epoch : 368| loss : (train) 0.00482773 (testing) 0.00316514 | accuracy : (train) 84.6153846 (testing)       87.5\n",
      "epoch : 369| loss : (train) 0.00496997 (testing) 0.00313334 | accuracy : (train) 84.7127555 (testing)  87.109375\n",
      "epoch : 370| loss : (train) 0.00462339 (testing) 0.00314388 | accuracy : (train) 84.5180136 (testing)  87.109375\n",
      "epoch : 371| loss : (train) 0.00463760 (testing) 0.00313797 | accuracy : (train) 84.8101265 (testing)  87.109375\n",
      "epoch : 372| loss : (train) 0.00464713 (testing) 0.00316925 | accuracy : (train) 84.9074975 (testing)  87.890625\n",
      "epoch : 373| loss : (train) 0.00419285 (testing) 0.00320036 | accuracy : (train) 85.0048685 (testing)       87.5\n",
      "epoch : 374| loss : (train) 0.00464450 (testing) 0.00317311 | accuracy : (train) 85.0048685 (testing)       87.5\n",
      "epoch : 375| loss : (train) 0.00462034 (testing) 0.00316553 | accuracy : (train) 85.1022395 (testing)       87.5\n",
      "epoch : 376| loss : (train) 0.00463333 (testing) 0.00311595 | accuracy : (train) 85.1022395 (testing)  87.109375\n",
      "epoch : 377| loss : (train) 0.00445442 (testing) 0.00310247 | accuracy : (train) 84.9074975 (testing)  87.109375\n",
      "epoch : 378| loss : (train) 0.00441722 (testing) 0.00305743 | accuracy : (train) 84.9074975 (testing)       87.5\n",
      "epoch : 379| loss : (train) 0.00439358 (testing) 0.00329282 | accuracy : (train) 84.9074975 (testing)  87.109375\n",
      "epoch : 380| loss : (train) 0.00437629 (testing) 0.00323818 | accuracy : (train) 85.5890944 (testing)       87.5\n",
      "epoch : 381| loss : (train) 0.00447669 (testing) 0.00325003 | accuracy : (train) 85.1022395 (testing)       87.5\n",
      "epoch : 382| loss : (train) 0.00438631 (testing) 0.00312204 | accuracy : (train) 85.1996105 (testing)       87.5\n",
      "epoch : 383| loss : (train) 0.00465519 (testing) 0.00328655 | accuracy : (train) 84.7127555 (testing)  87.109375\n",
      "epoch : 384| loss : (train) 0.00441196 (testing) 0.00319231 | accuracy : (train) 84.9074975 (testing)       87.5\n",
      "epoch : 385| loss : (train) 0.00447088 (testing) 0.00320876 | accuracy : (train) 85.6864654 (testing)       87.5\n",
      "epoch : 386| loss : (train) 0.00467641 (testing) 0.00323503 | accuracy : (train) 85.4917234 (testing)       87.5\n",
      "epoch : 387| loss : (train) 0.00458541 (testing) 0.00314117 | accuracy : (train) 85.3943524 (testing)  87.890625\n",
      "epoch : 388| loss : (train) 0.00462701 (testing) 0.00315774 | accuracy : (train) 85.2969814 (testing)       87.5\n",
      "epoch : 389| loss : (train) 0.00444397 (testing) 0.00313065 | accuracy : (train) 85.2969814 (testing)       87.5\n",
      "epoch : 390| loss : (train) 0.00462519 (testing) 0.00307150 | accuracy : (train) 84.9074975 (testing)       87.5\n",
      "epoch : 391| loss : (train) 0.00446931 (testing) 0.00306796 | accuracy : (train) 85.3943524 (testing)       87.5\n",
      "epoch : 392| loss : (train) 0.00471122 (testing) 0.00304188 | accuracy : (train) 85.4917234 (testing)       87.5\n",
      "epoch : 393| loss : (train) 0.00484879 (testing) 0.00317857 | accuracy : (train) 85.4917234 (testing)       87.5\n",
      "epoch : 394| loss : (train) 0.00436614 (testing) 0.00318486 | accuracy : (train) 85.4917234 (testing)       87.5\n",
      "epoch : 395| loss : (train) 0.00433246 (testing) 0.00317896 | accuracy : (train) 85.5890944 (testing)       87.5\n",
      "epoch : 396| loss : (train) 0.00450093 (testing) 0.00320512 | accuracy : (train) 85.6864654 (testing)       87.5\n",
      "epoch : 397| loss : (train) 0.00430180 (testing) 0.00319507 | accuracy : (train) 85.8812074 (testing)       87.5\n",
      "epoch : 398| loss : (train) 0.00416360 (testing) 0.00319660 | accuracy : (train) 85.6864654 (testing)       87.5\n",
      "epoch : 399| loss : (train) 0.00411736 (testing) 0.00314351 | accuracy : (train) 85.6864654 (testing)  87.109375\n",
      "epoch : 400| loss : (train) 0.00431581 (testing) 0.00322773 | accuracy : (train) 85.4917234 (testing)  87.109375\n",
      "epoch : 401| loss : (train) 0.00457990 (testing) 0.00314949 | accuracy : (train) 85.6864654 (testing)       87.5\n",
      "epoch : 402| loss : (train) 0.00447623 (testing) 0.00320615 | accuracy : (train) 85.2969814 (testing)       87.5\n",
      "epoch : 403| loss : (train) 0.00458879 (testing) 0.00314156 | accuracy : (train) 85.9785783 (testing)       87.5\n",
      "epoch : 404| loss : (train) 0.00475838 (testing) 0.00317124 | accuracy : (train) 85.8812074 (testing)       87.5\n",
      "epoch : 405| loss : (train) 0.00467862 (testing) 0.00314627 | accuracy : (train) 85.7838364 (testing)       87.5\n",
      "epoch : 406| loss : (train) 0.00440224 (testing) 0.00317614 | accuracy : (train) 85.8812074 (testing)       87.5\n",
      "epoch : 407| loss : (train) 0.00441088 (testing) 0.00311031 | accuracy : (train) 85.7838364 (testing)       87.5\n",
      "epoch : 408| loss : (train) 0.00429689 (testing) 0.00315852 | accuracy : (train) 85.8812074 (testing)       87.5\n",
      "epoch : 409| loss : (train) 0.00430410 (testing) 0.00310463 | accuracy : (train) 85.8812074 (testing)       87.5\n",
      "epoch : 410| loss : (train) 0.00457182 (testing) 0.00316433 | accuracy : (train) 85.9785783 (testing)       87.5\n",
      "epoch : 411| loss : (train) 0.00436974 (testing) 0.00322683 | accuracy : (train) 86.0759493 (testing)   86.71875\n",
      "epoch : 412| loss : (train) 0.00433026 (testing) 0.00313459 | accuracy : (train) 86.4654333 (testing)       87.5\n",
      "epoch : 413| loss : (train) 0.00440773 (testing) 0.00323873 | accuracy : (train) 85.9785783 (testing)   86.71875\n",
      "epoch : 414| loss : (train) 0.00425278 (testing) 0.00308948 | accuracy : (train) 86.1733203 (testing)       87.5\n",
      "epoch : 415| loss : (train) 0.00462856 (testing) 0.00340204 | accuracy : (train) 85.7838364 (testing)  87.109375\n",
      "epoch : 416| loss : (train) 0.00469274 (testing) 0.00317512 | accuracy : (train) 85.8812074 (testing)       87.5\n",
      "epoch : 417| loss : (train) 0.00417129 (testing) 0.00313722 | accuracy : (train) 85.9785783 (testing)       87.5\n",
      "epoch : 418| loss : (train) 0.00443106 (testing) 0.00318926 | accuracy : (train) 86.1733203 (testing)       87.5\n",
      "epoch : 419| loss : (train) 0.00425164 (testing) 0.00326773 | accuracy : (train) 86.1733203 (testing)   86.71875\n",
      "epoch : 420| loss : (train) 0.00422964 (testing) 0.00307866 | accuracy : (train) 86.2706913 (testing)  87.109375\n",
      "epoch : 421| loss : (train) 0.00406479 (testing) 0.00311415 | accuracy : (train) 86.3680623 (testing)  87.109375\n",
      "epoch : 422| loss : (train) 0.00419268 (testing) 0.00323255 | accuracy : (train) 86.0759493 (testing)   86.71875\n",
      "epoch : 423| loss : (train) 0.00438510 (testing) 0.00344156 | accuracy : (train) 86.2706913 (testing)  86.328125\n",
      "epoch : 424| loss : (train) 0.00407572 (testing) 0.00322278 | accuracy : (train) 86.1733203 (testing)   86.71875\n",
      "epoch : 425| loss : (train) 0.00424010 (testing) 0.00332221 | accuracy : (train) 86.3680623 (testing)  87.109375\n",
      "epoch : 426| loss : (train) 0.00429257 (testing) 0.00318631 | accuracy : (train) 86.3680623 (testing)       87.5\n",
      "epoch : 427| loss : (train) 0.00396203 (testing) 0.00315940 | accuracy : (train) 86.6601752 (testing)       87.5\n",
      "epoch : 428| loss : (train) 0.00410256 (testing) 0.00313328 | accuracy : (train) 86.4654333 (testing)       87.5\n",
      "epoch : 429| loss : (train) 0.00413331 (testing) 0.00312113 | accuracy : (train) 86.3680623 (testing)  87.109375\n",
      "epoch : 430| loss : (train) 0.00399740 (testing) 0.00317016 | accuracy : (train) 86.2706913 (testing)       87.5\n",
      "epoch : 431| loss : (train) 0.00411241 (testing) 0.00322776 | accuracy : (train) 86.2706913 (testing)   86.71875\n",
      "epoch : 432| loss : (train) 0.00439713 (testing) 0.00323227 | accuracy : (train) 86.4654333 (testing)   86.71875\n",
      "epoch : 433| loss : (train) 0.00455083 (testing) 0.00321030 | accuracy : (train) 86.2706913 (testing)   86.71875\n",
      "epoch : 434| loss : (train) 0.00396718 (testing) 0.00313755 | accuracy : (train) 86.3680623 (testing)       87.5\n",
      "epoch : 435| loss : (train) 0.00451884 (testing) 0.00342028 | accuracy : (train) 86.6601752 (testing)  86.328125\n",
      "epoch : 436| loss : (train) 0.00437909 (testing) 0.00309640 | accuracy : (train) 86.3680623 (testing)  87.109375\n",
      "epoch : 437| loss : (train) 0.00396692 (testing) 0.00312007 | accuracy : (train) 86.5628042 (testing)  87.109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 438| loss : (train) 0.00373327 (testing) 0.00306347 | accuracy : (train) 86.5628042 (testing)  87.890625\n",
      "epoch : 439| loss : (train) 0.00416065 (testing) 0.00314587 | accuracy : (train) 86.7575462 (testing)  87.890625\n",
      "epoch : 440| loss : (train) 0.00428636 (testing) 0.00329975 | accuracy : (train) 87.0496592 (testing)  87.109375\n",
      "epoch : 441| loss : (train) 0.00408422 (testing) 0.00318464 | accuracy : (train) 86.6601752 (testing)   86.71875\n",
      "epoch : 442| loss : (train) 0.00401677 (testing) 0.00317360 | accuracy : (train) 86.7575462 (testing)       87.5\n",
      "epoch : 443| loss : (train) 0.00396258 (testing) 0.00330654 | accuracy : (train) 86.7575462 (testing)  87.109375\n",
      "epoch : 444| loss : (train) 0.00427308 (testing) 0.00314619 | accuracy : (train) 86.6601752 (testing)  87.890625\n",
      "epoch : 445| loss : (train) 0.00384037 (testing) 0.00319480 | accuracy : (train) 86.8549172 (testing)   86.71875\n",
      "epoch : 446| loss : (train) 0.00381821 (testing) 0.00322476 | accuracy : (train) 87.0496592 (testing)   86.71875\n",
      "epoch : 447| loss : (train) 0.00456289 (testing) 0.00336303 | accuracy : (train) 86.8549172 (testing)       87.5\n",
      "epoch : 448| loss : (train) 0.00384138 (testing) 0.00314780 | accuracy : (train) 87.5365141 (testing)  87.890625\n",
      "epoch : 449| loss : (train) 0.00377670 (testing) 0.00324501 | accuracy : (train) 87.1470301 (testing)   86.71875\n",
      "epoch : 450| loss : (train) 0.00413913 (testing) 0.00313985 | accuracy : (train) 87.1470301 (testing)       87.5\n",
      "epoch : 451| loss : (train) 0.00412302 (testing) 0.00306056 | accuracy : (train) 87.0496592 (testing)  87.890625\n",
      "epoch : 452| loss : (train) 0.00420573 (testing) 0.00314383 | accuracy : (train) 86.8549172 (testing)       87.5\n",
      "epoch : 453| loss : (train) 0.00387029 (testing) 0.00333321 | accuracy : (train) 87.1470301 (testing)       87.5\n",
      "epoch : 454| loss : (train) 0.00404091 (testing) 0.00312159 | accuracy : (train) 86.9522882 (testing)  87.109375\n",
      "epoch : 455| loss : (train) 0.00393124 (testing) 0.00307655 | accuracy : (train) 86.9522882 (testing)  87.890625\n",
      "epoch : 456| loss : (train) 0.00410492 (testing) 0.00322664 | accuracy : (train) 87.1470301 (testing)   86.71875\n",
      "epoch : 457| loss : (train) 0.00382954 (testing) 0.00322853 | accuracy : (train) 86.7575462 (testing)   86.71875\n",
      "epoch : 458| loss : (train) 0.00383109 (testing) 0.00319917 | accuracy : (train) 87.0496592 (testing)   86.71875\n",
      "epoch : 459| loss : (train) 0.00427796 (testing) 0.00327584 | accuracy : (train) 87.0496592 (testing)   86.71875\n",
      "epoch : 460| loss : (train) 0.00425336 (testing) 0.00341462 | accuracy : (train) 86.8549172 (testing)   86.71875\n",
      "epoch : 461| loss : (train) 0.00423918 (testing) 0.00331468 | accuracy : (train) 87.1470301 (testing)  87.109375\n",
      "epoch : 462| loss : (train) 0.00367219 (testing) 0.00325438 | accuracy : (train) 86.8549172 (testing)   86.71875\n",
      "epoch : 463| loss : (train) 0.00375979 (testing) 0.00320382 | accuracy : (train) 87.4391431 (testing)   86.71875\n",
      "epoch : 464| loss : (train) 0.00379305 (testing) 0.00311703 | accuracy : (train) 87.3417721 (testing)  87.109375\n",
      "epoch : 465| loss : (train) 0.00419716 (testing) 0.00324864 | accuracy : (train) 87.2444011 (testing)   86.71875\n",
      "epoch : 466| loss : (train) 0.00399963 (testing) 0.00316575 | accuracy : (train) 87.2444011 (testing)  87.109375\n",
      "epoch : 467| loss : (train) 0.00414722 (testing) 0.00324506 | accuracy : (train) 87.4391431 (testing)   86.71875\n",
      "epoch : 468| loss : (train) 0.00408737 (testing) 0.00325148 | accuracy : (train) 87.2444011 (testing)   86.71875\n",
      "epoch : 469| loss : (train) 0.00400901 (testing) 0.00324726 | accuracy : (train) 87.4391431 (testing)   86.71875\n",
      "epoch : 470| loss : (train) 0.00374792 (testing) 0.00315276 | accuracy : (train) 87.5365141 (testing)       87.5\n",
      "epoch : 471| loss : (train) 0.00416277 (testing) 0.00317887 | accuracy : (train) 87.1470301 (testing)   86.71875\n",
      "epoch : 472| loss : (train) 0.00392579 (testing) 0.00314383 | accuracy : (train) 87.4391431 (testing)  87.109375\n",
      "epoch : 473| loss : (train) 0.00377772 (testing) 0.00310679 | accuracy : (train) 87.8286270 (testing)       87.5\n",
      "epoch : 474| loss : (train) 0.00380411 (testing) 0.00320136 | accuracy : (train) 87.5365141 (testing)   86.71875\n",
      "epoch : 475| loss : (train) 0.00422181 (testing) 0.00335935 | accuracy : (train) 87.5365141 (testing)       87.5\n",
      "epoch : 476| loss : (train) 0.00373362 (testing) 0.00317086 | accuracy : (train) 87.7312560 (testing)  87.109375\n",
      "epoch : 477| loss : (train) 0.00358764 (testing) 0.00318023 | accuracy : (train) 87.9259980 (testing)   86.71875\n",
      "epoch : 478| loss : (train) 0.00364032 (testing) 0.00322621 | accuracy : (train) 87.5365141 (testing)   86.71875\n",
      "epoch : 479| loss : (train) 0.00409334 (testing) 0.00325322 | accuracy : (train) 87.7312560 (testing)   86.71875\n",
      "epoch : 480| loss : (train) 0.00414428 (testing) 0.00306175 | accuracy : (train) 87.8286270 (testing)   88.28125\n",
      "epoch : 481| loss : (train) 0.00387857 (testing) 0.00318932 | accuracy : (train) 87.5365141 (testing)   86.71875\n",
      "epoch : 482| loss : (train) 0.00411481 (testing) 0.00333902 | accuracy : (train) 87.5365141 (testing)   86.71875\n",
      "epoch : 483| loss : (train) 0.00423169 (testing) 0.00324249 | accuracy : (train) 88.4128529 (testing)   86.71875\n",
      "epoch : 484| loss : (train) 0.00379138 (testing) 0.00323038 | accuracy : (train) 88.6075949 (testing)   86.71875\n",
      "epoch : 485| loss : (train) 0.00396578 (testing) 0.00341588 | accuracy : (train) 87.6338851 (testing)   86.71875\n",
      "epoch : 486| loss : (train) 0.00412289 (testing) 0.00318180 | accuracy : (train) 88.2181110 (testing)  87.109375\n",
      "epoch : 487| loss : (train) 0.00381809 (testing) 0.00325350 | accuracy : (train) 87.7312560 (testing)   86.71875\n",
      "epoch : 488| loss : (train) 0.00390412 (testing) 0.00314485 | accuracy : (train) 88.6075949 (testing)  87.109375\n",
      "epoch : 489| loss : (train) 0.00373245 (testing) 0.00311002 | accuracy : (train) 88.3154819 (testing)  87.109375\n",
      "epoch : 490| loss : (train) 0.00377822 (testing) 0.00315986 | accuracy : (train) 88.2181110 (testing)   86.71875\n",
      "epoch : 491| loss : (train) 0.00397237 (testing) 0.00326324 | accuracy : (train) 88.5102239 (testing)   86.71875\n",
      "epoch : 492| loss : (train) 0.00407593 (testing) 0.00329218 | accuracy : (train) 88.3154819 (testing)   86.71875\n",
      "epoch : 493| loss : (train) 0.00415014 (testing) 0.00326750 | accuracy : (train) 88.6075949 (testing)   86.71875\n",
      "epoch : 494| loss : (train) 0.00366419 (testing) 0.00330328 | accuracy : (train) 88.2181110 (testing)   86.71875\n",
      "epoch : 495| loss : (train) 0.00374729 (testing) 0.00335645 | accuracy : (train) 88.4128529 (testing)  87.109375\n",
      "epoch : 496| loss : (train) 0.00374371 (testing) 0.00314646 | accuracy : (train) 88.8023369 (testing)       87.5\n",
      "epoch : 497| loss : (train) 0.00366562 (testing) 0.00331502 | accuracy : (train) 88.4128529 (testing)   86.71875\n",
      "epoch : 498| loss : (train) 0.00365679 (testing) 0.00332821 | accuracy : (train) 88.7049659 (testing)   86.71875\n",
      "epoch : 499| loss : (train) 0.00383694 (testing) 0.00319679 | accuracy : (train) 88.7049659 (testing)   86.71875\n",
      "epoch : 500| loss : (train) 0.00379923 (testing) 0.00312258 | accuracy : (train) 88.8997078 (testing)       87.5\n",
      "epoch : 501| loss : (train) 0.00344607 (testing) 0.00321148 | accuracy : (train) 88.7049659 (testing)  87.109375\n",
      "epoch : 502| loss : (train) 0.00365391 (testing) 0.00328335 | accuracy : (train) 89.0944498 (testing)   86.71875\n",
      "epoch : 503| loss : (train) 0.00341071 (testing) 0.00321267 | accuracy : (train) 88.8997078 (testing)  87.109375\n",
      "epoch : 504| loss : (train) 0.00353850 (testing) 0.00322125 | accuracy : (train) 88.8997078 (testing)   86.71875\n",
      "epoch : 505| loss : (train) 0.00349676 (testing) 0.00347680 | accuracy : (train) 88.3154819 (testing)  86.328125\n",
      "epoch : 506| loss : (train) 0.00383215 (testing) 0.00341255 | accuracy : (train) 89.0944498 (testing)       87.5\n",
      "epoch : 507| loss : (train) 0.00346039 (testing) 0.00314071 | accuracy : (train) 88.8997078 (testing)       87.5\n",
      "epoch : 508| loss : (train) 0.00367586 (testing) 0.00344766 | accuracy : (train) 88.8997078 (testing)   86.71875\n",
      "epoch : 509| loss : (train) 0.00405702 (testing) 0.00313627 | accuracy : (train) 89.0944498 (testing)       87.5\n",
      "epoch : 510| loss : (train) 0.00375420 (testing) 0.00325878 | accuracy : (train) 88.9970788 (testing)   86.71875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 511| loss : (train) 0.00370435 (testing) 0.00324760 | accuracy : (train) 89.6786757 (testing)   86.71875\n",
      "epoch : 512| loss : (train) 0.00365560 (testing) 0.00323241 | accuracy : (train) 89.1918208 (testing)  87.109375\n",
      "epoch : 513| loss : (train) 0.00407295 (testing) 0.00342955 | accuracy : (train) 89.2891918 (testing)       87.5\n",
      "epoch : 514| loss : (train) 0.00416244 (testing) 0.00340395 | accuracy : (train) 89.4839337 (testing)  87.109375\n",
      "epoch : 515| loss : (train) 0.00383090 (testing) 0.00339322 | accuracy : (train) 89.2891918 (testing)  87.109375\n",
      "epoch : 516| loss : (train) 0.00336084 (testing) 0.00323202 | accuracy : (train) 89.6786757 (testing)   86.71875\n",
      "epoch : 517| loss : (train) 0.00368120 (testing) 0.00321791 | accuracy : (train) 89.6786757 (testing)  86.328125\n",
      "epoch : 518| loss : (train) 0.00372575 (testing) 0.00342289 | accuracy : (train) 89.4839337 (testing)  87.109375\n",
      "epoch : 519| loss : (train) 0.00358872 (testing) 0.00334685 | accuracy : (train) 89.6786757 (testing)  86.328125\n",
      "epoch : 520| loss : (train) 0.00363457 (testing) 0.00335166 | accuracy : (train) 89.9707887 (testing)  86.328125\n",
      "epoch : 521| loss : (train) 0.00353887 (testing) 0.00323954 | accuracy : (train) 89.8734177 (testing)   86.71875\n",
      "epoch : 522| loss : (train) 0.00350936 (testing) 0.00329503 | accuracy : (train) 89.7760467 (testing)   86.71875\n",
      "epoch : 523| loss : (train) 0.00377075 (testing) 0.00328107 | accuracy : (train) 89.8734177 (testing)   86.71875\n",
      "epoch : 524| loss : (train) 0.00369874 (testing) 0.00328510 | accuracy : (train) 89.6786757 (testing)   86.71875\n",
      "epoch : 525| loss : (train) 0.00362446 (testing) 0.00318182 | accuracy : (train) 89.8734177 (testing)       87.5\n",
      "epoch : 526| loss : (train) 0.00351841 (testing) 0.00329467 | accuracy : (train) 89.6786757 (testing)   86.71875\n",
      "epoch : 527| loss : (train) 0.00354719 (testing) 0.00328766 | accuracy : (train) 89.7760467 (testing)   86.71875\n",
      "epoch : 528| loss : (train) 0.00366422 (testing) 0.00325967 | accuracy : (train) 89.8734177 (testing)   86.71875\n",
      "epoch : 529| loss : (train) 0.00358050 (testing) 0.00332506 | accuracy : (train) 89.7760467 (testing)   86.71875\n",
      "epoch : 530| loss : (train) 0.00388750 (testing) 0.00346217 | accuracy : (train) 90.1655306 (testing)       87.5\n",
      "epoch : 531| loss : (train) 0.00335412 (testing) 0.00327819 | accuracy : (train) 89.9707887 (testing)   86.71875\n",
      "epoch : 532| loss : (train) 0.00373478 (testing) 0.00347577 | accuracy : (train) 89.9707887 (testing)   86.71875\n",
      "epoch : 533| loss : (train) 0.00327130 (testing) 0.00326176 | accuracy : (train) 90.2629016 (testing)   86.71875\n",
      "epoch : 534| loss : (train) 0.00352805 (testing) 0.00332265 | accuracy : (train) 90.3602726 (testing)   86.71875\n",
      "epoch : 535| loss : (train) 0.00359958 (testing) 0.00333523 | accuracy : (train) 90.5550146 (testing)   86.71875\n",
      "epoch : 536| loss : (train) 0.00358684 (testing) 0.00344766 | accuracy : (train) 90.4576436 (testing)  87.109375\n",
      "epoch : 537| loss : (train) 0.00361354 (testing) 0.00333243 | accuracy : (train) 90.1655306 (testing)   86.71875\n",
      "epoch : 538| loss : (train) 0.00356832 (testing) 0.00331580 | accuracy : (train) 90.6523855 (testing)   86.71875\n",
      "epoch : 539| loss : (train) 0.00367326 (testing) 0.00334443 | accuracy : (train) 90.3602726 (testing)   86.71875\n",
      "epoch : 540| loss : (train) 0.00358028 (testing) 0.00331559 | accuracy : (train) 90.5550146 (testing)   86.71875\n",
      "epoch : 541| loss : (train) 0.00374631 (testing) 0.00335116 | accuracy : (train) 90.6523855 (testing)  86.328125\n",
      "epoch : 542| loss : (train) 0.00366271 (testing) 0.00332754 | accuracy : (train) 90.3602726 (testing)   86.71875\n",
      "epoch : 543| loss : (train) 0.00377596 (testing) 0.00348356 | accuracy : (train) 90.4576436 (testing)  87.109375\n",
      "epoch : 544| loss : (train) 0.00336476 (testing) 0.00331895 | accuracy : (train) 90.8471275 (testing)   86.71875\n",
      "epoch : 545| loss : (train) 0.00354689 (testing) 0.00327550 | accuracy : (train) 90.2629016 (testing)  86.328125\n",
      "epoch : 546| loss : (train) 0.00312851 (testing) 0.00330645 | accuracy : (train) 90.3602726 (testing)   86.71875\n",
      "epoch : 547| loss : (train) 0.00395298 (testing) 0.00376431 | accuracy : (train) 90.2629016 (testing)   85.15625\n",
      "epoch : 548| loss : (train) 0.00363937 (testing) 0.00351280 | accuracy : (train) 90.7497565 (testing)  86.328125\n",
      "epoch : 549| loss : (train) 0.00327299 (testing) 0.00317308 | accuracy : (train) 90.5550146 (testing)   88.28125\n",
      "epoch : 550| loss : (train) 0.00321619 (testing) 0.00339933 | accuracy : (train) 90.7497565 (testing)  87.109375\n",
      "epoch : 551| loss : (train) 0.00347151 (testing) 0.00321436 | accuracy : (train) 90.6523855 (testing)  87.109375\n",
      "epoch : 552| loss : (train) 0.00325821 (testing) 0.00334568 | accuracy : (train) 90.6523855 (testing)   86.71875\n",
      "epoch : 553| loss : (train) 0.00358284 (testing) 0.00348807 | accuracy : (train) 90.7497565 (testing)  87.109375\n",
      "epoch : 554| loss : (train) 0.00347902 (testing) 0.00334489 | accuracy : (train) 90.6523855 (testing)   86.71875\n",
      "epoch : 555| loss : (train) 0.00395966 (testing) 0.00354824 | accuracy : (train) 90.6523855 (testing)    85.9375\n",
      "epoch : 556| loss : (train) 0.00350540 (testing) 0.00352731 | accuracy : (train) 90.7497565 (testing)   86.71875\n",
      "epoch : 557| loss : (train) 0.00343099 (testing) 0.00333989 | accuracy : (train) 91.1392405 (testing)   86.71875\n",
      "epoch : 558| loss : (train) 0.00344693 (testing) 0.00349336 | accuracy : (train) 90.7497565 (testing)  87.109375\n",
      "epoch : 559| loss : (train) 0.00371893 (testing) 0.00339250 | accuracy : (train) 90.9444985 (testing)  86.328125\n",
      "epoch : 560| loss : (train) 0.00341694 (testing) 0.00346508 | accuracy : (train) 91.1392405 (testing)  87.109375\n",
      "epoch : 561| loss : (train) 0.00296423 (testing) 0.00330557 | accuracy : (train) 90.9444985 (testing)  86.328125\n",
      "epoch : 562| loss : (train) 0.00371007 (testing) 0.00325466 | accuracy : (train) 91.1392405 (testing)  87.109375\n",
      "epoch : 563| loss : (train) 0.00335192 (testing) 0.00326159 | accuracy : (train) 91.0418695 (testing)  87.109375\n",
      "epoch : 564| loss : (train) 0.00331257 (testing) 0.00325613 | accuracy : (train) 90.9444985 (testing)  87.109375\n",
      "epoch : 565| loss : (train) 0.00337695 (testing) 0.00325262 | accuracy : (train) 91.1392405 (testing)  87.109375\n",
      "epoch : 566| loss : (train) 0.00340580 (testing) 0.00334126 | accuracy : (train) 90.8471275 (testing)  86.328125\n",
      "epoch : 567| loss : (train) 0.00349877 (testing) 0.00326455 | accuracy : (train) 90.7497565 (testing)  87.109375\n",
      "epoch : 568| loss : (train) 0.00326419 (testing) 0.00345423 | accuracy : (train) 91.1392405 (testing)  87.109375\n",
      "epoch : 569| loss : (train) 0.00339426 (testing) 0.00341599 | accuracy : (train) 91.1392405 (testing)   86.71875\n",
      "epoch : 570| loss : (train) 0.00338959 (testing) 0.00352382 | accuracy : (train) 90.9444985 (testing)  87.109375\n",
      "epoch : 571| loss : (train) 0.00318982 (testing) 0.00334723 | accuracy : (train) 91.2366114 (testing)   86.71875\n",
      "epoch : 572| loss : (train) 0.00337245 (testing) 0.00347465 | accuracy : (train) 91.1392405 (testing)  87.109375\n",
      "epoch : 573| loss : (train) 0.00331655 (testing) 0.00352178 | accuracy : (train) 91.1392405 (testing)  87.109375\n",
      "epoch : 574| loss : (train) 0.00317896 (testing) 0.00346129 | accuracy : (train) 91.4313534 (testing)  87.109375\n",
      "epoch : 575| loss : (train) 0.00316370 (testing) 0.00332039 | accuracy : (train) 91.1392405 (testing)  87.109375\n",
      "epoch : 576| loss : (train) 0.00335698 (testing) 0.00341319 | accuracy : (train) 91.0418695 (testing)  86.328125\n",
      "epoch : 577| loss : (train) 0.00345924 (testing) 0.00364618 | accuracy : (train) 91.0418695 (testing)   85.15625\n",
      "epoch : 578| loss : (train) 0.00323535 (testing) 0.00330636 | accuracy : (train) 91.3339824 (testing)  87.109375\n",
      "epoch : 579| loss : (train) 0.00336141 (testing) 0.00345097 | accuracy : (train) 91.4313534 (testing)   86.71875\n",
      "epoch : 580| loss : (train) 0.00303010 (testing) 0.00334314 | accuracy : (train) 91.3339824 (testing)  87.109375\n",
      "epoch : 581| loss : (train) 0.00316980 (testing) 0.00334662 | accuracy : (train) 91.7234664 (testing)  87.109375\n",
      "epoch : 582| loss : (train) 0.00339356 (testing) 0.00332997 | accuracy : (train) 91.4313534 (testing)  87.109375\n",
      "epoch : 583| loss : (train) 0.00364775 (testing) 0.00343970 | accuracy : (train) 91.5287244 (testing)   86.71875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 584| loss : (train) 0.00315164 (testing) 0.00344343 | accuracy : (train) 91.4313534 (testing)   86.71875\n",
      "epoch : 585| loss : (train) 0.00335954 (testing) 0.00334015 | accuracy : (train) 91.4313534 (testing)  87.109375\n",
      "epoch : 586| loss : (train) 0.00326642 (testing) 0.00347613 | accuracy : (train) 91.5287244 (testing)  87.109375\n",
      "epoch : 587| loss : (train) 0.00352276 (testing) 0.00345303 | accuracy : (train) 91.6260954 (testing)   86.71875\n",
      "epoch : 588| loss : (train) 0.00335933 (testing) 0.00347960 | accuracy : (train) 91.3339824 (testing)  87.109375\n",
      "epoch : 589| loss : (train) 0.00317200 (testing) 0.00350772 | accuracy : (train) 91.6260954 (testing)  87.109375\n",
      "epoch : 590| loss : (train) 0.00329116 (testing) 0.00354245 | accuracy : (train) 91.6260954 (testing)  87.109375\n",
      "epoch : 591| loss : (train) 0.00317715 (testing) 0.00350737 | accuracy : (train) 91.5287244 (testing)  87.109375\n",
      "epoch : 592| loss : (train) 0.00357975 (testing) 0.00368178 | accuracy : (train) 91.7234664 (testing)  84.765625\n",
      "epoch : 593| loss : (train) 0.00319401 (testing) 0.00342770 | accuracy : (train) 91.8208373 (testing)    85.9375\n",
      "epoch : 594| loss : (train) 0.00316353 (testing) 0.00334489 | accuracy : (train) 91.8208373 (testing)  87.109375\n",
      "epoch : 595| loss : (train) 0.00319928 (testing) 0.00358453 | accuracy : (train) 91.6260954 (testing)  87.109375\n",
      "epoch : 596| loss : (train) 0.00323014 (testing) 0.00347890 | accuracy : (train) 91.6260954 (testing)   86.71875\n",
      "epoch : 597| loss : (train) 0.00303012 (testing) 0.00352234 | accuracy : (train) 91.7234664 (testing)  87.109375\n",
      "epoch : 598| loss : (train) 0.00318639 (testing) 0.00338849 | accuracy : (train) 91.9182083 (testing)  87.109375\n",
      "epoch : 599| loss : (train) 0.00315590 (testing) 0.00359327 | accuracy : (train) 91.6260954 (testing)  87.109375\n",
      "epoch : 600| loss : (train) 0.00325781 (testing) 0.00351867 | accuracy : (train) 91.9182083 (testing)  87.109375\n",
      "epoch : 601| loss : (train) 0.00324687 (testing) 0.00348148 | accuracy : (train) 92.1129503 (testing)   86.71875\n",
      "epoch : 602| loss : (train) 0.00299795 (testing) 0.00350353 | accuracy : (train) 91.9182083 (testing)   86.71875\n",
      "epoch : 603| loss : (train) 0.00345070 (testing) 0.00356413 | accuracy : (train) 91.7234664 (testing)  87.109375\n",
      "epoch : 604| loss : (train) 0.00334806 (testing) 0.00370194 | accuracy : (train) 92.0155793 (testing)  84.765625\n",
      "epoch : 605| loss : (train) 0.00290476 (testing) 0.00350728 | accuracy : (train) 92.3076923 (testing)   86.71875\n",
      "epoch : 606| loss : (train) 0.00285521 (testing) 0.00345105 | accuracy : (train) 92.1129503 (testing)    85.9375\n",
      "epoch : 607| loss : (train) 0.00322487 (testing) 0.00358839 | accuracy : (train) 92.0155793 (testing)  87.109375\n",
      "epoch : 608| loss : (train) 0.00337585 (testing) 0.00350218 | accuracy : (train) 92.1129503 (testing)   86.71875\n",
      "epoch : 609| loss : (train) 0.00308109 (testing) 0.00349293 | accuracy : (train) 92.2103213 (testing)   86.71875\n",
      "epoch : 610| loss : (train) 0.00303921 (testing) 0.00374443 | accuracy : (train) 92.2103213 (testing)  84.765625\n",
      "epoch : 611| loss : (train) 0.00331975 (testing) 0.00341686 | accuracy : (train) 92.2103213 (testing)   86.71875\n",
      "epoch : 612| loss : (train) 0.00299245 (testing) 0.00360413 | accuracy : (train) 92.2103213 (testing)  87.109375\n",
      "epoch : 613| loss : (train) 0.00340843 (testing) 0.00364951 | accuracy : (train) 92.3076923 (testing)    85.9375\n",
      "epoch : 614| loss : (train) 0.00333864 (testing) 0.00357610 | accuracy : (train) 92.4050632 (testing)  87.109375\n",
      "epoch : 615| loss : (train) 0.00301473 (testing) 0.00366379 | accuracy : (train) 92.3076923 (testing)    85.9375\n",
      "epoch : 616| loss : (train) 0.00304910 (testing) 0.00340486 | accuracy : (train) 92.5024342 (testing)  87.109375\n",
      "epoch : 617| loss : (train) 0.00323143 (testing) 0.00352015 | accuracy : (train) 91.9182083 (testing)   86.71875\n",
      "epoch : 618| loss : (train) 0.00290024 (testing) 0.00349105 | accuracy : (train) 92.5998052 (testing)  86.328125\n",
      "epoch : 619| loss : (train) 0.00330918 (testing) 0.00366902 | accuracy : (train) 92.5024342 (testing)    85.9375\n",
      "epoch : 620| loss : (train) 0.00306374 (testing) 0.00347664 | accuracy : (train) 92.3076923 (testing)  86.328125\n",
      "epoch : 621| loss : (train) 0.00346709 (testing) 0.00354150 | accuracy : (train) 91.9182083 (testing)   86.71875\n",
      "epoch : 622| loss : (train) 0.00287500 (testing) 0.00361017 | accuracy : (train) 92.7945472 (testing)  87.109375\n",
      "epoch : 623| loss : (train) 0.00313134 (testing) 0.00352204 | accuracy : (train) 92.7945472 (testing)  86.328125\n",
      "epoch : 624| loss : (train) 0.00325599 (testing) 0.00363134 | accuracy : (train) 92.6971762 (testing)  87.109375\n",
      "epoch : 625| loss : (train) 0.00301470 (testing) 0.00347759 | accuracy : (train) 92.8919182 (testing)   86.71875\n",
      "epoch : 626| loss : (train) 0.00296387 (testing) 0.00362748 | accuracy : (train) 92.7945472 (testing)  87.109375\n",
      "epoch : 627| loss : (train) 0.00308518 (testing) 0.00401347 | accuracy : (train) 92.5024342 (testing)  83.203125\n",
      "epoch : 628| loss : (train) 0.00285977 (testing) 0.00355175 | accuracy : (train) 92.7945472 (testing)  86.328125\n",
      "epoch : 629| loss : (train) 0.00311257 (testing) 0.00375098 | accuracy : (train) 92.8919182 (testing)  84.765625\n",
      "epoch : 630| loss : (train) 0.00294329 (testing) 0.00370993 | accuracy : (train) 92.8919182 (testing)  85.546875\n",
      "epoch : 631| loss : (train) 0.00301673 (testing) 0.00353630 | accuracy : (train) 92.9892891 (testing)   86.71875\n",
      "epoch : 632| loss : (train) 0.00305218 (testing) 0.00385895 | accuracy : (train) 92.4050632 (testing)     84.375\n",
      "epoch : 633| loss : (train) 0.00371287 (testing) 0.00367185 | accuracy : (train) 92.7945472 (testing)  87.109375\n",
      "epoch : 634| loss : (train) 0.00318549 (testing) 0.00358304 | accuracy : (train) 93.2814021 (testing)  86.328125\n",
      "epoch : 635| loss : (train) 0.00323555 (testing) 0.00363367 | accuracy : (train) 92.9892891 (testing)  87.109375\n",
      "epoch : 636| loss : (train) 0.00310070 (testing) 0.00368636 | accuracy : (train) 93.0866601 (testing)   86.71875\n",
      "epoch : 637| loss : (train) 0.00284041 (testing) 0.00360568 | accuracy : (train) 92.9892891 (testing)  87.109375\n",
      "epoch : 638| loss : (train) 0.00293276 (testing) 0.00371469 | accuracy : (train) 93.2814021 (testing)  85.546875\n",
      "epoch : 639| loss : (train) 0.00301782 (testing) 0.00361556 | accuracy : (train) 92.8919182 (testing)  87.109375\n",
      "epoch : 640| loss : (train) 0.00293664 (testing) 0.00348328 | accuracy : (train) 93.1840311 (testing)   86.71875\n",
      "epoch : 641| loss : (train) 0.00274806 (testing) 0.00371614 | accuracy : (train) 93.1840311 (testing)    85.9375\n",
      "epoch : 642| loss : (train) 0.00336719 (testing) 0.00392322 | accuracy : (train) 93.3787731 (testing)     84.375\n",
      "epoch : 643| loss : (train) 0.00312004 (testing) 0.00364228 | accuracy : (train) 92.6971762 (testing)  87.109375\n",
      "epoch : 644| loss : (train) 0.00291900 (testing) 0.00365307 | accuracy : (train) 92.8919182 (testing)  87.109375\n",
      "epoch : 645| loss : (train) 0.00317545 (testing) 0.00355530 | accuracy : (train) 93.0866601 (testing)   86.71875\n",
      "epoch : 646| loss : (train) 0.00279710 (testing) 0.00358992 | accuracy : (train) 93.2814021 (testing)   86.71875\n",
      "epoch : 647| loss : (train) 0.00305711 (testing) 0.00361524 | accuracy : (train) 93.0866601 (testing)  86.328125\n",
      "epoch : 648| loss : (train) 0.00300591 (testing) 0.00386741 | accuracy : (train) 93.1840311 (testing)     84.375\n",
      "epoch : 649| loss : (train) 0.00310148 (testing) 0.00356718 | accuracy : (train) 93.5735150 (testing)   86.71875\n",
      "epoch : 650| loss : (train) 0.00329656 (testing) 0.00377201 | accuracy : (train) 92.9892891 (testing)  84.765625\n",
      "epoch : 651| loss : (train) 0.00278744 (testing) 0.00344981 | accuracy : (train) 93.2814021 (testing)  87.109375\n",
      "epoch : 652| loss : (train) 0.00281528 (testing) 0.00365754 | accuracy : (train) 92.9892891 (testing)  86.328125\n",
      "epoch : 653| loss : (train) 0.00322651 (testing) 0.00354012 | accuracy : (train) 93.3787731 (testing)   86.71875\n",
      "epoch : 654| loss : (train) 0.00312512 (testing) 0.00377056 | accuracy : (train) 93.5735150 (testing)   85.15625\n",
      "epoch : 655| loss : (train) 0.00284034 (testing) 0.00375536 | accuracy : (train) 93.3787731 (testing)    85.9375\n",
      "epoch : 656| loss : (train) 0.00285206 (testing) 0.00375775 | accuracy : (train) 93.3787731 (testing)    85.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 657| loss : (train) 0.00298398 (testing) 0.00388682 | accuracy : (train) 93.3787731 (testing)  83.984375\n",
      "epoch : 658| loss : (train) 0.00305238 (testing) 0.00373363 | accuracy : (train) 93.5735150 (testing)   86.71875\n",
      "epoch : 659| loss : (train) 0.00273184 (testing) 0.00373628 | accuracy : (train) 93.1840311 (testing)   86.71875\n",
      "epoch : 660| loss : (train) 0.00302298 (testing) 0.00390075 | accuracy : (train) 93.3787731 (testing)  83.984375\n",
      "epoch : 661| loss : (train) 0.00288341 (testing) 0.00379265 | accuracy : (train) 93.4761441 (testing)  84.765625\n",
      "epoch : 662| loss : (train) 0.00279472 (testing) 0.00376155 | accuracy : (train) 93.4761441 (testing)  86.328125\n",
      "epoch : 663| loss : (train) 0.00303211 (testing) 0.00428873 | accuracy : (train) 93.5735150 (testing)   82.03125\n",
      "epoch : 664| loss : (train) 0.00331044 (testing) 0.00376695 | accuracy : (train) 93.4761441 (testing)  86.328125\n",
      "epoch : 665| loss : (train) 0.00289926 (testing) 0.00377585 | accuracy : (train) 93.2814021 (testing)    85.9375\n",
      "epoch : 666| loss : (train) 0.00288119 (testing) 0.00403031 | accuracy : (train) 93.4761441 (testing)  83.984375\n",
      "epoch : 667| loss : (train) 0.00272366 (testing) 0.00394823 | accuracy : (train) 93.5735150 (testing)  83.984375\n",
      "epoch : 668| loss : (train) 0.00292363 (testing) 0.00397215 | accuracy : (train) 93.5735150 (testing)   83.59375\n",
      "epoch : 669| loss : (train) 0.00286025 (testing) 0.00354978 | accuracy : (train) 93.5735150 (testing)  87.109375\n",
      "epoch : 670| loss : (train) 0.00259313 (testing) 0.00372028 | accuracy : (train) 93.6708860 (testing)   86.71875\n",
      "epoch : 671| loss : (train) 0.00294731 (testing) 0.00378670 | accuracy : (train) 93.5735150 (testing)  86.328125\n",
      "epoch : 672| loss : (train) 0.00304607 (testing) 0.00381842 | accuracy : (train) 93.7682570 (testing)  84.765625\n",
      "epoch : 673| loss : (train) 0.00252330 (testing) 0.00395541 | accuracy : (train) 93.5735150 (testing)  83.984375\n",
      "epoch : 674| loss : (train) 0.00288947 (testing) 0.00380191 | accuracy : (train) 93.4761441 (testing)   85.15625\n",
      "epoch : 675| loss : (train) 0.00271175 (testing) 0.00405948 | accuracy : (train) 93.7682570 (testing)  83.984375\n",
      "epoch : 676| loss : (train) 0.00309277 (testing) 0.00386691 | accuracy : (train) 93.9629990 (testing)     84.375\n",
      "epoch : 677| loss : (train) 0.00285995 (testing) 0.00384340 | accuracy : (train) 94.0603700 (testing)  84.765625\n",
      "epoch : 678| loss : (train) 0.00269338 (testing) 0.00372231 | accuracy : (train) 93.7682570 (testing)   86.71875\n",
      "epoch : 679| loss : (train) 0.00282248 (testing) 0.00389389 | accuracy : (train) 93.9629990 (testing)     84.375\n",
      "epoch : 680| loss : (train) 0.00274784 (testing) 0.00360609 | accuracy : (train) 94.2551119 (testing)   86.71875\n",
      "epoch : 681| loss : (train) 0.00265555 (testing) 0.00371545 | accuracy : (train) 93.9629990 (testing)   86.71875\n",
      "epoch : 682| loss : (train) 0.00270382 (testing) 0.00363281 | accuracy : (train) 93.9629990 (testing)   86.71875\n",
      "epoch : 683| loss : (train) 0.00258094 (testing) 0.00378804 | accuracy : (train) 94.2551119 (testing)  86.328125\n",
      "epoch : 684| loss : (train) 0.00292009 (testing) 0.00373247 | accuracy : (train) 93.7682570 (testing)   86.71875\n",
      "epoch : 685| loss : (train) 0.00255582 (testing) 0.00367415 | accuracy : (train) 94.2551119 (testing)   86.71875\n",
      "epoch : 686| loss : (train) 0.00284958 (testing) 0.00381021 | accuracy : (train) 93.8656280 (testing)    85.9375\n",
      "epoch : 687| loss : (train) 0.00300040 (testing) 0.00400286 | accuracy : (train) 94.2551119 (testing)   83.59375\n",
      "epoch : 688| loss : (train) 0.00264957 (testing) 0.00365551 | accuracy : (train) 94.2551119 (testing)  86.328125\n",
      "epoch : 689| loss : (train) 0.00290760 (testing) 0.00368184 | accuracy : (train) 94.0603700 (testing)   86.71875\n",
      "epoch : 690| loss : (train) 0.00275612 (testing) 0.00391427 | accuracy : (train) 94.3524829 (testing)     84.375\n",
      "epoch : 691| loss : (train) 0.00262908 (testing) 0.00411168 | accuracy : (train) 94.2551119 (testing)    82.8125\n",
      "epoch : 692| loss : (train) 0.00252269 (testing) 0.00389107 | accuracy : (train) 94.3524829 (testing)     84.375\n",
      "epoch : 693| loss : (train) 0.00253091 (testing) 0.00386665 | accuracy : (train) 94.1577409 (testing)  84.765625\n",
      "epoch : 694| loss : (train) 0.00287578 (testing) 0.00411922 | accuracy : (train) 94.1577409 (testing)    82.8125\n",
      "epoch : 695| loss : (train) 0.00233532 (testing) 0.00386880 | accuracy : (train) 94.2551119 (testing)  84.765625\n",
      "epoch : 696| loss : (train) 0.00275233 (testing) 0.00402854 | accuracy : (train) 93.8656280 (testing)   83.59375\n",
      "epoch : 697| loss : (train) 0.00273037 (testing) 0.00402428 | accuracy : (train) 94.2551119 (testing)   83.59375\n",
      "epoch : 698| loss : (train) 0.00274383 (testing) 0.00398619 | accuracy : (train) 93.9629990 (testing)  83.984375\n",
      "epoch : 699| loss : (train) 0.00268933 (testing) 0.00384231 | accuracy : (train) 94.3524829 (testing)    85.9375\n",
      "epoch : 700| loss : (train) 0.00287794 (testing) 0.00385267 | accuracy : (train) 94.4498539 (testing)    85.9375\n",
      "epoch : 701| loss : (train) 0.00276616 (testing) 0.00383212 | accuracy : (train) 94.0603700 (testing)  86.328125\n",
      "epoch : 702| loss : (train) 0.00259644 (testing) 0.00407671 | accuracy : (train) 94.3524829 (testing)   83.59375\n",
      "epoch : 703| loss : (train) 0.00276662 (testing) 0.00393635 | accuracy : (train) 94.7419668 (testing)     84.375\n",
      "epoch : 704| loss : (train) 0.00252454 (testing) 0.00394073 | accuracy : (train) 94.5472249 (testing)     84.375\n",
      "epoch : 705| loss : (train) 0.00264869 (testing) 0.00376269 | accuracy : (train) 94.2551119 (testing)  87.109375\n",
      "epoch : 706| loss : (train) 0.00257911 (testing) 0.00383758 | accuracy : (train) 94.3524829 (testing)  86.328125\n",
      "epoch : 707| loss : (train) 0.00275512 (testing) 0.00393173 | accuracy : (train) 94.4498539 (testing)  84.765625\n",
      "epoch : 708| loss : (train) 0.00267103 (testing) 0.00376696 | accuracy : (train) 94.0603700 (testing)  87.109375\n",
      "epoch : 709| loss : (train) 0.00263542 (testing) 0.00372098 | accuracy : (train) 94.5472249 (testing)  86.328125\n",
      "epoch : 710| loss : (train) 0.00248244 (testing) 0.00379947 | accuracy : (train) 94.1577409 (testing)   86.71875\n",
      "epoch : 711| loss : (train) 0.00255818 (testing) 0.00374800 | accuracy : (train) 94.5472249 (testing)  86.328125\n",
      "epoch : 712| loss : (train) 0.00308918 (testing) 0.00425198 | accuracy : (train) 94.4498539 (testing)  82.421875\n",
      "epoch : 713| loss : (train) 0.00238098 (testing) 0.00393703 | accuracy : (train) 94.6445959 (testing)     84.375\n",
      "epoch : 714| loss : (train) 0.00250226 (testing) 0.00376346 | accuracy : (train) 94.3524829 (testing)   86.71875\n",
      "epoch : 715| loss : (train) 0.00289194 (testing) 0.00394315 | accuracy : (train) 94.6445959 (testing)     84.375\n",
      "epoch : 716| loss : (train) 0.00254536 (testing) 0.00408400 | accuracy : (train) 94.6445959 (testing)   83.59375\n",
      "epoch : 717| loss : (train) 0.00241638 (testing) 0.00434314 | accuracy : (train) 94.6445959 (testing)      81.25\n",
      "epoch : 718| loss : (train) 0.00261788 (testing) 0.00361742 | accuracy : (train) 94.9367088 (testing)   86.71875\n",
      "epoch : 719| loss : (train) 0.00263592 (testing) 0.00392075 | accuracy : (train) 94.5472249 (testing)   85.15625\n",
      "epoch : 720| loss : (train) 0.00286892 (testing) 0.00410281 | accuracy : (train) 94.6445959 (testing)   83.59375\n",
      "epoch : 721| loss : (train) 0.00254729 (testing) 0.00413569 | accuracy : (train) 94.8393378 (testing)   83.59375\n",
      "epoch : 722| loss : (train) 0.00269087 (testing) 0.00396468 | accuracy : (train) 94.8393378 (testing)     84.375\n",
      "epoch : 723| loss : (train) 0.00247553 (testing) 0.00396257 | accuracy : (train) 94.7419668 (testing)     84.375\n",
      "epoch : 724| loss : (train) 0.00251906 (testing) 0.00382221 | accuracy : (train) 94.7419668 (testing)   86.71875\n",
      "epoch : 725| loss : (train) 0.00254453 (testing) 0.00363980 | accuracy : (train) 94.5472249 (testing)   86.71875\n",
      "epoch : 726| loss : (train) 0.00260779 (testing) 0.00412371 | accuracy : (train) 94.4498539 (testing)   83.59375\n",
      "epoch : 727| loss : (train) 0.00272082 (testing) 0.00418828 | accuracy : (train) 94.9367088 (testing)  83.203125\n",
      "epoch : 728| loss : (train) 0.00248494 (testing) 0.00379660 | accuracy : (train) 95.2288218 (testing)   86.71875\n",
      "epoch : 729| loss : (train) 0.00242691 (testing) 0.00401600 | accuracy : (train) 94.8393378 (testing)   83.59375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 730| loss : (train) 0.00259072 (testing) 0.00365103 | accuracy : (train) 94.8393378 (testing)  86.328125\n",
      "epoch : 731| loss : (train) 0.00233949 (testing) 0.00401584 | accuracy : (train) 94.5472249 (testing)   83.59375\n",
      "epoch : 732| loss : (train) 0.00254693 (testing) 0.00408923 | accuracy : (train) 95.0340798 (testing)   83.59375\n",
      "epoch : 733| loss : (train) 0.00265771 (testing) 0.00438141 | accuracy : (train) 94.8393378 (testing)      81.25\n",
      "epoch : 734| loss : (train) 0.00248909 (testing) 0.00414587 | accuracy : (train) 94.9367088 (testing)   83.59375\n",
      "epoch : 735| loss : (train) 0.00243864 (testing) 0.00384718 | accuracy : (train) 95.1314508 (testing)  86.328125\n",
      "epoch : 736| loss : (train) 0.00226982 (testing) 0.00402602 | accuracy : (train) 94.5472249 (testing)  83.203125\n",
      "epoch : 737| loss : (train) 0.00246632 (testing) 0.00417241 | accuracy : (train) 94.5472249 (testing)   83.59375\n",
      "epoch : 738| loss : (train) 0.00244956 (testing) 0.00396656 | accuracy : (train) 94.5472249 (testing)   85.15625\n",
      "epoch : 739| loss : (train) 0.00253243 (testing) 0.00405359 | accuracy : (train) 94.7419668 (testing)  83.203125\n",
      "epoch : 740| loss : (train) 0.00281461 (testing) 0.00401809 | accuracy : (train) 95.0340798 (testing)     84.375\n",
      "epoch : 741| loss : (train) 0.00249720 (testing) 0.00394208 | accuracy : (train) 95.2288218 (testing)  85.546875\n",
      "epoch : 742| loss : (train) 0.00225939 (testing) 0.00386960 | accuracy : (train) 94.8393378 (testing)  86.328125\n",
      "epoch : 743| loss : (train) 0.00235193 (testing) 0.00392139 | accuracy : (train) 94.7419668 (testing)    85.9375\n",
      "epoch : 744| loss : (train) 0.00223829 (testing) 0.00407140 | accuracy : (train) 94.7419668 (testing)  83.203125\n",
      "epoch : 745| loss : (train) 0.00262881 (testing) 0.00384648 | accuracy : (train) 95.0340798 (testing)    85.9375\n",
      "epoch : 746| loss : (train) 0.00244746 (testing) 0.00385739 | accuracy : (train) 94.9367088 (testing)  86.328125\n",
      "epoch : 747| loss : (train) 0.00239043 (testing) 0.00395687 | accuracy : (train) 95.0340798 (testing)  85.546875\n",
      "epoch : 748| loss : (train) 0.00257963 (testing) 0.00410785 | accuracy : (train) 95.0340798 (testing)  83.203125\n",
      "epoch : 749| loss : (train) 0.00240855 (testing) 0.00403704 | accuracy : (train) 95.1314508 (testing)     84.375\n",
      "epoch : 750| loss : (train) 0.00246494 (testing) 0.00401838 | accuracy : (train) 95.2288218 (testing)   85.15625\n",
      "epoch : 751| loss : (train) 0.00233072 (testing) 0.00392281 | accuracy : (train) 95.0340798 (testing)   86.71875\n",
      "epoch : 752| loss : (train) 0.00241173 (testing) 0.00410091 | accuracy : (train) 95.1314508 (testing)  83.203125\n",
      "epoch : 753| loss : (train) 0.00264619 (testing) 0.00392909 | accuracy : (train) 95.1314508 (testing)    85.9375\n",
      "epoch : 754| loss : (train) 0.00241229 (testing) 0.00403832 | accuracy : (train) 95.0340798 (testing)  84.765625\n",
      "epoch : 755| loss : (train) 0.00256905 (testing) 0.00444265 | accuracy : (train) 94.9367088 (testing)  80.859375\n",
      "epoch : 756| loss : (train) 0.00268843 (testing) 0.00439909 | accuracy : (train) 94.9367088 (testing)      81.25\n",
      "epoch : 757| loss : (train) 0.00245623 (testing) 0.00398292 | accuracy : (train) 95.0340798 (testing)  85.546875\n",
      "epoch : 758| loss : (train) 0.00243833 (testing) 0.00376532 | accuracy : (train) 94.9367088 (testing)  86.328125\n",
      "epoch : 759| loss : (train) 0.00244156 (testing) 0.00437833 | accuracy : (train) 94.8393378 (testing)  81.640625\n",
      "epoch : 760| loss : (train) 0.00243638 (testing) 0.00436029 | accuracy : (train) 95.1314508 (testing)  81.640625\n",
      "epoch : 761| loss : (train) 0.00254174 (testing) 0.00443621 | accuracy : (train) 95.2288218 (testing)  80.859375\n",
      "epoch : 762| loss : (train) 0.00246546 (testing) 0.00385710 | accuracy : (train) 95.4235637 (testing)   86.71875\n",
      "epoch : 763| loss : (train) 0.00248673 (testing) 0.00446636 | accuracy : (train) 95.2288218 (testing)  80.859375\n",
      "epoch : 764| loss : (train) 0.00232249 (testing) 0.00420508 | accuracy : (train) 95.1314508 (testing)  83.203125\n",
      "epoch : 765| loss : (train) 0.00226932 (testing) 0.00413688 | accuracy : (train) 95.3261927 (testing)  83.203125\n",
      "epoch : 766| loss : (train) 0.00239391 (testing) 0.00429254 | accuracy : (train) 95.2288218 (testing)    82.8125\n",
      "epoch : 767| loss : (train) 0.00223472 (testing) 0.00419882 | accuracy : (train) 95.5209347 (testing)  83.203125\n",
      "epoch : 768| loss : (train) 0.00249559 (testing) 0.00398287 | accuracy : (train) 95.1314508 (testing)    85.9375\n",
      "epoch : 769| loss : (train) 0.00230497 (testing) 0.00450474 | accuracy : (train) 95.1314508 (testing)  80.859375\n",
      "epoch : 770| loss : (train) 0.00231656 (testing) 0.00399858 | accuracy : (train) 95.0340798 (testing)    85.9375\n",
      "epoch : 771| loss : (train) 0.00221965 (testing) 0.00393949 | accuracy : (train) 95.3261927 (testing)    85.9375\n",
      "epoch : 772| loss : (train) 0.00225275 (testing) 0.00430364 | accuracy : (train) 95.5209347 (testing)    82.8125\n",
      "epoch : 773| loss : (train) 0.00226906 (testing) 0.00404862 | accuracy : (train) 95.4235637 (testing)  85.546875\n",
      "epoch : 774| loss : (train) 0.00237991 (testing) 0.00420674 | accuracy : (train) 95.1314508 (testing)  83.203125\n",
      "epoch : 775| loss : (train) 0.00234697 (testing) 0.00416058 | accuracy : (train) 95.3261927 (testing)   83.59375\n",
      "epoch : 776| loss : (train) 0.00256772 (testing) 0.00460671 | accuracy : (train) 95.4235637 (testing)      81.25\n",
      "epoch : 777| loss : (train) 0.00220873 (testing) 0.00409524 | accuracy : (train) 95.1314508 (testing)     84.375\n",
      "epoch : 778| loss : (train) 0.00234513 (testing) 0.00422578 | accuracy : (train) 95.3261927 (testing)  83.203125\n",
      "epoch : 779| loss : (train) 0.00249758 (testing) 0.00394395 | accuracy : (train) 95.4235637 (testing)  86.328125\n",
      "epoch : 780| loss : (train) 0.00229604 (testing) 0.00429907 | accuracy : (train) 95.2288218 (testing)  82.421875\n",
      "epoch : 781| loss : (train) 0.00226327 (testing) 0.00411750 | accuracy : (train) 95.4235637 (testing)  83.984375\n",
      "epoch : 782| loss : (train) 0.00237871 (testing) 0.00447991 | accuracy : (train) 95.2288218 (testing)      81.25\n",
      "epoch : 783| loss : (train) 0.00223041 (testing) 0.00419638 | accuracy : (train) 95.4235637 (testing)   83.59375\n",
      "epoch : 784| loss : (train) 0.00205573 (testing) 0.00453820 | accuracy : (train) 95.3261927 (testing)  80.859375\n",
      "epoch : 785| loss : (train) 0.00259182 (testing) 0.00454964 | accuracy : (train) 95.1314508 (testing)  80.859375\n",
      "epoch : 786| loss : (train) 0.00227858 (testing) 0.00439214 | accuracy : (train) 95.5209347 (testing)   82.03125\n",
      "epoch : 787| loss : (train) 0.00228981 (testing) 0.00431746 | accuracy : (train) 95.4235637 (testing)  82.421875\n",
      "epoch : 788| loss : (train) 0.00235160 (testing) 0.00452371 | accuracy : (train) 95.6183057 (testing)  80.859375\n",
      "epoch : 789| loss : (train) 0.00255116 (testing) 0.00393222 | accuracy : (train) 95.5209347 (testing)   86.71875\n",
      "epoch : 790| loss : (train) 0.00223020 (testing) 0.00399738 | accuracy : (train) 95.6183057 (testing)    85.9375\n",
      "epoch : 791| loss : (train) 0.00239178 (testing) 0.00435998 | accuracy : (train) 95.5209347 (testing)   82.03125\n",
      "epoch : 792| loss : (train) 0.00243930 (testing) 0.00435841 | accuracy : (train) 95.2288218 (testing)   82.03125\n",
      "epoch : 793| loss : (train) 0.00273513 (testing) 0.00416718 | accuracy : (train) 95.5209347 (testing)  83.984375\n",
      "epoch : 794| loss : (train) 0.00214111 (testing) 0.00416327 | accuracy : (train) 95.6183057 (testing)  83.984375\n",
      "epoch : 795| loss : (train) 0.00222910 (testing) 0.00407060 | accuracy : (train) 95.6183057 (testing)  85.546875\n",
      "epoch : 796| loss : (train) 0.00231158 (testing) 0.00417449 | accuracy : (train) 95.5209347 (testing)  83.984375\n",
      "epoch : 797| loss : (train) 0.00221085 (testing) 0.00413670 | accuracy : (train) 95.4235637 (testing)     84.375\n",
      "epoch : 798| loss : (train) 0.00236854 (testing) 0.00426917 | accuracy : (train) 95.6183057 (testing)    82.8125\n",
      "epoch : 799| loss : (train) 0.00218045 (testing) 0.00401829 | accuracy : (train) 95.5209347 (testing)    85.9375\n",
      "epoch : 800| loss : (train) 0.00236015 (testing) 0.00450343 | accuracy : (train) 95.5209347 (testing)      81.25\n",
      "epoch : 801| loss : (train) 0.00248046 (testing) 0.00428389 | accuracy : (train) 95.6183057 (testing)    82.8125\n",
      "epoch : 802| loss : (train) 0.00223820 (testing) 0.00420603 | accuracy : (train) 95.6183057 (testing)   83.59375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 803| loss : (train) 0.00256295 (testing) 0.00429947 | accuracy : (train) 95.5209347 (testing)    82.8125\n",
      "epoch : 804| loss : (train) 0.00216429 (testing) 0.00429455 | accuracy : (train) 95.4235637 (testing)    82.8125\n",
      "epoch : 805| loss : (train) 0.00229609 (testing) 0.00461163 | accuracy : (train) 95.7156767 (testing)  80.859375\n",
      "epoch : 806| loss : (train) 0.00237417 (testing) 0.00428295 | accuracy : (train) 95.6183057 (testing)    82.8125\n",
      "epoch : 807| loss : (train) 0.00228798 (testing) 0.00449077 | accuracy : (train) 95.8130477 (testing)  81.640625\n",
      "epoch : 808| loss : (train) 0.00222222 (testing) 0.00433690 | accuracy : (train) 95.5209347 (testing)    82.8125\n",
      "epoch : 809| loss : (train) 0.00230820 (testing) 0.00405193 | accuracy : (train) 95.6183057 (testing)  85.546875\n",
      "epoch : 810| loss : (train) 0.00212538 (testing) 0.00444627 | accuracy : (train) 95.5209347 (testing)      81.25\n",
      "epoch : 811| loss : (train) 0.00235057 (testing) 0.00464718 | accuracy : (train) 95.8130477 (testing)  80.859375\n",
      "epoch : 812| loss : (train) 0.00204386 (testing) 0.00420433 | accuracy : (train) 95.9104186 (testing)     84.375\n",
      "epoch : 813| loss : (train) 0.00203212 (testing) 0.00409862 | accuracy : (train) 95.8130477 (testing)   85.15625\n",
      "epoch : 814| loss : (train) 0.00218949 (testing) 0.00399201 | accuracy : (train) 95.7156767 (testing)  86.328125\n",
      "epoch : 815| loss : (train) 0.00208722 (testing) 0.00409934 | accuracy : (train) 95.7156767 (testing)  85.546875\n",
      "epoch : 816| loss : (train) 0.00214554 (testing) 0.00417188 | accuracy : (train) 95.6183057 (testing)  84.765625\n",
      "epoch : 817| loss : (train) 0.00220140 (testing) 0.00431563 | accuracy : (train) 95.8130477 (testing)    82.8125\n",
      "epoch : 818| loss : (train) 0.00228791 (testing) 0.00460175 | accuracy : (train) 95.6183057 (testing)      81.25\n",
      "epoch : 819| loss : (train) 0.00231859 (testing) 0.00459991 | accuracy : (train) 95.8130477 (testing)      81.25\n",
      "epoch : 820| loss : (train) 0.00214892 (testing) 0.00434957 | accuracy : (train) 95.7156767 (testing)    82.8125\n",
      "epoch : 821| loss : (train) 0.00210902 (testing) 0.00409974 | accuracy : (train) 95.7156767 (testing)  85.546875\n",
      "epoch : 822| loss : (train) 0.00232582 (testing) 0.00475573 | accuracy : (train) 95.9104186 (testing)   80.46875\n",
      "epoch : 823| loss : (train) 0.00229253 (testing) 0.00396140 | accuracy : (train) 95.9104186 (testing)  86.328125\n",
      "epoch : 824| loss : (train) 0.00229568 (testing) 0.00439480 | accuracy : (train) 95.5209347 (testing)  82.421875\n",
      "epoch : 825| loss : (train) 0.00200421 (testing) 0.00417796 | accuracy : (train) 95.8130477 (testing)  84.765625\n",
      "epoch : 826| loss : (train) 0.00200712 (testing) 0.00464994 | accuracy : (train) 95.8130477 (testing)  80.859375\n",
      "epoch : 827| loss : (train) 0.00238606 (testing) 0.00408487 | accuracy : (train) 95.8130477 (testing)  86.328125\n",
      "epoch : 828| loss : (train) 0.00211571 (testing) 0.00432134 | accuracy : (train) 95.8130477 (testing)    82.8125\n",
      "epoch : 829| loss : (train) 0.00201073 (testing) 0.00445604 | accuracy : (train) 95.9104186 (testing)   82.03125\n",
      "epoch : 830| loss : (train) 0.00224769 (testing) 0.00491484 | accuracy : (train) 96.0077896 (testing)   80.46875\n",
      "epoch : 831| loss : (train) 0.00215207 (testing) 0.00431987 | accuracy : (train) 95.9104186 (testing)  83.203125\n",
      "epoch : 832| loss : (train) 0.00213489 (testing) 0.00413948 | accuracy : (train) 95.8130477 (testing)   85.15625\n",
      "epoch : 833| loss : (train) 0.00206988 (testing) 0.00454973 | accuracy : (train) 95.9104186 (testing)      81.25\n",
      "epoch : 834| loss : (train) 0.00189853 (testing) 0.00432046 | accuracy : (train) 96.1051606 (testing)  83.203125\n",
      "epoch : 835| loss : (train) 0.00197545 (testing) 0.00437773 | accuracy : (train) 95.8130477 (testing)    82.8125\n",
      "epoch : 836| loss : (train) 0.00199634 (testing) 0.00421678 | accuracy : (train) 96.2025316 (testing)  84.765625\n",
      "epoch : 837| loss : (train) 0.00215552 (testing) 0.00445317 | accuracy : (train) 95.8130477 (testing)   82.03125\n",
      "epoch : 838| loss : (train) 0.00196641 (testing) 0.00470751 | accuracy : (train) 96.0077896 (testing)   80.46875\n",
      "epoch : 839| loss : (train) 0.00235183 (testing) 0.00444674 | accuracy : (train) 96.0077896 (testing)   82.03125\n",
      "epoch : 840| loss : (train) 0.00195429 (testing) 0.00435273 | accuracy : (train) 96.0077896 (testing)  83.203125\n",
      "epoch : 841| loss : (train) 0.00225042 (testing) 0.00476217 | accuracy : (train) 96.1051606 (testing)   80.46875\n",
      "epoch : 842| loss : (train) 0.00216908 (testing) 0.00441476 | accuracy : (train) 96.0077896 (testing)  82.421875\n",
      "epoch : 843| loss : (train) 0.00230590 (testing) 0.00447950 | accuracy : (train) 95.9104186 (testing)  81.640625\n",
      "epoch : 844| loss : (train) 0.00216316 (testing) 0.00464894 | accuracy : (train) 96.0077896 (testing)  80.859375\n",
      "epoch : 845| loss : (train) 0.00205386 (testing) 0.00459100 | accuracy : (train) 96.0077896 (testing)      81.25\n",
      "epoch : 846| loss : (train) 0.00232576 (testing) 0.00480729 | accuracy : (train) 96.0077896 (testing)   80.46875\n",
      "epoch : 847| loss : (train) 0.00223212 (testing) 0.00441764 | accuracy : (train) 96.1051606 (testing)  82.421875\n",
      "epoch : 848| loss : (train) 0.00199241 (testing) 0.00430281 | accuracy : (train) 96.1051606 (testing)  83.984375\n",
      "epoch : 849| loss : (train) 0.00210117 (testing) 0.00451233 | accuracy : (train) 96.0077896 (testing)  81.640625\n",
      "epoch : 850| loss : (train) 0.00247218 (testing) 0.00479318 | accuracy : (train) 96.0077896 (testing)   80.46875\n",
      "epoch : 851| loss : (train) 0.00207353 (testing) 0.00418222 | accuracy : (train) 95.8130477 (testing)  85.546875\n",
      "epoch : 852| loss : (train) 0.00218498 (testing) 0.00513095 | accuracy : (train) 96.5920155 (testing)   80.46875\n",
      "epoch : 853| loss : (train) 0.00233115 (testing) 0.00471391 | accuracy : (train) 96.0077896 (testing)   80.46875\n",
      "epoch : 854| loss : (train) 0.00211470 (testing) 0.00457278 | accuracy : (train) 96.2999026 (testing)  81.640625\n",
      "epoch : 855| loss : (train) 0.00212910 (testing) 0.00421050 | accuracy : (train) 96.2999026 (testing)   85.15625\n",
      "epoch : 856| loss : (train) 0.00236401 (testing) 0.00475632 | accuracy : (train) 96.1051606 (testing)   80.46875\n",
      "epoch : 857| loss : (train) 0.00226840 (testing) 0.00446838 | accuracy : (train) 96.2025316 (testing)  82.421875\n",
      "epoch : 858| loss : (train) 0.00197730 (testing) 0.00432324 | accuracy : (train) 96.3972736 (testing)  83.984375\n",
      "epoch : 859| loss : (train) 0.00207731 (testing) 0.00409456 | accuracy : (train) 96.2025316 (testing)    85.9375\n",
      "epoch : 860| loss : (train) 0.00208576 (testing) 0.00480866 | accuracy : (train) 96.5920155 (testing)  80.078125\n",
      "epoch : 861| loss : (train) 0.00192106 (testing) 0.00468125 | accuracy : (train) 96.3972736 (testing)      81.25\n",
      "epoch : 862| loss : (train) 0.00193513 (testing) 0.00470978 | accuracy : (train) 96.2025316 (testing)  80.859375\n",
      "epoch : 863| loss : (train) 0.00197212 (testing) 0.00484615 | accuracy : (train) 95.9104186 (testing)   80.46875\n",
      "epoch : 864| loss : (train) 0.00193602 (testing) 0.00471513 | accuracy : (train) 96.1051606 (testing)  80.859375\n",
      "epoch : 865| loss : (train) 0.00199654 (testing) 0.00433104 | accuracy : (train) 96.5920155 (testing)     84.375\n",
      "epoch : 866| loss : (train) 0.00221378 (testing) 0.00522803 | accuracy : (train) 96.1051606 (testing)   80.46875\n",
      "epoch : 867| loss : (train) 0.00198481 (testing) 0.00506121 | accuracy : (train) 96.3972736 (testing)  80.078125\n",
      "epoch : 868| loss : (train) 0.00186307 (testing) 0.00443582 | accuracy : (train) 96.4946445 (testing)  83.203125\n",
      "epoch : 869| loss : (train) 0.00193265 (testing) 0.00445070 | accuracy : (train) 96.2999026 (testing)    82.8125\n",
      "epoch : 870| loss : (train) 0.00193603 (testing) 0.00483384 | accuracy : (train) 96.2025316 (testing)  80.078125\n",
      "epoch : 871| loss : (train) 0.00219449 (testing) 0.00471993 | accuracy : (train) 96.2025316 (testing)      81.25\n",
      "epoch : 872| loss : (train) 0.00208705 (testing) 0.00490388 | accuracy : (train) 96.5920155 (testing)   80.46875\n",
      "epoch : 873| loss : (train) 0.00228493 (testing) 0.00442484 | accuracy : (train) 96.3972736 (testing)  83.203125\n",
      "epoch : 874| loss : (train) 0.00196358 (testing) 0.00459192 | accuracy : (train) 96.5920155 (testing)      81.25\n",
      "epoch : 875| loss : (train) 0.00195182 (testing) 0.00474311 | accuracy : (train) 96.2999026 (testing)  80.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 876| loss : (train) 0.00179006 (testing) 0.00489958 | accuracy : (train) 96.4946445 (testing)  80.078125\n",
      "epoch : 877| loss : (train) 0.00220912 (testing) 0.00472322 | accuracy : (train) 96.3972736 (testing)      81.25\n",
      "epoch : 878| loss : (train) 0.00205430 (testing) 0.00472423 | accuracy : (train) 96.8841285 (testing)      81.25\n",
      "epoch : 879| loss : (train) 0.00211368 (testing) 0.00484761 | accuracy : (train) 96.5920155 (testing)  80.078125\n",
      "epoch : 880| loss : (train) 0.00183184 (testing) 0.00446461 | accuracy : (train) 96.5920155 (testing)    82.8125\n",
      "epoch : 881| loss : (train) 0.00200680 (testing) 0.00450064 | accuracy : (train) 96.4946445 (testing)    82.8125\n",
      "epoch : 882| loss : (train) 0.00215908 (testing) 0.00445823 | accuracy : (train) 96.7867575 (testing)  83.203125\n",
      "epoch : 883| loss : (train) 0.00184238 (testing) 0.00483146 | accuracy : (train) 96.6893865 (testing)   80.46875\n",
      "epoch : 884| loss : (train) 0.00191613 (testing) 0.00454622 | accuracy : (train) 96.7867575 (testing)   82.03125\n",
      "epoch : 885| loss : (train) 0.00214383 (testing) 0.00452285 | accuracy : (train) 96.7867575 (testing)    82.8125\n",
      "epoch : 886| loss : (train) 0.00203829 (testing) 0.00462361 | accuracy : (train) 96.5920155 (testing)      81.25\n",
      "epoch : 887| loss : (train) 0.00200999 (testing) 0.00425673 | accuracy : (train) 96.5920155 (testing)  84.765625\n",
      "epoch : 888| loss : (train) 0.00186386 (testing) 0.00453578 | accuracy : (train) 96.5920155 (testing)    82.8125\n",
      "epoch : 889| loss : (train) 0.00204888 (testing) 0.00473387 | accuracy : (train) 96.5920155 (testing)  80.859375\n",
      "epoch : 890| loss : (train) 0.00207901 (testing) 0.00437649 | accuracy : (train) 96.6893865 (testing)  83.984375\n",
      "epoch : 891| loss : (train) 0.00181642 (testing) 0.00488874 | accuracy : (train) 96.8841285 (testing)  80.078125\n",
      "epoch : 892| loss : (train) 0.00182901 (testing) 0.00456238 | accuracy : (train) 96.8841285 (testing)  82.421875\n",
      "epoch : 893| loss : (train) 0.00187781 (testing) 0.00457330 | accuracy : (train) 96.5920155 (testing)  82.421875\n",
      "epoch : 894| loss : (train) 0.00206176 (testing) 0.00505602 | accuracy : (train) 96.7867575 (testing)  80.078125\n",
      "epoch : 895| loss : (train) 0.00192056 (testing) 0.00445003 | accuracy : (train) 96.7867575 (testing)   83.59375\n",
      "epoch : 896| loss : (train) 0.00203249 (testing) 0.00503355 | accuracy : (train) 96.7867575 (testing)    79.6875\n",
      "epoch : 897| loss : (train) 0.00185664 (testing) 0.00448109 | accuracy : (train) 96.8841285 (testing)   83.59375\n",
      "epoch : 898| loss : (train) 0.00168946 (testing) 0.00461238 | accuracy : (train) 96.7867575 (testing)  82.421875\n",
      "epoch : 899| loss : (train) 0.00178265 (testing) 0.00439912 | accuracy : (train) 96.8841285 (testing)  83.984375\n",
      "epoch : 900| loss : (train) 0.00190750 (testing) 0.00449107 | accuracy : (train) 96.9814995 (testing)   83.59375\n",
      "epoch : 901| loss : (train) 0.00198936 (testing) 0.00492955 | accuracy : (train) 96.7867575 (testing)   80.46875\n",
      "epoch : 902| loss : (train) 0.00188877 (testing) 0.00485785 | accuracy : (train) 96.5920155 (testing)  80.859375\n",
      "epoch : 903| loss : (train) 0.00169322 (testing) 0.00450739 | accuracy : (train) 96.6893865 (testing)    82.8125\n",
      "epoch : 904| loss : (train) 0.00190573 (testing) 0.00529980 | accuracy : (train) 96.8841285 (testing)   80.46875\n",
      "epoch : 905| loss : (train) 0.00185845 (testing) 0.00472932 | accuracy : (train) 97.0788704 (testing)  80.859375\n",
      "epoch : 906| loss : (train) 0.00176056 (testing) 0.00437238 | accuracy : (train) 96.9814995 (testing)  83.984375\n",
      "epoch : 907| loss : (train) 0.00188808 (testing) 0.00519309 | accuracy : (train) 96.8841285 (testing)  80.078125\n",
      "epoch : 908| loss : (train) 0.00172429 (testing) 0.00477701 | accuracy : (train) 97.2736124 (testing)   80.46875\n",
      "epoch : 909| loss : (train) 0.00172958 (testing) 0.00451067 | accuracy : (train) 97.1762414 (testing)   83.59375\n",
      "epoch : 910| loss : (train) 0.00184534 (testing) 0.00487990 | accuracy : (train) 96.9814995 (testing)  80.859375\n",
      "epoch : 911| loss : (train) 0.00164266 (testing) 0.00441881 | accuracy : (train) 97.1762414 (testing)   83.59375\n",
      "epoch : 912| loss : (train) 0.00178213 (testing) 0.00488900 | accuracy : (train) 96.8841285 (testing)  80.859375\n",
      "epoch : 913| loss : (train) 0.00218753 (testing) 0.00494329 | accuracy : (train) 97.0788704 (testing)   80.46875\n",
      "epoch : 914| loss : (train) 0.00195735 (testing) 0.00508552 | accuracy : (train) 97.0788704 (testing)  80.078125\n",
      "epoch : 915| loss : (train) 0.00174837 (testing) 0.00473945 | accuracy : (train) 96.9814995 (testing)      81.25\n",
      "epoch : 916| loss : (train) 0.00199367 (testing) 0.00481644 | accuracy : (train) 97.1762414 (testing)   80.46875\n",
      "epoch : 917| loss : (train) 0.00182113 (testing) 0.00470844 | accuracy : (train) 97.1762414 (testing)      81.25\n",
      "epoch : 918| loss : (train) 0.00173868 (testing) 0.00484171 | accuracy : (train) 97.1762414 (testing)   80.46875\n",
      "epoch : 919| loss : (train) 0.00214493 (testing) 0.00526415 | accuracy : (train) 97.0788704 (testing)  80.078125\n",
      "epoch : 920| loss : (train) 0.00180987 (testing) 0.00474021 | accuracy : (train) 96.9814995 (testing)      81.25\n",
      "epoch : 921| loss : (train) 0.00185788 (testing) 0.00516582 | accuracy : (train) 97.1762414 (testing)    79.6875\n",
      "epoch : 922| loss : (train) 0.00169633 (testing) 0.00475561 | accuracy : (train) 97.0788704 (testing)      81.25\n",
      "epoch : 923| loss : (train) 0.00184874 (testing) 0.00508034 | accuracy : (train) 96.9814995 (testing)  80.078125\n",
      "epoch : 924| loss : (train) 0.00176624 (testing) 0.00516487 | accuracy : (train) 97.1762414 (testing)    79.6875\n",
      "epoch : 925| loss : (train) 0.00185005 (testing) 0.00480449 | accuracy : (train) 97.3709834 (testing)   80.46875\n",
      "epoch : 926| loss : (train) 0.00196536 (testing) 0.00459161 | accuracy : (train) 97.1762414 (testing)    82.8125\n",
      "epoch : 927| loss : (train) 0.00177995 (testing) 0.00462057 | accuracy : (train) 97.0788704 (testing)  82.421875\n",
      "epoch : 928| loss : (train) 0.00172774 (testing) 0.00467978 | accuracy : (train) 97.2736124 (testing)  82.421875\n",
      "epoch : 929| loss : (train) 0.00169710 (testing) 0.00446242 | accuracy : (train) 97.1762414 (testing)   83.59375\n",
      "epoch : 930| loss : (train) 0.00208914 (testing) 0.00540941 | accuracy : (train) 97.2736124 (testing)  80.078125\n",
      "epoch : 931| loss : (train) 0.00169317 (testing) 0.00511088 | accuracy : (train) 97.0788704 (testing)  80.078125\n",
      "epoch : 932| loss : (train) 0.00166588 (testing) 0.00480994 | accuracy : (train) 97.0788704 (testing)  80.859375\n",
      "epoch : 933| loss : (train) 0.00182397 (testing) 0.00500018 | accuracy : (train) 97.2736124 (testing)   80.46875\n",
      "epoch : 934| loss : (train) 0.00170964 (testing) 0.00487090 | accuracy : (train) 97.2736124 (testing)   80.46875\n",
      "epoch : 935| loss : (train) 0.00199467 (testing) 0.00454498 | accuracy : (train) 97.2736124 (testing)    82.8125\n",
      "epoch : 936| loss : (train) 0.00172646 (testing) 0.00447216 | accuracy : (train) 97.3709834 (testing)  83.203125\n",
      "epoch : 937| loss : (train) 0.00173055 (testing) 0.00474017 | accuracy : (train) 97.1762414 (testing)   82.03125\n",
      "epoch : 938| loss : (train) 0.00186797 (testing) 0.00481616 | accuracy : (train) 97.2736124 (testing)  80.859375\n",
      "epoch : 939| loss : (train) 0.00179732 (testing) 0.00485136 | accuracy : (train) 97.2736124 (testing)   80.46875\n",
      "epoch : 940| loss : (train) 0.00166078 (testing) 0.00462155 | accuracy : (train) 97.3709834 (testing)    82.8125\n",
      "epoch : 941| loss : (train) 0.00172165 (testing) 0.00474750 | accuracy : (train) 97.2736124 (testing)   82.03125\n",
      "epoch : 942| loss : (train) 0.00165340 (testing) 0.00494754 | accuracy : (train) 97.6630963 (testing)   80.46875\n",
      "epoch : 943| loss : (train) 0.00171510 (testing) 0.00467757 | accuracy : (train) 97.4683544 (testing)   82.03125\n",
      "epoch : 944| loss : (train) 0.00160004 (testing) 0.00508193 | accuracy : (train) 97.2736124 (testing)   80.46875\n",
      "epoch : 945| loss : (train) 0.00171053 (testing) 0.00478434 | accuracy : (train) 97.2736124 (testing)   82.03125\n",
      "epoch : 946| loss : (train) 0.00162940 (testing) 0.00506051 | accuracy : (train) 97.3709834 (testing)   80.46875\n",
      "epoch : 947| loss : (train) 0.00165551 (testing) 0.00503713 | accuracy : (train) 97.0788704 (testing)   80.46875\n",
      "epoch : 948| loss : (train) 0.00167327 (testing) 0.00505000 | accuracy : (train) 97.4683544 (testing)   80.46875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 949| loss : (train) 0.00162391 (testing) 0.00488314 | accuracy : (train) 97.4683544 (testing)   80.46875\n",
      "epoch : 950| loss : (train) 0.00169631 (testing) 0.00480714 | accuracy : (train) 97.1762414 (testing)  81.640625\n",
      "epoch : 951| loss : (train) 0.00190370 (testing) 0.00510241 | accuracy : (train) 97.4683544 (testing)   80.46875\n",
      "epoch : 952| loss : (train) 0.00170997 (testing) 0.00465865 | accuracy : (train) 97.3709834 (testing)   82.03125\n",
      "epoch : 953| loss : (train) 0.00187097 (testing) 0.00488437 | accuracy : (train) 97.5657254 (testing)  80.859375\n",
      "epoch : 954| loss : (train) 0.00167769 (testing) 0.00455894 | accuracy : (train) 97.5657254 (testing)   83.59375\n",
      "epoch : 955| loss : (train) 0.00188885 (testing) 0.00455278 | accuracy : (train) 97.2736124 (testing)  83.203125\n",
      "epoch : 956| loss : (train) 0.00170428 (testing) 0.00516366 | accuracy : (train) 97.1762414 (testing)  80.078125\n",
      "epoch : 957| loss : (train) 0.00168894 (testing) 0.00450873 | accuracy : (train) 97.6630963 (testing)   83.59375\n",
      "epoch : 958| loss : (train) 0.00172312 (testing) 0.00508737 | accuracy : (train) 97.2736124 (testing)   80.46875\n",
      "epoch : 959| loss : (train) 0.00160247 (testing) 0.00488340 | accuracy : (train) 97.6630963 (testing)  80.859375\n",
      "epoch : 960| loss : (train) 0.00168232 (testing) 0.00458472 | accuracy : (train) 97.4683544 (testing)   83.59375\n",
      "epoch : 961| loss : (train) 0.00186060 (testing) 0.00469081 | accuracy : (train) 97.3709834 (testing)   82.03125\n",
      "epoch : 962| loss : (train) 0.00176052 (testing) 0.00547525 | accuracy : (train) 97.3709834 (testing)  80.078125\n",
      "epoch : 963| loss : (train) 0.00171782 (testing) 0.00531047 | accuracy : (train) 97.5657254 (testing)    79.6875\n",
      "epoch : 964| loss : (train) 0.00167541 (testing) 0.00487819 | accuracy : (train) 97.5657254 (testing)      81.25\n",
      "epoch : 965| loss : (train) 0.00159986 (testing) 0.00502612 | accuracy : (train) 97.5657254 (testing)   80.46875\n",
      "epoch : 966| loss : (train) 0.00170819 (testing) 0.00455402 | accuracy : (train) 97.6630963 (testing)  83.203125\n",
      "epoch : 967| loss : (train) 0.00150992 (testing) 0.00497534 | accuracy : (train) 97.2736124 (testing)   80.46875\n",
      "epoch : 968| loss : (train) 0.00158363 (testing) 0.00482650 | accuracy : (train) 97.4683544 (testing)  81.640625\n",
      "epoch : 969| loss : (train) 0.00155042 (testing) 0.00478592 | accuracy : (train) 97.6630963 (testing)   82.03125\n",
      "epoch : 970| loss : (train) 0.00160367 (testing) 0.00523480 | accuracy : (train) 97.4683544 (testing)  80.078125\n",
      "epoch : 971| loss : (train) 0.00171823 (testing) 0.00468221 | accuracy : (train) 97.5657254 (testing)  82.421875\n",
      "epoch : 972| loss : (train) 0.00146881 (testing) 0.00467747 | accuracy : (train) 97.6630963 (testing)  82.421875\n",
      "epoch : 973| loss : (train) 0.00150018 (testing) 0.00483904 | accuracy : (train) 97.2736124 (testing)  81.640625\n",
      "epoch : 974| loss : (train) 0.00182877 (testing) 0.00460013 | accuracy : (train) 97.3709834 (testing)  83.203125\n",
      "epoch : 975| loss : (train) 0.00160725 (testing) 0.00487305 | accuracy : (train) 97.6630963 (testing)      81.25\n",
      "epoch : 976| loss : (train) 0.00155670 (testing) 0.00481210 | accuracy : (train) 97.6630963 (testing)   82.03125\n",
      "epoch : 977| loss : (train) 0.00165594 (testing) 0.00542039 | accuracy : (train) 97.6630963 (testing)    79.6875\n",
      "epoch : 978| loss : (train) 0.00146990 (testing) 0.00504819 | accuracy : (train) 97.6630963 (testing)   80.46875\n",
      "epoch : 979| loss : (train) 0.00156592 (testing) 0.00483689 | accuracy : (train) 97.6630963 (testing)  81.640625\n",
      "epoch : 980| loss : (train) 0.00172531 (testing) 0.00505306 | accuracy : (train) 97.5657254 (testing)   80.46875\n",
      "epoch : 981| loss : (train) 0.00175273 (testing) 0.00470277 | accuracy : (train) 97.6630963 (testing)    82.8125\n",
      "epoch : 982| loss : (train) 0.00189053 (testing) 0.00524254 | accuracy : (train) 97.6630963 (testing)    79.6875\n",
      "epoch : 983| loss : (train) 0.00148221 (testing) 0.00544314 | accuracy : (train) 97.8578383 (testing)    79.6875\n",
      "epoch : 984| loss : (train) 0.00169303 (testing) 0.00510784 | accuracy : (train) 97.7604673 (testing)   80.46875\n",
      "epoch : 985| loss : (train) 0.00162117 (testing) 0.00500934 | accuracy : (train) 97.8578383 (testing)   80.46875\n",
      "epoch : 986| loss : (train) 0.00172376 (testing) 0.00489444 | accuracy : (train) 97.8578383 (testing)      81.25\n",
      "epoch : 987| loss : (train) 0.00146955 (testing) 0.00493743 | accuracy : (train) 97.5657254 (testing)  80.859375\n",
      "epoch : 988| loss : (train) 0.00160320 (testing) 0.00472976 | accuracy : (train) 97.7604673 (testing)   82.03125\n",
      "epoch : 989| loss : (train) 0.00173496 (testing) 0.00508087 | accuracy : (train) 97.6630963 (testing)   80.46875\n",
      "epoch : 990| loss : (train) 0.00176512 (testing) 0.00531830 | accuracy : (train) 97.6630963 (testing)  80.078125\n",
      "epoch : 991| loss : (train) 0.00175458 (testing) 0.00520693 | accuracy : (train) 97.8578383 (testing)   80.46875\n",
      "epoch : 992| loss : (train) 0.00164300 (testing) 0.00492689 | accuracy : (train) 97.8578383 (testing)      81.25\n",
      "epoch : 993| loss : (train) 0.00152356 (testing) 0.00528306 | accuracy : (train) 97.7604673 (testing)  80.078125\n",
      "epoch : 994| loss : (train) 0.00136571 (testing) 0.00508376 | accuracy : (train) 97.9552093 (testing)   80.46875\n",
      "epoch : 995| loss : (train) 0.00149959 (testing) 0.00506558 | accuracy : (train) 97.7604673 (testing)   80.46875\n",
      "epoch : 996| loss : (train) 0.00158591 (testing) 0.00535756 | accuracy : (train) 97.8578383 (testing)  80.078125\n",
      "epoch : 997| loss : (train) 0.00151293 (testing) 0.00517142 | accuracy : (train) 97.6630963 (testing)   80.46875\n",
      "epoch : 998| loss : (train) 0.00154377 (testing) 0.00520750 | accuracy : (train) 97.6630963 (testing)   80.46875\n",
      "epoch : 999| loss : (train) 0.00163258 (testing) 0.00501031 | accuracy : (train) 97.7604673 (testing)  80.859375\n",
      "epoch : 1000| loss : (train) 0.00138711 (testing) 0.00504107 | accuracy : (train) 97.6630963 (testing)   80.46875\n",
      "epoch : 1001| loss : (train) 0.00163394 (testing) 0.00533960 | accuracy : (train) 97.7604673 (testing)    79.6875\n",
      "epoch : 1002| loss : (train) 0.00178745 (testing) 0.00584675 | accuracy : (train) 97.9552093 (testing)   80.46875\n",
      "epoch : 1003| loss : (train) 0.00165361 (testing) 0.00550474 | accuracy : (train) 98.0525803 (testing)    79.6875\n",
      "epoch : 1004| loss : (train) 0.00162981 (testing) 0.00502600 | accuracy : (train) 98.1499513 (testing)  80.859375\n",
      "epoch : 1005| loss : (train) 0.00150541 (testing) 0.00463944 | accuracy : (train) 97.9552093 (testing)  83.203125\n",
      "epoch : 1006| loss : (train) 0.00155899 (testing) 0.00460826 | accuracy : (train) 97.7604673 (testing)  83.984375\n",
      "epoch : 1007| loss : (train) 0.00159321 (testing) 0.00482781 | accuracy : (train) 97.8578383 (testing)  81.640625\n",
      "epoch : 1008| loss : (train) 0.00147968 (testing) 0.00499711 | accuracy : (train) 97.9552093 (testing)  80.859375\n",
      "epoch : 1009| loss : (train) 0.00140008 (testing) 0.00512240 | accuracy : (train) 98.1499513 (testing)  80.078125\n",
      "epoch : 1010| loss : (train) 0.00167776 (testing) 0.00501885 | accuracy : (train) 98.1499513 (testing)  80.859375\n",
      "epoch : 1011| loss : (train) 0.00171192 (testing) 0.00488179 | accuracy : (train) 97.9552093 (testing)  81.640625\n",
      "epoch : 1012| loss : (train) 0.00149291 (testing) 0.00483250 | accuracy : (train) 97.7604673 (testing)   82.03125\n",
      "epoch : 1013| loss : (train) 0.00157188 (testing) 0.00522977 | accuracy : (train) 98.1499513 (testing)   80.46875\n",
      "epoch : 1014| loss : (train) 0.00150206 (testing) 0.00511797 | accuracy : (train) 97.8578383 (testing)  80.078125\n",
      "epoch : 1015| loss : (train) 0.00165437 (testing) 0.00465444 | accuracy : (train) 97.8578383 (testing)   83.59375\n",
      "epoch : 1016| loss : (train) 0.00152728 (testing) 0.00517491 | accuracy : (train) 97.9552093 (testing)  80.078125\n",
      "epoch : 1017| loss : (train) 0.00160896 (testing) 0.00502263 | accuracy : (train) 98.0525803 (testing)  80.859375\n",
      "epoch : 1018| loss : (train) 0.00189289 (testing) 0.00548861 | accuracy : (train) 98.0525803 (testing)    79.6875\n",
      "epoch : 1019| loss : (train) 0.00178146 (testing) 0.00553642 | accuracy : (train) 97.9552093 (testing)    79.6875\n",
      "epoch : 1020| loss : (train) 0.00173131 (testing) 0.00520125 | accuracy : (train) 98.3446932 (testing)  80.078125\n",
      "epoch : 1021| loss : (train) 0.00159987 (testing) 0.00521829 | accuracy : (train) 98.1499513 (testing)  80.078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1022| loss : (train) 0.00143075 (testing) 0.00493033 | accuracy : (train) 97.9552093 (testing)      81.25\n",
      "epoch : 1023| loss : (train) 0.00163367 (testing) 0.00518278 | accuracy : (train) 98.0525803 (testing)  80.078125\n",
      "epoch : 1024| loss : (train) 0.00149950 (testing) 0.00547820 | accuracy : (train) 98.2473222 (testing)  79.296875\n",
      "epoch : 1025| loss : (train) 0.00148121 (testing) 0.00531931 | accuracy : (train) 97.9552093 (testing)   80.46875\n",
      "epoch : 1026| loss : (train) 0.00150014 (testing) 0.00475471 | accuracy : (train) 98.2473222 (testing)    82.8125\n",
      "epoch : 1027| loss : (train) 0.00152849 (testing) 0.00550357 | accuracy : (train) 98.1499513 (testing)  79.296875\n",
      "epoch : 1028| loss : (train) 0.00141460 (testing) 0.00485428 | accuracy : (train) 98.0525803 (testing)   82.03125\n",
      "epoch : 1029| loss : (train) 0.00140443 (testing) 0.00510244 | accuracy : (train) 98.2473222 (testing)  80.859375\n",
      "epoch : 1030| loss : (train) 0.00160684 (testing) 0.00556107 | accuracy : (train) 98.0525803 (testing)    79.6875\n",
      "epoch : 1031| loss : (train) 0.00182541 (testing) 0.00566635 | accuracy : (train) 98.1499513 (testing)    79.6875\n",
      "epoch : 1032| loss : (train) 0.00140910 (testing) 0.00549885 | accuracy : (train) 97.9552093 (testing)  79.296875\n",
      "epoch : 1033| loss : (train) 0.00139811 (testing) 0.00510378 | accuracy : (train) 98.1499513 (testing)  80.859375\n",
      "epoch : 1034| loss : (train) 0.00139074 (testing) 0.00524484 | accuracy : (train) 98.0525803 (testing)  80.078125\n",
      "epoch : 1035| loss : (train) 0.00128959 (testing) 0.00475841 | accuracy : (train) 98.2473222 (testing)    82.8125\n",
      "epoch : 1036| loss : (train) 0.00142426 (testing) 0.00504208 | accuracy : (train) 98.5394352 (testing)      81.25\n",
      "epoch : 1037| loss : (train) 0.00152563 (testing) 0.00526949 | accuracy : (train) 98.0525803 (testing)  80.078125\n",
      "epoch : 1038| loss : (train) 0.00147819 (testing) 0.00509819 | accuracy : (train) 98.1499513 (testing)  80.859375\n",
      "epoch : 1039| loss : (train) 0.00142337 (testing) 0.00503622 | accuracy : (train) 98.3446932 (testing)  80.859375\n",
      "epoch : 1040| loss : (train) 0.00165076 (testing) 0.00565496 | accuracy : (train) 98.3446932 (testing)    79.6875\n",
      "epoch : 1041| loss : (train) 0.00150060 (testing) 0.00525993 | accuracy : (train) 98.3446932 (testing)  80.078125\n",
      "epoch : 1042| loss : (train) 0.00142588 (testing) 0.00576517 | accuracy : (train) 98.3446932 (testing)  80.078125\n",
      "epoch : 1043| loss : (train) 0.00167125 (testing) 0.00579163 | accuracy : (train) 98.4420642 (testing)  80.078125\n",
      "epoch : 1044| loss : (train) 0.00163863 (testing) 0.00582358 | accuracy : (train) 98.2473222 (testing)  80.078125\n",
      "epoch : 1045| loss : (train) 0.00157468 (testing) 0.00514469 | accuracy : (train) 98.4420642 (testing)  80.859375\n",
      "epoch : 1046| loss : (train) 0.00131172 (testing) 0.00526342 | accuracy : (train) 98.2473222 (testing)  80.078125\n",
      "epoch : 1047| loss : (train) 0.00131809 (testing) 0.00511859 | accuracy : (train) 98.4420642 (testing)  80.859375\n",
      "epoch : 1048| loss : (train) 0.00149346 (testing) 0.00546418 | accuracy : (train) 98.4420642 (testing)   80.46875\n",
      "epoch : 1049| loss : (train) 0.00134298 (testing) 0.00532154 | accuracy : (train) 98.3446932 (testing)  80.078125\n",
      "epoch : 1050| loss : (train) 0.00145761 (testing) 0.00496496 | accuracy : (train) 98.1499513 (testing)  81.640625\n",
      "epoch : 1051| loss : (train) 0.00131811 (testing) 0.00517641 | accuracy : (train) 98.3446932 (testing)   80.46875\n",
      "epoch : 1052| loss : (train) 0.00138702 (testing) 0.00489342 | accuracy : (train) 98.4420642 (testing)  82.421875\n",
      "epoch : 1053| loss : (train) 0.00142018 (testing) 0.00514945 | accuracy : (train) 98.3446932 (testing)  80.859375\n",
      "epoch : 1054| loss : (train) 0.00146756 (testing) 0.00520080 | accuracy : (train) 98.4420642 (testing)   80.46875\n",
      "epoch : 1055| loss : (train) 0.00158488 (testing) 0.00494334 | accuracy : (train) 98.3446932 (testing)   82.03125\n",
      "epoch : 1056| loss : (train) 0.00128389 (testing) 0.00512003 | accuracy : (train) 98.3446932 (testing)      81.25\n",
      "epoch : 1057| loss : (train) 0.00138910 (testing) 0.00533917 | accuracy : (train) 98.3446932 (testing)  80.078125\n",
      "epoch : 1058| loss : (train) 0.00160631 (testing) 0.00566556 | accuracy : (train) 98.4420642 (testing)  79.296875\n",
      "epoch : 1059| loss : (train) 0.00140767 (testing) 0.00555904 | accuracy : (train) 98.4420642 (testing)  80.078125\n",
      "epoch : 1060| loss : (train) 0.00125185 (testing) 0.00538129 | accuracy : (train) 98.2473222 (testing)  80.078125\n",
      "epoch : 1061| loss : (train) 0.00144060 (testing) 0.00559151 | accuracy : (train) 98.3446932 (testing)  79.296875\n",
      "epoch : 1062| loss : (train) 0.00146500 (testing) 0.00575886 | accuracy : (train) 98.4420642 (testing)  80.078125\n",
      "epoch : 1063| loss : (train) 0.00137464 (testing) 0.00520615 | accuracy : (train) 98.4420642 (testing)  80.859375\n",
      "epoch : 1064| loss : (train) 0.00132055 (testing) 0.00500112 | accuracy : (train) 98.6368062 (testing)  81.640625\n",
      "epoch : 1065| loss : (train) 0.00134743 (testing) 0.00507029 | accuracy : (train) 98.4420642 (testing)      81.25\n",
      "epoch : 1066| loss : (train) 0.00128292 (testing) 0.00525313 | accuracy : (train) 98.5394352 (testing)   80.46875\n",
      "epoch : 1067| loss : (train) 0.00134876 (testing) 0.00524941 | accuracy : (train) 98.3446932 (testing)   80.46875\n",
      "epoch : 1068| loss : (train) 0.00140119 (testing) 0.00510354 | accuracy : (train) 98.5394352 (testing)  80.859375\n",
      "epoch : 1069| loss : (train) 0.00126539 (testing) 0.00508398 | accuracy : (train) 98.3446932 (testing)      81.25\n",
      "epoch : 1070| loss : (train) 0.00163646 (testing) 0.00538893 | accuracy : (train) 98.4420642 (testing)  80.078125\n",
      "epoch : 1071| loss : (train) 0.00136449 (testing) 0.00543580 | accuracy : (train) 98.4420642 (testing)  80.078125\n",
      "epoch : 1072| loss : (train) 0.00130784 (testing) 0.00536983 | accuracy : (train) 98.4420642 (testing)  80.078125\n",
      "epoch : 1073| loss : (train) 0.00125238 (testing) 0.00507005 | accuracy : (train) 98.3446932 (testing)      81.25\n",
      "epoch : 1074| loss : (train) 0.00138730 (testing) 0.00576505 | accuracy : (train) 98.4420642 (testing)  79.296875\n",
      "epoch : 1075| loss : (train) 0.00148518 (testing) 0.00541337 | accuracy : (train) 98.7341772 (testing)  80.078125\n",
      "epoch : 1076| loss : (train) 0.00149185 (testing) 0.00527631 | accuracy : (train) 98.5394352 (testing)   80.46875\n",
      "epoch : 1077| loss : (train) 0.00125951 (testing) 0.00517141 | accuracy : (train) 98.6368062 (testing)   80.46875\n",
      "epoch : 1078| loss : (train) 0.00132874 (testing) 0.00539177 | accuracy : (train) 98.4420642 (testing)  80.078125\n",
      "epoch : 1079| loss : (train) 0.00142581 (testing) 0.00504974 | accuracy : (train) 98.6368062 (testing)      81.25\n",
      "epoch : 1080| loss : (train) 0.00153681 (testing) 0.00586786 | accuracy : (train) 98.4420642 (testing)  80.078125\n",
      "epoch : 1081| loss : (train) 0.00130704 (testing) 0.00499010 | accuracy : (train) 98.5394352 (testing)   82.03125\n",
      "epoch : 1082| loss : (train) 0.00151729 (testing) 0.00568046 | accuracy : (train) 98.6368062 (testing)   78.90625\n",
      "epoch : 1083| loss : (train) 0.00138114 (testing) 0.00502997 | accuracy : (train) 98.7341772 (testing)   82.03125\n",
      "epoch : 1084| loss : (train) 0.00144186 (testing) 0.00570460 | accuracy : (train) 98.6368062 (testing)   78.90625\n",
      "epoch : 1085| loss : (train) 0.00138149 (testing) 0.00510750 | accuracy : (train) 98.6368062 (testing)      81.25\n",
      "epoch : 1086| loss : (train) 0.00149767 (testing) 0.00553613 | accuracy : (train) 98.6368062 (testing)  80.078125\n",
      "epoch : 1087| loss : (train) 0.00129902 (testing) 0.00584191 | accuracy : (train) 98.6368062 (testing)    79.6875\n",
      "epoch : 1088| loss : (train) 0.00134223 (testing) 0.00514818 | accuracy : (train) 98.8315481 (testing)  80.859375\n",
      "epoch : 1089| loss : (train) 0.00127697 (testing) 0.00572228 | accuracy : (train) 98.4420642 (testing)   78.90625\n",
      "epoch : 1090| loss : (train) 0.00130727 (testing) 0.00527609 | accuracy : (train) 98.6368062 (testing)  80.859375\n",
      "epoch : 1091| loss : (train) 0.00123519 (testing) 0.00556083 | accuracy : (train) 98.6368062 (testing)  80.078125\n",
      "epoch : 1092| loss : (train) 0.00128910 (testing) 0.00563819 | accuracy : (train) 98.6368062 (testing)  80.078125\n",
      "epoch : 1093| loss : (train) 0.00126708 (testing) 0.00535489 | accuracy : (train) 98.6368062 (testing)   80.46875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1094| loss : (train) 0.00126270 (testing) 0.00522189 | accuracy : (train) 98.5394352 (testing)  80.859375\n",
      "epoch : 1095| loss : (train) 0.00145769 (testing) 0.00535440 | accuracy : (train) 98.6368062 (testing)   80.46875\n",
      "epoch : 1096| loss : (train) 0.00137604 (testing) 0.00532864 | accuracy : (train) 98.5394352 (testing)   80.46875\n",
      "epoch : 1097| loss : (train) 0.00133269 (testing) 0.00517109 | accuracy : (train) 98.6368062 (testing)  80.859375\n",
      "epoch : 1098| loss : (train) 0.00141428 (testing) 0.00523444 | accuracy : (train) 98.6368062 (testing)  80.859375\n",
      "epoch : 1099| loss : (train) 0.00135748 (testing) 0.00483181 | accuracy : (train) 98.6368062 (testing)     84.375\n",
      "epoch : 1100| loss : (train) 0.00140787 (testing) 0.00532046 | accuracy : (train) 98.2473222 (testing)  80.859375\n",
      "epoch : 1101| loss : (train) 0.00140867 (testing) 0.00585612 | accuracy : (train) 98.9289191 (testing)  79.296875\n",
      "epoch : 1102| loss : (train) 0.00136936 (testing) 0.00583068 | accuracy : (train) 98.8315481 (testing)  79.296875\n",
      "epoch : 1103| loss : (train) 0.00131130 (testing) 0.00557000 | accuracy : (train) 98.7341772 (testing)  80.078125\n",
      "epoch : 1104| loss : (train) 0.00130500 (testing) 0.00579815 | accuracy : (train) 98.7341772 (testing)   78.90625\n",
      "epoch : 1105| loss : (train) 0.00138734 (testing) 0.00520305 | accuracy : (train) 98.5394352 (testing)  80.859375\n",
      "epoch : 1106| loss : (train) 0.00132272 (testing) 0.00503508 | accuracy : (train) 98.9289191 (testing)  82.421875\n",
      "epoch : 1107| loss : (train) 0.00119647 (testing) 0.00553577 | accuracy : (train) 98.7341772 (testing)  80.078125\n",
      "epoch : 1108| loss : (train) 0.00140451 (testing) 0.00550105 | accuracy : (train) 98.9289191 (testing)   80.46875\n",
      "epoch : 1109| loss : (train) 0.00125065 (testing) 0.00515850 | accuracy : (train) 98.6368062 (testing)      81.25\n",
      "epoch : 1110| loss : (train) 0.00135503 (testing) 0.00547592 | accuracy : (train) 98.6368062 (testing)   80.46875\n",
      "epoch : 1111| loss : (train) 0.00127260 (testing) 0.00553869 | accuracy : (train) 98.5394352 (testing)  80.078125\n",
      "epoch : 1112| loss : (train) 0.00137913 (testing) 0.00589085 | accuracy : (train) 98.8315481 (testing)  79.296875\n",
      "epoch : 1113| loss : (train) 0.00121108 (testing) 0.00521229 | accuracy : (train) 98.8315481 (testing)      81.25\n",
      "epoch : 1114| loss : (train) 0.00126480 (testing) 0.00527051 | accuracy : (train) 98.7341772 (testing)  80.859375\n",
      "epoch : 1115| loss : (train) 0.00118765 (testing) 0.00527629 | accuracy : (train) 98.9289191 (testing)  80.859375\n",
      "epoch : 1116| loss : (train) 0.00128732 (testing) 0.00552225 | accuracy : (train) 98.7341772 (testing)   80.46875\n",
      "epoch : 1117| loss : (train) 0.00133148 (testing) 0.00516628 | accuracy : (train) 98.7341772 (testing)      81.25\n",
      "epoch : 1118| loss : (train) 0.00122745 (testing) 0.00528520 | accuracy : (train) 98.8315481 (testing)  80.859375\n",
      "epoch : 1119| loss : (train) 0.00136027 (testing) 0.00575288 | accuracy : (train) 98.7341772 (testing)  80.078125\n",
      "epoch : 1120| loss : (train) 0.00127678 (testing) 0.00545193 | accuracy : (train) 98.8315481 (testing)   80.46875\n",
      "epoch : 1121| loss : (train) 0.00118568 (testing) 0.00528386 | accuracy : (train) 98.9289191 (testing)  80.859375\n",
      "epoch : 1122| loss : (train) 0.00139683 (testing) 0.00561219 | accuracy : (train) 98.9289191 (testing)  80.078125\n",
      "epoch : 1123| loss : (train) 0.00113154 (testing) 0.00559129 | accuracy : (train) 98.9289191 (testing)  80.078125\n",
      "epoch : 1124| loss : (train) 0.00114168 (testing) 0.00555320 | accuracy : (train) 98.7341772 (testing)   80.46875\n",
      "epoch : 1125| loss : (train) 0.00124638 (testing) 0.00534538 | accuracy : (train) 98.7341772 (testing)   80.46875\n",
      "epoch : 1126| loss : (train) 0.00119531 (testing) 0.00534734 | accuracy : (train) 98.9289191 (testing)   80.46875\n",
      "epoch : 1127| loss : (train) 0.00122231 (testing) 0.00508320 | accuracy : (train) 98.9289191 (testing)  82.421875\n",
      "epoch : 1128| loss : (train) 0.00118268 (testing) 0.00546336 | accuracy : (train) 98.7341772 (testing)   80.46875\n",
      "epoch : 1129| loss : (train) 0.00119095 (testing) 0.00576524 | accuracy : (train) 99.0262901 (testing)  80.078125\n",
      "epoch : 1130| loss : (train) 0.00131544 (testing) 0.00646117 | accuracy : (train) 98.9289191 (testing)  79.296875\n",
      "epoch : 1131| loss : (train) 0.00117767 (testing) 0.00581156 | accuracy : (train) 98.8315481 (testing)  80.078125\n",
      "epoch : 1132| loss : (train) 0.00139708 (testing) 0.00554873 | accuracy : (train) 99.0262901 (testing)   80.46875\n",
      "epoch : 1133| loss : (train) 0.00133375 (testing) 0.00579008 | accuracy : (train) 98.7341772 (testing)  80.078125\n",
      "epoch : 1134| loss : (train) 0.00115181 (testing) 0.00550236 | accuracy : (train) 99.0262901 (testing)   80.46875\n",
      "epoch : 1135| loss : (train) 0.00119791 (testing) 0.00548703 | accuracy : (train) 98.5394352 (testing)   80.46875\n",
      "epoch : 1136| loss : (train) 0.00127834 (testing) 0.00589025 | accuracy : (train) 98.7341772 (testing)    79.6875\n",
      "epoch : 1137| loss : (train) 0.00116836 (testing) 0.00559817 | accuracy : (train) 98.9289191 (testing)   80.46875\n",
      "epoch : 1138| loss : (train) 0.00116793 (testing) 0.00550317 | accuracy : (train) 99.1236611 (testing)   80.46875\n",
      "epoch : 1139| loss : (train) 0.00121461 (testing) 0.00528616 | accuracy : (train) 98.7341772 (testing)      81.25\n",
      "epoch : 1140| loss : (train) 0.00121675 (testing) 0.00555065 | accuracy : (train) 98.8315481 (testing)   80.46875\n",
      "epoch : 1141| loss : (train) 0.00121385 (testing) 0.00536533 | accuracy : (train) 98.9289191 (testing)   80.46875\n",
      "epoch : 1142| loss : (train) 0.00138764 (testing) 0.00613451 | accuracy : (train) 98.6368062 (testing)   78.90625\n",
      "epoch : 1143| loss : (train) 0.00119337 (testing) 0.00529118 | accuracy : (train) 98.7341772 (testing)      81.25\n",
      "epoch : 1144| loss : (train) 0.00106343 (testing) 0.00568247 | accuracy : (train) 98.7341772 (testing)  80.078125\n",
      "epoch : 1145| loss : (train) 0.00136638 (testing) 0.00556950 | accuracy : (train) 99.0262901 (testing)   80.46875\n",
      "epoch : 1146| loss : (train) 0.00116203 (testing) 0.00565202 | accuracy : (train) 98.9289191 (testing)   80.46875\n",
      "epoch : 1147| loss : (train) 0.00126950 (testing) 0.00576652 | accuracy : (train) 99.0262901 (testing)  80.078125\n",
      "epoch : 1148| loss : (train) 0.00116834 (testing) 0.00548660 | accuracy : (train) 99.0262901 (testing)  80.078125\n",
      "epoch : 1149| loss : (train) 0.00111660 (testing) 0.00574814 | accuracy : (train) 99.1236611 (testing)  80.078125\n",
      "epoch : 1150| loss : (train) 0.00119311 (testing) 0.00533579 | accuracy : (train) 99.1236611 (testing)      81.25\n",
      "epoch : 1151| loss : (train) 0.00120755 (testing) 0.00568272 | accuracy : (train) 99.2210321 (testing)   80.46875\n",
      "epoch : 1152| loss : (train) 0.00123837 (testing) 0.00616681 | accuracy : (train) 98.9289191 (testing)   78.90625\n",
      "epoch : 1153| loss : (train) 0.00109755 (testing) 0.00598339 | accuracy : (train) 98.9289191 (testing)    79.6875\n",
      "epoch : 1154| loss : (train) 0.00128333 (testing) 0.00550593 | accuracy : (train) 99.3184031 (testing)  80.078125\n",
      "epoch : 1155| loss : (train) 0.00144345 (testing) 0.00587978 | accuracy : (train) 99.1236611 (testing)  80.078125\n",
      "epoch : 1156| loss : (train) 0.00129031 (testing) 0.00529959 | accuracy : (train) 99.2210321 (testing)      81.25\n",
      "epoch : 1157| loss : (train) 0.00111634 (testing) 0.00545040 | accuracy : (train) 99.0262901 (testing)   80.46875\n",
      "epoch : 1158| loss : (train) 0.00111250 (testing) 0.00549732 | accuracy : (train) 99.1236611 (testing)   80.46875\n",
      "epoch : 1159| loss : (train) 0.00123167 (testing) 0.00553440 | accuracy : (train) 98.9289191 (testing)  80.078125\n",
      "epoch : 1160| loss : (train) 0.00111491 (testing) 0.00608434 | accuracy : (train) 99.0262901 (testing)  79.296875\n",
      "epoch : 1161| loss : (train) 0.00113663 (testing) 0.00549654 | accuracy : (train) 99.1236611 (testing)   80.46875\n",
      "epoch : 1162| loss : (train) 0.00110638 (testing) 0.00548265 | accuracy : (train) 98.7341772 (testing)   80.46875\n",
      "epoch : 1163| loss : (train) 0.00121417 (testing) 0.00598295 | accuracy : (train) 99.1236611 (testing)  80.078125\n",
      "epoch : 1164| loss : (train) 0.00106169 (testing) 0.00590393 | accuracy : (train) 98.9289191 (testing)  80.078125\n",
      "epoch : 1165| loss : (train) 0.00117614 (testing) 0.00546568 | accuracy : (train) 99.0262901 (testing)   80.46875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1166| loss : (train) 0.00105487 (testing) 0.00551795 | accuracy : (train) 99.1236611 (testing)   80.46875\n",
      "epoch : 1167| loss : (train) 0.00125103 (testing) 0.00623601 | accuracy : (train) 98.9289191 (testing)   78.90625\n",
      "epoch : 1168| loss : (train) 0.00104172 (testing) 0.00557737 | accuracy : (train) 99.3184031 (testing)  80.078125\n",
      "epoch : 1169| loss : (train) 0.00109844 (testing) 0.00569752 | accuracy : (train) 99.3184031 (testing)   80.46875\n",
      "epoch : 1170| loss : (train) 0.00123131 (testing) 0.00583505 | accuracy : (train) 99.1236611 (testing)  80.078125\n",
      "epoch : 1171| loss : (train) 0.00133809 (testing) 0.00540773 | accuracy : (train) 99.2210321 (testing)  80.859375\n",
      "epoch : 1172| loss : (train) 0.00129515 (testing) 0.00602925 | accuracy : (train) 99.1236611 (testing)  80.078125\n",
      "epoch : 1173| loss : (train) 0.00123897 (testing) 0.00564789 | accuracy : (train) 99.3184031 (testing)  80.078125\n",
      "epoch : 1174| loss : (train) 0.00124674 (testing) 0.00516520 | accuracy : (train) 99.3184031 (testing)  82.421875\n",
      "epoch : 1175| loss : (train) 0.00130866 (testing) 0.00604981 | accuracy : (train) 98.9289191 (testing)  80.078125\n",
      "epoch : 1176| loss : (train) 0.00107216 (testing) 0.00531944 | accuracy : (train) 99.2210321 (testing)      81.25\n",
      "epoch : 1177| loss : (train) 0.00112214 (testing) 0.00568530 | accuracy : (train) 99.1236611 (testing)   80.46875\n",
      "epoch : 1178| loss : (train) 0.00128525 (testing) 0.00576205 | accuracy : (train) 99.2210321 (testing)   80.46875\n",
      "epoch : 1179| loss : (train) 0.00101703 (testing) 0.00582330 | accuracy : (train) 99.2210321 (testing)  80.078125\n",
      "epoch : 1180| loss : (train) 0.00109078 (testing) 0.00556115 | accuracy : (train) 99.3184031 (testing)   80.46875\n",
      "epoch : 1181| loss : (train) 0.00107534 (testing) 0.00591884 | accuracy : (train) 98.9289191 (testing)  80.078125\n",
      "epoch : 1182| loss : (train) 0.00105389 (testing) 0.00544373 | accuracy : (train) 99.2210321 (testing)  80.859375\n",
      "epoch : 1183| loss : (train) 0.00118427 (testing) 0.00542008 | accuracy : (train) 99.3184031 (testing)      81.25\n",
      "epoch : 1184| loss : (train) 0.00105106 (testing) 0.00555725 | accuracy : (train) 99.1236611 (testing)   80.46875\n",
      "epoch : 1185| loss : (train) 0.00110306 (testing) 0.00570085 | accuracy : (train) 99.2210321 (testing)  80.078125\n",
      "epoch : 1186| loss : (train) 0.00110556 (testing) 0.00597999 | accuracy : (train) 99.3184031 (testing)   80.46875\n",
      "epoch : 1187| loss : (train) 0.00107951 (testing) 0.00557768 | accuracy : (train) 99.2210321 (testing)   80.46875\n",
      "epoch : 1188| loss : (train) 0.00113962 (testing) 0.00531859 | accuracy : (train) 99.3184031 (testing)  81.640625\n",
      "epoch : 1189| loss : (train) 0.00105950 (testing) 0.00589073 | accuracy : (train) 99.1236611 (testing)  80.078125\n",
      "epoch : 1190| loss : (train) 0.00117486 (testing) 0.00615087 | accuracy : (train) 99.2210321 (testing)  79.296875\n",
      "epoch : 1191| loss : (train) 0.00118879 (testing) 0.00539708 | accuracy : (train) 99.2210321 (testing)      81.25\n",
      "epoch : 1192| loss : (train) 0.00116183 (testing) 0.00604004 | accuracy : (train) 99.1236611 (testing)  80.078125\n",
      "epoch : 1193| loss : (train) 0.00119473 (testing) 0.00711499 | accuracy : (train) 99.2210321 (testing)  79.296875\n",
      "epoch : 1194| loss : (train) 0.00116006 (testing) 0.00531290 | accuracy : (train) 99.1236611 (testing)      81.25\n",
      "epoch : 1195| loss : (train) 0.00124443 (testing) 0.00601106 | accuracy : (train) 99.1236611 (testing)   80.46875\n",
      "epoch : 1196| loss : (train) 0.00096155 (testing) 0.00563343 | accuracy : (train) 99.4157740 (testing)  80.078125\n",
      "epoch : 1197| loss : (train) 0.00107690 (testing) 0.00569505 | accuracy : (train) 99.2210321 (testing)  80.078125\n",
      "epoch : 1198| loss : (train) 0.00116489 (testing) 0.00540866 | accuracy : (train) 99.2210321 (testing)      81.25\n",
      "epoch : 1199| loss : (train) 0.00109856 (testing) 0.00511525 | accuracy : (train) 99.4157740 (testing)  83.984375\n",
      "epoch : 1200| loss : (train) 0.00109863 (testing) 0.00552613 | accuracy : (train) 99.1236611 (testing)   80.46875\n",
      "epoch : 1201| loss : (train) 0.00112560 (testing) 0.00568606 | accuracy : (train) 99.3184031 (testing)  80.078125\n",
      "epoch : 1202| loss : (train) 0.00106196 (testing) 0.00586064 | accuracy : (train) 99.4157740 (testing)   80.46875\n",
      "epoch : 1203| loss : (train) 0.00118965 (testing) 0.00648460 | accuracy : (train) 99.3184031 (testing)   78.90625\n",
      "epoch : 1204| loss : (train) 0.00112665 (testing) 0.00665328 | accuracy : (train) 99.2210321 (testing)  78.515625\n",
      "epoch : 1205| loss : (train) 0.00105536 (testing) 0.00565757 | accuracy : (train) 99.4157740 (testing)  80.078125\n",
      "epoch : 1206| loss : (train) 0.00129546 (testing) 0.00678926 | accuracy : (train) 99.3184031 (testing)  78.515625\n",
      "epoch : 1207| loss : (train) 0.00103850 (testing) 0.00571982 | accuracy : (train) 99.2210321 (testing)  80.078125\n",
      "epoch : 1208| loss : (train) 0.00099924 (testing) 0.00592398 | accuracy : (train) 99.2210321 (testing)   80.46875\n",
      "epoch : 1209| loss : (train) 0.00102117 (testing) 0.00592663 | accuracy : (train) 99.1236611 (testing)   80.46875\n",
      "epoch : 1210| loss : (train) 0.00100349 (testing) 0.00542264 | accuracy : (train) 99.4157740 (testing)      81.25\n",
      "epoch : 1211| loss : (train) 0.00105428 (testing) 0.00613887 | accuracy : (train) 99.2210321 (testing)  80.078125\n",
      "epoch : 1212| loss : (train) 0.00102409 (testing) 0.00600933 | accuracy : (train) 99.2210321 (testing)   80.46875\n",
      "epoch : 1213| loss : (train) 0.00126878 (testing) 0.00638369 | accuracy : (train) 99.4157740 (testing)   78.90625\n",
      "epoch : 1214| loss : (train) 0.00096625 (testing) 0.00557084 | accuracy : (train) 99.3184031 (testing)   80.46875\n",
      "epoch : 1215| loss : (train) 0.00133256 (testing) 0.00597371 | accuracy : (train) 99.2210321 (testing)  80.078125\n",
      "epoch : 1216| loss : (train) 0.00106792 (testing) 0.00638122 | accuracy : (train) 99.4157740 (testing)   78.90625\n",
      "epoch : 1217| loss : (train) 0.00107418 (testing) 0.00612671 | accuracy : (train) 99.3184031 (testing)  80.078125\n",
      "epoch : 1218| loss : (train) 0.00105714 (testing) 0.00543149 | accuracy : (train) 99.4157740 (testing)      81.25\n",
      "epoch : 1219| loss : (train) 0.00126101 (testing) 0.00614881 | accuracy : (train) 99.3184031 (testing)  80.078125\n",
      "epoch : 1220| loss : (train) 0.00111505 (testing) 0.00545003 | accuracy : (train) 99.4157740 (testing)      81.25\n",
      "epoch : 1221| loss : (train) 0.00095716 (testing) 0.00563729 | accuracy : (train) 99.4157740 (testing)   80.46875\n",
      "epoch : 1222| loss : (train) 0.00096869 (testing) 0.00582749 | accuracy : (train) 99.4157740 (testing)  80.078125\n",
      "epoch : 1223| loss : (train) 0.00121666 (testing) 0.00583748 | accuracy : (train) 99.4157740 (testing)  80.078125\n",
      "epoch : 1224| loss : (train) 0.00117060 (testing) 0.00590671 | accuracy : (train) 99.4157740 (testing)  80.078125\n",
      "epoch : 1225| loss : (train) 0.00100851 (testing) 0.00602506 | accuracy : (train) 99.5131450 (testing)   80.46875\n",
      "epoch : 1226| loss : (train) 0.00110512 (testing) 0.00551752 | accuracy : (train) 99.5131450 (testing)      81.25\n",
      "epoch : 1227| loss : (train) 0.00109308 (testing) 0.00592087 | accuracy : (train) 99.2210321 (testing)  80.078125\n",
      "epoch : 1228| loss : (train) 0.00100823 (testing) 0.00618543 | accuracy : (train) 99.5131450 (testing)  80.078125\n",
      "epoch : 1229| loss : (train) 0.00098112 (testing) 0.00578610 | accuracy : (train) 99.3184031 (testing)  80.078125\n",
      "epoch : 1230| loss : (train) 0.00126705 (testing) 0.00670290 | accuracy : (train) 99.5131450 (testing)   78.90625\n",
      "epoch : 1231| loss : (train) 0.00098526 (testing) 0.00568961 | accuracy : (train) 99.3184031 (testing)   80.46875\n",
      "epoch : 1232| loss : (train) 0.00098436 (testing) 0.00553493 | accuracy : (train) 99.3184031 (testing)      81.25\n",
      "epoch : 1233| loss : (train) 0.00115569 (testing) 0.00617818 | accuracy : (train) 99.5131450 (testing)  80.078125\n",
      "epoch : 1234| loss : (train) 0.00097961 (testing) 0.00545422 | accuracy : (train) 99.5131450 (testing)  81.640625\n",
      "epoch : 1235| loss : (train) 0.00101180 (testing) 0.00610996 | accuracy : (train) 99.1236611 (testing)   80.46875\n",
      "epoch : 1236| loss : (train) 0.00101681 (testing) 0.00576040 | accuracy : (train) 99.5131450 (testing)  80.078125\n",
      "epoch : 1237| loss : (train) 0.00098361 (testing) 0.00579772 | accuracy : (train) 99.5131450 (testing)  80.078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1238| loss : (train) 0.00095352 (testing) 0.00556523 | accuracy : (train) 99.5131450 (testing)      81.25\n",
      "epoch : 1239| loss : (train) 0.00116210 (testing) 0.00608013 | accuracy : (train) 99.4157740 (testing)   80.46875\n",
      "epoch : 1240| loss : (train) 0.00093214 (testing) 0.00594862 | accuracy : (train) 99.6105160 (testing)  80.078125\n",
      "epoch : 1241| loss : (train) 0.00105403 (testing) 0.00596273 | accuracy : (train) 99.4157740 (testing)  80.078125\n",
      "epoch : 1242| loss : (train) 0.00108645 (testing) 0.00555117 | accuracy : (train) 99.6105160 (testing)      81.25\n",
      "epoch : 1243| loss : (train) 0.00113158 (testing) 0.00719644 | accuracy : (train) 99.3184031 (testing)  79.296875\n",
      "epoch : 1244| loss : (train) 0.00091429 (testing) 0.00602400 | accuracy : (train) 99.5131450 (testing)   80.46875\n",
      "epoch : 1245| loss : (train) 0.00099421 (testing) 0.00601203 | accuracy : (train) 99.5131450 (testing)  80.078125\n",
      "epoch : 1246| loss : (train) 0.00125588 (testing) 0.00579240 | accuracy : (train) 99.6105160 (testing)  80.078125\n",
      "epoch : 1247| loss : (train) 0.00107100 (testing) 0.00684243 | accuracy : (train) 99.4157740 (testing)     78.125\n",
      "epoch : 1248| loss : (train) 0.00104356 (testing) 0.00582857 | accuracy : (train) 99.5131450 (testing)  80.078125\n",
      "epoch : 1249| loss : (train) 0.00105160 (testing) 0.00584644 | accuracy : (train) 99.3184031 (testing)  80.078125\n",
      "epoch : 1250| loss : (train) 0.00100270 (testing) 0.00596868 | accuracy : (train) 99.5131450 (testing)  80.078125\n",
      "epoch : 1251| loss : (train) 0.00097369 (testing) 0.00597197 | accuracy : (train) 99.5131450 (testing)  80.078125\n",
      "epoch : 1252| loss : (train) 0.00095763 (testing) 0.00557239 | accuracy : (train) 99.5131450 (testing)      81.25\n",
      "epoch : 1253| loss : (train) 0.00106383 (testing) 0.00540403 | accuracy : (train) 99.4157740 (testing)   82.03125\n",
      "epoch : 1254| loss : (train) 0.00085607 (testing) 0.00593450 | accuracy : (train) 99.3184031 (testing)  80.078125\n",
      "epoch : 1255| loss : (train) 0.00090337 (testing) 0.00611127 | accuracy : (train) 99.4157740 (testing)  80.859375\n",
      "epoch : 1256| loss : (train) 0.00117790 (testing) 0.00683348 | accuracy : (train) 99.4157740 (testing)  78.515625\n",
      "epoch : 1257| loss : (train) 0.00103589 (testing) 0.00601406 | accuracy : (train) 99.4157740 (testing)  80.078125\n",
      "epoch : 1258| loss : (train) 0.00085656 (testing) 0.00585337 | accuracy : (train) 99.5131450 (testing)  80.078125\n",
      "epoch : 1259| loss : (train) 0.00099314 (testing) 0.00559930 | accuracy : (train) 99.6105160 (testing)      81.25\n",
      "epoch : 1260| loss : (train) 0.00085786 (testing) 0.00570332 | accuracy : (train) 99.4157740 (testing)   80.46875\n",
      "epoch : 1261| loss : (train) 0.00108897 (testing) 0.00663448 | accuracy : (train) 99.5131450 (testing)   78.90625\n",
      "epoch : 1262| loss : (train) 0.00100695 (testing) 0.00550791 | accuracy : (train) 99.3184031 (testing)      81.25\n",
      "epoch : 1263| loss : (train) 0.00096433 (testing) 0.00588200 | accuracy : (train) 99.2210321 (testing)  80.078125\n",
      "epoch : 1264| loss : (train) 0.00095351 (testing) 0.00592824 | accuracy : (train) 99.5131450 (testing)  80.078125\n",
      "epoch : 1265| loss : (train) 0.00095226 (testing) 0.00551221 | accuracy : (train) 99.6105160 (testing)  81.640625\n",
      "epoch : 1266| loss : (train) 0.00094401 (testing) 0.00583261 | accuracy : (train) 99.4157740 (testing)   80.46875\n",
      "epoch : 1267| loss : (train) 0.00095183 (testing) 0.00591031 | accuracy : (train) 99.5131450 (testing)  80.078125\n",
      "epoch : 1268| loss : (train) 0.00102800 (testing) 0.00576776 | accuracy : (train) 99.5131450 (testing)   80.46875\n",
      "epoch : 1269| loss : (train) 0.00094380 (testing) 0.00590297 | accuracy : (train) 99.5131450 (testing)  80.078125\n",
      "epoch : 1270| loss : (train) 0.00111133 (testing) 0.00607638 | accuracy : (train) 99.5131450 (testing)   80.46875\n",
      "epoch : 1271| loss : (train) 0.00089873 (testing) 0.00648025 | accuracy : (train) 99.6105160 (testing)  79.296875\n",
      "epoch : 1272| loss : (train) 0.00101547 (testing) 0.00593929 | accuracy : (train) 99.6105160 (testing)  80.078125\n",
      "epoch : 1273| loss : (train) 0.00107982 (testing) 0.00618854 | accuracy : (train) 99.5131450 (testing)  80.859375\n",
      "epoch : 1274| loss : (train) 0.00104579 (testing) 0.00584380 | accuracy : (train) 99.6105160 (testing)  80.078125\n",
      "epoch : 1275| loss : (train) 0.00086999 (testing) 0.00575261 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1276| loss : (train) 0.00095626 (testing) 0.00666745 | accuracy : (train) 99.6105160 (testing)   78.90625\n",
      "epoch : 1277| loss : (train) 0.00092385 (testing) 0.00587222 | accuracy : (train) 99.5131450 (testing)   80.46875\n",
      "epoch : 1278| loss : (train) 0.00095843 (testing) 0.00594996 | accuracy : (train) 99.6105160 (testing)  80.078125\n",
      "epoch : 1279| loss : (train) 0.00089225 (testing) 0.00602179 | accuracy : (train) 99.6105160 (testing)  80.078125\n",
      "epoch : 1280| loss : (train) 0.00095649 (testing) 0.00556262 | accuracy : (train) 99.6105160 (testing)      81.25\n",
      "epoch : 1281| loss : (train) 0.00105354 (testing) 0.00697902 | accuracy : (train) 99.5131450 (testing)     78.125\n",
      "epoch : 1282| loss : (train) 0.00094514 (testing) 0.00609025 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1283| loss : (train) 0.00104640 (testing) 0.00593387 | accuracy : (train) 99.6105160 (testing)  80.078125\n",
      "epoch : 1284| loss : (train) 0.00096033 (testing) 0.00609439 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1285| loss : (train) 0.00090114 (testing) 0.00604293 | accuracy : (train) 99.5131450 (testing)  80.078125\n",
      "epoch : 1286| loss : (train) 0.00089835 (testing) 0.00614147 | accuracy : (train) 99.5131450 (testing)   80.46875\n",
      "epoch : 1287| loss : (train) 0.00092754 (testing) 0.00595144 | accuracy : (train) 99.6105160 (testing)  80.078125\n",
      "epoch : 1288| loss : (train) 0.00090550 (testing) 0.00576474 | accuracy : (train) 99.5131450 (testing)   80.46875\n",
      "epoch : 1289| loss : (train) 0.00092900 (testing) 0.00614572 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1290| loss : (train) 0.00098771 (testing) 0.00566416 | accuracy : (train) 99.6105160 (testing)      81.25\n",
      "epoch : 1291| loss : (train) 0.00107788 (testing) 0.00563738 | accuracy : (train) 99.3184031 (testing)  81.640625\n",
      "epoch : 1292| loss : (train) 0.00095060 (testing) 0.00623614 | accuracy : (train) 99.6105160 (testing)  80.859375\n",
      "epoch : 1293| loss : (train) 0.00083701 (testing) 0.00591019 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1294| loss : (train) 0.00093986 (testing) 0.00642965 | accuracy : (train) 99.5131450 (testing)    79.6875\n",
      "epoch : 1295| loss : (train) 0.00095522 (testing) 0.00602564 | accuracy : (train) 99.5131450 (testing)  80.078125\n",
      "epoch : 1296| loss : (train) 0.00089173 (testing) 0.00572072 | accuracy : (train) 99.6105160 (testing)  80.859375\n",
      "epoch : 1297| loss : (train) 0.00088022 (testing) 0.00600569 | accuracy : (train) 99.6105160 (testing)  80.078125\n",
      "epoch : 1298| loss : (train) 0.00083585 (testing) 0.00652105 | accuracy : (train) 99.6105160 (testing)    79.6875\n",
      "epoch : 1299| loss : (train) 0.00086421 (testing) 0.00584358 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1300| loss : (train) 0.00085883 (testing) 0.00638750 | accuracy : (train) 99.7078870 (testing)  80.078125\n",
      "epoch : 1301| loss : (train) 0.00096177 (testing) 0.00606818 | accuracy : (train) 99.6105160 (testing)  80.078125\n",
      "epoch : 1302| loss : (train) 0.00081775 (testing) 0.00619583 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1303| loss : (train) 0.00094395 (testing) 0.00571947 | accuracy : (train) 99.6105160 (testing)      81.25\n",
      "epoch : 1304| loss : (train) 0.00095648 (testing) 0.00598669 | accuracy : (train) 99.5131450 (testing)  80.078125\n",
      "epoch : 1305| loss : (train) 0.00082155 (testing) 0.00611412 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1306| loss : (train) 0.00090687 (testing) 0.00614986 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1307| loss : (train) 0.00093615 (testing) 0.00592667 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1308| loss : (train) 0.00098218 (testing) 0.00636158 | accuracy : (train) 99.6105160 (testing)  80.078125\n",
      "epoch : 1309| loss : (train) 0.00088885 (testing) 0.00579129 | accuracy : (train) 99.6105160 (testing)   80.46875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1310| loss : (train) 0.00082169 (testing) 0.00577054 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1311| loss : (train) 0.00091885 (testing) 0.00635362 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1312| loss : (train) 0.00095199 (testing) 0.00612120 | accuracy : (train) 99.5131450 (testing)   80.46875\n",
      "epoch : 1313| loss : (train) 0.00083221 (testing) 0.00593161 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1314| loss : (train) 0.00100505 (testing) 0.00613970 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1315| loss : (train) 0.00080468 (testing) 0.00597799 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1316| loss : (train) 0.00081441 (testing) 0.00620390 | accuracy : (train) 99.5131450 (testing)   80.46875\n",
      "epoch : 1317| loss : (train) 0.00099369 (testing) 0.00592383 | accuracy : (train) 99.5131450 (testing)   80.46875\n",
      "epoch : 1318| loss : (train) 0.00086686 (testing) 0.00604514 | accuracy : (train) 99.6105160 (testing)  80.078125\n",
      "epoch : 1319| loss : (train) 0.00085545 (testing) 0.00592841 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1320| loss : (train) 0.00076275 (testing) 0.00569431 | accuracy : (train) 99.6105160 (testing)  81.640625\n",
      "epoch : 1321| loss : (train) 0.00090924 (testing) 0.00629757 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1322| loss : (train) 0.00088912 (testing) 0.00624891 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1323| loss : (train) 0.00089064 (testing) 0.00581274 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1324| loss : (train) 0.00106347 (testing) 0.00680473 | accuracy : (train) 99.6105160 (testing)   78.90625\n",
      "epoch : 1325| loss : (train) 0.00077658 (testing) 0.00631671 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1326| loss : (train) 0.00090574 (testing) 0.00657490 | accuracy : (train) 99.7078870 (testing)    79.6875\n",
      "epoch : 1327| loss : (train) 0.00084207 (testing) 0.00591050 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1328| loss : (train) 0.00085159 (testing) 0.00600265 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1329| loss : (train) 0.00096800 (testing) 0.00612104 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1330| loss : (train) 0.00083807 (testing) 0.00594696 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1331| loss : (train) 0.00099722 (testing) 0.00607517 | accuracy : (train) 99.7078870 (testing)  80.078125\n",
      "epoch : 1332| loss : (train) 0.00092054 (testing) 0.00634789 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1333| loss : (train) 0.00098989 (testing) 0.00633412 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1334| loss : (train) 0.00086692 (testing) 0.00583397 | accuracy : (train) 99.7078870 (testing)  80.859375\n",
      "epoch : 1335| loss : (train) 0.00084307 (testing) 0.00620502 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1336| loss : (train) 0.00085156 (testing) 0.00585964 | accuracy : (train) 99.5131450 (testing)   80.46875\n",
      "epoch : 1337| loss : (train) 0.00082312 (testing) 0.00582205 | accuracy : (train) 99.5131450 (testing)  80.859375\n",
      "epoch : 1338| loss : (train) 0.00093822 (testing) 0.00585587 | accuracy : (train) 99.4157740 (testing)   80.46875\n",
      "epoch : 1339| loss : (train) 0.00087400 (testing) 0.00573082 | accuracy : (train) 99.5131450 (testing)  81.640625\n",
      "epoch : 1340| loss : (train) 0.00091371 (testing) 0.00569492 | accuracy : (train) 99.5131450 (testing)  81.640625\n",
      "epoch : 1341| loss : (train) 0.00088473 (testing) 0.00597524 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1342| loss : (train) 0.00076514 (testing) 0.00638073 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1343| loss : (train) 0.00086370 (testing) 0.00585281 | accuracy : (train) 99.7078870 (testing)  80.859375\n",
      "epoch : 1344| loss : (train) 0.00089314 (testing) 0.00627936 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1345| loss : (train) 0.00079159 (testing) 0.00615317 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1346| loss : (train) 0.00096282 (testing) 0.00612465 | accuracy : (train) 99.5131450 (testing)   80.46875\n",
      "epoch : 1347| loss : (train) 0.00086236 (testing) 0.00628457 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1348| loss : (train) 0.00078550 (testing) 0.00619247 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1349| loss : (train) 0.00088928 (testing) 0.00678628 | accuracy : (train) 99.7078870 (testing)    79.6875\n",
      "epoch : 1350| loss : (train) 0.00078029 (testing) 0.00625016 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1351| loss : (train) 0.00081217 (testing) 0.00602625 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1352| loss : (train) 0.00079231 (testing) 0.00628172 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1353| loss : (train) 0.00076174 (testing) 0.00621101 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1354| loss : (train) 0.00086862 (testing) 0.00631593 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1355| loss : (train) 0.00090033 (testing) 0.00643071 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1356| loss : (train) 0.00091785 (testing) 0.00617554 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1357| loss : (train) 0.00075363 (testing) 0.00624153 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1358| loss : (train) 0.00078768 (testing) 0.00592492 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1359| loss : (train) 0.00079305 (testing) 0.00676923 | accuracy : (train) 99.6105160 (testing)    79.6875\n",
      "epoch : 1360| loss : (train) 0.00077065 (testing) 0.00637174 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1361| loss : (train) 0.00088423 (testing) 0.00603621 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1362| loss : (train) 0.00087581 (testing) 0.00601284 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1363| loss : (train) 0.00083713 (testing) 0.00640407 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1364| loss : (train) 0.00081634 (testing) 0.00586981 | accuracy : (train) 99.6105160 (testing)  80.859375\n",
      "epoch : 1365| loss : (train) 0.00090840 (testing) 0.00684870 | accuracy : (train) 99.7078870 (testing)    79.6875\n",
      "epoch : 1366| loss : (train) 0.00087844 (testing) 0.00605559 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1367| loss : (train) 0.00082243 (testing) 0.00611838 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1368| loss : (train) 0.00086951 (testing) 0.00604001 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1369| loss : (train) 0.00090794 (testing) 0.00623085 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1370| loss : (train) 0.00086494 (testing) 0.00603706 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1371| loss : (train) 0.00080796 (testing) 0.00612716 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1372| loss : (train) 0.00093153 (testing) 0.00669799 | accuracy : (train) 99.7078870 (testing)    79.6875\n",
      "epoch : 1373| loss : (train) 0.00073721 (testing) 0.00641172 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1374| loss : (train) 0.00085929 (testing) 0.00673915 | accuracy : (train) 99.6105160 (testing)    79.6875\n",
      "epoch : 1375| loss : (train) 0.00069598 (testing) 0.00600185 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1376| loss : (train) 0.00093702 (testing) 0.00710453 | accuracy : (train) 99.7078870 (testing)  78.515625\n",
      "epoch : 1377| loss : (train) 0.00093289 (testing) 0.00673238 | accuracy : (train) 99.6105160 (testing)    79.6875\n",
      "epoch : 1378| loss : (train) 0.00082691 (testing) 0.00583457 | accuracy : (train) 99.6105160 (testing)   82.03125\n",
      "epoch : 1379| loss : (train) 0.00088461 (testing) 0.00617313 | accuracy : (train) 99.7078870 (testing)  80.859375\n",
      "epoch : 1380| loss : (train) 0.00081233 (testing) 0.00606720 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1381| loss : (train) 0.00072891 (testing) 0.00597463 | accuracy : (train) 99.7078870 (testing)   80.46875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1382| loss : (train) 0.00088637 (testing) 0.00591715 | accuracy : (train) 99.7078870 (testing)      81.25\n",
      "epoch : 1383| loss : (train) 0.00071628 (testing) 0.00597290 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1384| loss : (train) 0.00080564 (testing) 0.00619407 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1385| loss : (train) 0.00080393 (testing) 0.00623900 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1386| loss : (train) 0.00071655 (testing) 0.00616193 | accuracy : (train) 99.7078870 (testing)  80.859375\n",
      "epoch : 1387| loss : (train) 0.00080202 (testing) 0.00670802 | accuracy : (train) 99.7078870 (testing)    79.6875\n",
      "epoch : 1388| loss : (train) 0.00087698 (testing) 0.00601702 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1389| loss : (train) 0.00084881 (testing) 0.00610814 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1390| loss : (train) 0.00076304 (testing) 0.00599239 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1391| loss : (train) 0.00085405 (testing) 0.00620057 | accuracy : (train) 99.7078870 (testing)  80.859375\n",
      "epoch : 1392| loss : (train) 0.00074047 (testing) 0.00658348 | accuracy : (train) 99.7078870 (testing)  80.078125\n",
      "epoch : 1393| loss : (train) 0.00081029 (testing) 0.00606962 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1394| loss : (train) 0.00079754 (testing) 0.00637324 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1395| loss : (train) 0.00081986 (testing) 0.00638267 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1396| loss : (train) 0.00079412 (testing) 0.00666811 | accuracy : (train) 99.7078870 (testing)  79.296875\n",
      "epoch : 1397| loss : (train) 0.00069578 (testing) 0.00608439 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1398| loss : (train) 0.00091249 (testing) 0.00634160 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1399| loss : (train) 0.00075186 (testing) 0.00617908 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1400| loss : (train) 0.00073086 (testing) 0.00623520 | accuracy : (train) 99.6105160 (testing)  80.859375\n",
      "epoch : 1401| loss : (train) 0.00070850 (testing) 0.00633240 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1402| loss : (train) 0.00073788 (testing) 0.00601743 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1403| loss : (train) 0.00083549 (testing) 0.00608172 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1404| loss : (train) 0.00069318 (testing) 0.00587742 | accuracy : (train) 99.7078870 (testing)   82.03125\n",
      "epoch : 1405| loss : (train) 0.00073282 (testing) 0.00616267 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1406| loss : (train) 0.00080162 (testing) 0.00702751 | accuracy : (train) 99.7078870 (testing)    79.6875\n",
      "epoch : 1407| loss : (train) 0.00077807 (testing) 0.00641109 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1408| loss : (train) 0.00078443 (testing) 0.00619209 | accuracy : (train) 99.7078870 (testing)  80.859375\n",
      "epoch : 1409| loss : (train) 0.00083931 (testing) 0.00603169 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1410| loss : (train) 0.00080365 (testing) 0.00681736 | accuracy : (train) 99.7078870 (testing)    79.6875\n",
      "epoch : 1411| loss : (train) 0.00072495 (testing) 0.00662417 | accuracy : (train) 99.6105160 (testing)  80.078125\n",
      "epoch : 1412| loss : (train) 0.00071975 (testing) 0.00604125 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1413| loss : (train) 0.00075916 (testing) 0.00654548 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1414| loss : (train) 0.00079993 (testing) 0.00656706 | accuracy : (train) 99.8052580 (testing)   80.46875\n",
      "epoch : 1415| loss : (train) 0.00074424 (testing) 0.00643865 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1416| loss : (train) 0.00080979 (testing) 0.00616846 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1417| loss : (train) 0.00080307 (testing) 0.00674214 | accuracy : (train) 99.7078870 (testing)  79.296875\n",
      "epoch : 1418| loss : (train) 0.00078274 (testing) 0.00674029 | accuracy : (train) 99.7078870 (testing)  79.296875\n",
      "epoch : 1419| loss : (train) 0.00079574 (testing) 0.00635108 | accuracy : (train) 99.6105160 (testing)   80.46875\n",
      "epoch : 1420| loss : (train) 0.00073607 (testing) 0.00619902 | accuracy : (train) 99.7078870 (testing)  80.859375\n",
      "epoch : 1421| loss : (train) 0.00068557 (testing) 0.00653640 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1422| loss : (train) 0.00076553 (testing) 0.00664084 | accuracy : (train) 99.7078870 (testing)  80.078125\n",
      "epoch : 1423| loss : (train) 0.00077217 (testing) 0.00600583 | accuracy : (train) 99.7078870 (testing)      81.25\n",
      "epoch : 1424| loss : (train) 0.00085674 (testing) 0.00592345 | accuracy : (train) 99.7078870 (testing)   82.03125\n",
      "epoch : 1425| loss : (train) 0.00071381 (testing) 0.00601411 | accuracy : (train) 99.7078870 (testing)      81.25\n",
      "epoch : 1426| loss : (train) 0.00076911 (testing) 0.00625821 | accuracy : (train) 99.7078870 (testing)      81.25\n",
      "epoch : 1427| loss : (train) 0.00072805 (testing) 0.00636101 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1428| loss : (train) 0.00070744 (testing) 0.00672593 | accuracy : (train) 99.7078870 (testing)  79.296875\n",
      "epoch : 1429| loss : (train) 0.00074146 (testing) 0.00620897 | accuracy : (train) 99.7078870 (testing)  80.859375\n",
      "epoch : 1430| loss : (train) 0.00069841 (testing) 0.00637219 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1431| loss : (train) 0.00086189 (testing) 0.00653279 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1432| loss : (train) 0.00070113 (testing) 0.00666787 | accuracy : (train) 99.7078870 (testing)  80.078125\n",
      "epoch : 1433| loss : (train) 0.00070383 (testing) 0.00649338 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1434| loss : (train) 0.00074790 (testing) 0.00661269 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1435| loss : (train) 0.00065864 (testing) 0.00630366 | accuracy : (train) 99.7078870 (testing)  80.859375\n",
      "epoch : 1436| loss : (train) 0.00081760 (testing) 0.00673031 | accuracy : (train) 99.7078870 (testing)    79.6875\n",
      "epoch : 1437| loss : (train) 0.00071809 (testing) 0.00647506 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1438| loss : (train) 0.00073358 (testing) 0.00628499 | accuracy : (train) 99.8052580 (testing)      81.25\n",
      "epoch : 1439| loss : (train) 0.00068951 (testing) 0.00636058 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1440| loss : (train) 0.00077084 (testing) 0.00599347 | accuracy : (train) 99.7078870 (testing)  82.421875\n",
      "epoch : 1441| loss : (train) 0.00067879 (testing) 0.00647359 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1442| loss : (train) 0.00070774 (testing) 0.00615015 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1443| loss : (train) 0.00073857 (testing) 0.00684285 | accuracy : (train) 99.7078870 (testing)  79.296875\n",
      "epoch : 1444| loss : (train) 0.00071525 (testing) 0.00623405 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1445| loss : (train) 0.00081891 (testing) 0.00667973 | accuracy : (train) 99.7078870 (testing)  80.078125\n",
      "epoch : 1446| loss : (train) 0.00070758 (testing) 0.00640453 | accuracy : (train) 99.9026290 (testing)   80.46875\n",
      "epoch : 1447| loss : (train) 0.00066697 (testing) 0.00642784 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1448| loss : (train) 0.00075281 (testing) 0.00642510 | accuracy : (train) 99.8052580 (testing)   80.46875\n",
      "epoch : 1449| loss : (train) 0.00069111 (testing) 0.00648569 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1450| loss : (train) 0.00069274 (testing) 0.00623082 | accuracy : (train) 99.8052580 (testing)   80.46875\n",
      "epoch : 1451| loss : (train) 0.00066540 (testing) 0.00663572 | accuracy : (train) 99.8052580 (testing)   80.46875\n",
      "epoch : 1452| loss : (train) 0.00066854 (testing) 0.00631515 | accuracy : (train) 99.8052580 (testing)  80.859375\n",
      "epoch : 1453| loss : (train) 0.00082603 (testing) 0.00651739 | accuracy : (train) 99.8052580 (testing)   80.46875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1454| loss : (train) 0.00073156 (testing) 0.00672036 | accuracy : (train) 99.8052580 (testing)  80.078125\n",
      "epoch : 1455| loss : (train) 0.00063593 (testing) 0.00621914 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1456| loss : (train) 0.00068617 (testing) 0.00656344 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1457| loss : (train) 0.00062211 (testing) 0.00652639 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1458| loss : (train) 0.00078572 (testing) 0.00657776 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1459| loss : (train) 0.00069827 (testing) 0.00635710 | accuracy : (train) 99.8052580 (testing)  80.859375\n",
      "epoch : 1460| loss : (train) 0.00069604 (testing) 0.00643751 | accuracy : (train) 99.8052580 (testing)   80.46875\n",
      "epoch : 1461| loss : (train) 0.00065818 (testing) 0.00611172 | accuracy : (train) 99.7078870 (testing)      81.25\n",
      "epoch : 1462| loss : (train) 0.00064022 (testing) 0.00665599 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1463| loss : (train) 0.00068519 (testing) 0.00668384 | accuracy : (train) 99.8052580 (testing)   80.46875\n",
      "epoch : 1464| loss : (train) 0.00069173 (testing) 0.00675897 | accuracy : (train) 99.7078870 (testing)  80.078125\n",
      "epoch : 1465| loss : (train) 0.00063842 (testing) 0.00643959 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1466| loss : (train) 0.00063058 (testing) 0.00684523 | accuracy : (train) 99.7078870 (testing)    79.6875\n",
      "epoch : 1467| loss : (train) 0.00072423 (testing) 0.00623477 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1468| loss : (train) 0.00061174 (testing) 0.00644262 | accuracy : (train) 99.8052580 (testing)   80.46875\n",
      "epoch : 1469| loss : (train) 0.00067021 (testing) 0.00647261 | accuracy : (train) 99.8052580 (testing)   80.46875\n",
      "epoch : 1470| loss : (train) 0.00078001 (testing) 0.00617867 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1471| loss : (train) 0.00069143 (testing) 0.00695181 | accuracy : (train) 99.7078870 (testing)  79.296875\n",
      "epoch : 1472| loss : (train) 0.00066970 (testing) 0.00622401 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1473| loss : (train) 0.00072147 (testing) 0.00718176 | accuracy : (train) 99.7078870 (testing)  79.296875\n",
      "epoch : 1474| loss : (train) 0.00062089 (testing) 0.00672547 | accuracy : (train) 99.8052580 (testing)   80.46875\n",
      "epoch : 1475| loss : (train) 0.00068900 (testing) 0.00645191 | accuracy : (train) 99.8052580 (testing)   80.46875\n",
      "epoch : 1476| loss : (train) 0.00071205 (testing) 0.00615561 | accuracy : (train) 99.7078870 (testing)      81.25\n",
      "epoch : 1477| loss : (train) 0.00068040 (testing) 0.00633080 | accuracy : (train) 99.7078870 (testing)  80.859375\n",
      "epoch : 1478| loss : (train) 0.00081831 (testing) 0.00651285 | accuracy : (train) 99.8052580 (testing)   80.46875\n",
      "epoch : 1479| loss : (train) 0.00069370 (testing) 0.00669715 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1480| loss : (train) 0.00072431 (testing) 0.00661704 | accuracy : (train) 99.8052580 (testing)   80.46875\n",
      "epoch : 1481| loss : (train) 0.00057000 (testing) 0.00670843 | accuracy : (train) 99.9026290 (testing)   80.46875\n",
      "epoch : 1482| loss : (train) 0.00074129 (testing) 0.00610395 | accuracy : (train) 99.9026290 (testing)   82.03125\n",
      "epoch : 1483| loss : (train) 0.00066516 (testing) 0.00643754 | accuracy : (train) 99.9026290 (testing)  80.859375\n",
      "epoch : 1484| loss : (train) 0.00061752 (testing) 0.00629980 | accuracy : (train) 99.8052580 (testing)  80.859375\n",
      "epoch : 1485| loss : (train) 0.00067025 (testing) 0.00651575 | accuracy : (train) 99.8052580 (testing)   80.46875\n",
      "epoch : 1486| loss : (train) 0.00067329 (testing) 0.00614278 | accuracy : (train) 99.9026290 (testing)   82.03125\n",
      "epoch : 1487| loss : (train) 0.00064431 (testing) 0.00641868 | accuracy : (train) 99.7078870 (testing)      81.25\n",
      "epoch : 1488| loss : (train) 0.00062064 (testing) 0.00642139 | accuracy : (train) 99.8052580 (testing)      81.25\n",
      "epoch : 1489| loss : (train) 0.00064734 (testing) 0.00668797 | accuracy : (train) 99.9026290 (testing)   80.46875\n",
      "epoch : 1490| loss : (train) 0.00062457 (testing) 0.00667551 | accuracy : (train) 99.9026290 (testing)   80.46875\n",
      "epoch : 1491| loss : (train) 0.00066399 (testing) 0.00667640 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1492| loss : (train) 0.00067282 (testing) 0.00635642 | accuracy : (train) 99.8052580 (testing)  80.859375\n",
      "epoch : 1493| loss : (train) 0.00058383 (testing) 0.00678680 | accuracy : (train) 99.8052580 (testing)  80.078125\n",
      "epoch : 1494| loss : (train) 0.00076375 (testing) 0.00675774 | accuracy : (train) 99.8052580 (testing)   80.46875\n",
      "epoch : 1495| loss : (train) 0.00067717 (testing) 0.00625134 | accuracy : (train) 99.8052580 (testing)   80.46875\n",
      "epoch : 1496| loss : (train) 0.00069986 (testing) 0.00650613 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1497| loss : (train) 0.00065852 (testing) 0.00655783 | accuracy : (train) 99.8052580 (testing)   80.46875\n",
      "epoch : 1498| loss : (train) 0.00065706 (testing) 0.00621225 | accuracy : (train) 99.9026290 (testing)  80.859375\n",
      "epoch : 1499| loss : (train) 0.00065754 (testing) 0.00667043 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1500| loss : (train) 0.00064866 (testing) 0.00635802 | accuracy : (train) 99.9026290 (testing)  80.859375\n",
      "epoch : 1501| loss : (train) 0.00065370 (testing) 0.00616946 | accuracy : (train) 99.8052580 (testing)   82.03125\n",
      "epoch : 1502| loss : (train) 0.00068987 (testing) 0.00643082 | accuracy : (train) 99.8052580 (testing)  80.859375\n",
      "epoch : 1503| loss : (train) 0.00062809 (testing) 0.00618718 | accuracy : (train)      100.0 (testing)   82.03125\n",
      "epoch : 1504| loss : (train) 0.00064910 (testing) 0.00655964 | accuracy : (train) 99.7078870 (testing)   80.46875\n",
      "epoch : 1505| loss : (train) 0.00064120 (testing) 0.00666120 | accuracy : (train) 99.9026290 (testing)   80.46875\n",
      "epoch : 1506| loss : (train) 0.00060920 (testing) 0.00659020 | accuracy : (train) 99.9026290 (testing)   80.46875\n",
      "epoch : 1507| loss : (train) 0.00064005 (testing) 0.00667744 | accuracy : (train) 99.9026290 (testing)   80.46875\n",
      "epoch : 1508| loss : (train) 0.00062721 (testing) 0.00691516 | accuracy : (train) 99.9026290 (testing)    79.6875\n",
      "epoch : 1509| loss : (train) 0.00063281 (testing) 0.00648621 | accuracy : (train) 99.9026290 (testing)      81.25\n",
      "epoch : 1510| loss : (train) 0.00065050 (testing) 0.00625307 | accuracy : (train) 99.9026290 (testing)  80.859375\n",
      "epoch : 1511| loss : (train) 0.00066299 (testing) 0.00629512 | accuracy : (train) 99.8052580 (testing)   80.46875\n",
      "epoch : 1512| loss : (train) 0.00063296 (testing) 0.00623495 | accuracy : (train) 99.9026290 (testing)  81.640625\n",
      "epoch : 1513| loss : (train) 0.00066901 (testing) 0.00626203 | accuracy : (train) 99.8052580 (testing)  80.859375\n",
      "epoch : 1514| loss : (train) 0.00062551 (testing) 0.00670418 | accuracy : (train) 99.8052580 (testing)   80.46875\n",
      "epoch : 1515| loss : (train) 0.00067926 (testing) 0.00635432 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1516| loss : (train) 0.00066411 (testing) 0.00663416 | accuracy : (train) 99.9026290 (testing)   80.46875\n",
      "epoch : 1517| loss : (train) 0.00066041 (testing) 0.00634468 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1518| loss : (train) 0.00070117 (testing) 0.00639503 | accuracy : (train) 99.8052580 (testing)  80.859375\n",
      "epoch : 1519| loss : (train) 0.00059594 (testing) 0.00651611 | accuracy : (train) 99.7078870 (testing)  80.859375\n",
      "epoch : 1520| loss : (train) 0.00062459 (testing) 0.00674307 | accuracy : (train) 99.9026290 (testing)   80.46875\n",
      "epoch : 1521| loss : (train) 0.00061750 (testing) 0.00666444 | accuracy : (train) 99.9026290 (testing)   80.46875\n",
      "epoch : 1522| loss : (train) 0.00062910 (testing) 0.00644744 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1523| loss : (train) 0.00062972 (testing) 0.00682767 | accuracy : (train) 99.9026290 (testing)   80.46875\n",
      "epoch : 1524| loss : (train) 0.00063793 (testing) 0.00683931 | accuracy : (train) 99.9026290 (testing)   80.46875\n",
      "epoch : 1525| loss : (train) 0.00067035 (testing) 0.00647249 | accuracy : (train)      100.0 (testing)  80.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1526| loss : (train) 0.00061399 (testing) 0.00646727 | accuracy : (train) 99.9026290 (testing)  80.859375\n",
      "epoch : 1527| loss : (train) 0.00060576 (testing) 0.00619232 | accuracy : (train) 99.9026290 (testing)  81.640625\n",
      "epoch : 1528| loss : (train) 0.00058356 (testing) 0.00637497 | accuracy : (train) 99.7078870 (testing)  80.859375\n",
      "epoch : 1529| loss : (train) 0.00062610 (testing) 0.00687331 | accuracy : (train) 99.9026290 (testing)   80.46875\n",
      "epoch : 1530| loss : (train) 0.00058817 (testing) 0.00638107 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1531| loss : (train) 0.00065667 (testing) 0.00721344 | accuracy : (train) 99.9026290 (testing)  79.296875\n",
      "epoch : 1532| loss : (train) 0.00071633 (testing) 0.00738851 | accuracy : (train)      100.0 (testing)  79.296875\n",
      "epoch : 1533| loss : (train) 0.00062575 (testing) 0.00698100 | accuracy : (train) 99.9026290 (testing)    79.6875\n",
      "epoch : 1534| loss : (train) 0.00058653 (testing) 0.00646179 | accuracy : (train) 99.8052580 (testing)  80.859375\n",
      "epoch : 1535| loss : (train) 0.00060607 (testing) 0.00626620 | accuracy : (train)      100.0 (testing)   82.03125\n",
      "epoch : 1536| loss : (train) 0.00058522 (testing) 0.00649316 | accuracy : (train) 99.9026290 (testing)  80.859375\n",
      "epoch : 1537| loss : (train) 0.00068943 (testing) 0.00686662 | accuracy : (train) 99.9026290 (testing)   80.46875\n",
      "epoch : 1538| loss : (train) 0.00064422 (testing) 0.00632797 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1539| loss : (train) 0.00066349 (testing) 0.00681798 | accuracy : (train) 99.8052580 (testing)   80.46875\n",
      "epoch : 1540| loss : (train) 0.00063839 (testing) 0.00707442 | accuracy : (train)      100.0 (testing)  79.296875\n",
      "epoch : 1541| loss : (train) 0.00055211 (testing) 0.00659001 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1542| loss : (train) 0.00062946 (testing) 0.00658131 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1543| loss : (train) 0.00059866 (testing) 0.00645396 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1544| loss : (train) 0.00070075 (testing) 0.00678155 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1545| loss : (train) 0.00060556 (testing) 0.00654633 | accuracy : (train)      100.0 (testing)      81.25\n",
      "epoch : 1546| loss : (train) 0.00058020 (testing) 0.00673417 | accuracy : (train) 99.9026290 (testing)   80.46875\n",
      "epoch : 1547| loss : (train) 0.00057053 (testing) 0.00661972 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1548| loss : (train) 0.00062384 (testing) 0.00635645 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1549| loss : (train) 0.00058709 (testing) 0.00641106 | accuracy : (train) 99.8052580 (testing)  80.859375\n",
      "epoch : 1550| loss : (train) 0.00059618 (testing) 0.00663366 | accuracy : (train) 99.9026290 (testing)   80.46875\n",
      "epoch : 1551| loss : (train) 0.00055416 (testing) 0.00673443 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1552| loss : (train) 0.00062349 (testing) 0.00670452 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1553| loss : (train) 0.00059676 (testing) 0.00679057 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1554| loss : (train) 0.00056476 (testing) 0.00691062 | accuracy : (train) 99.9026290 (testing)   80.46875\n",
      "epoch : 1555| loss : (train) 0.00067754 (testing) 0.00695721 | accuracy : (train)      100.0 (testing)  80.078125\n",
      "epoch : 1556| loss : (train) 0.00061821 (testing) 0.00666966 | accuracy : (train) 99.9026290 (testing)   80.46875\n",
      "epoch : 1557| loss : (train) 0.00060483 (testing) 0.00644604 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1558| loss : (train) 0.00056424 (testing) 0.00653869 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1559| loss : (train) 0.00069044 (testing) 0.00650686 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1560| loss : (train) 0.00057109 (testing) 0.00691041 | accuracy : (train) 99.9026290 (testing)   80.46875\n",
      "epoch : 1561| loss : (train) 0.00057043 (testing) 0.00666951 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1562| loss : (train) 0.00061578 (testing) 0.00719063 | accuracy : (train)      100.0 (testing)  79.296875\n",
      "epoch : 1563| loss : (train) 0.00052509 (testing) 0.00658907 | accuracy : (train)      100.0 (testing)      81.25\n",
      "epoch : 1564| loss : (train) 0.00068680 (testing) 0.00632744 | accuracy : (train)      100.0 (testing)   82.03125\n",
      "epoch : 1565| loss : (train) 0.00057840 (testing) 0.00660871 | accuracy : (train)      100.0 (testing)      81.25\n",
      "epoch : 1566| loss : (train) 0.00058531 (testing) 0.00674306 | accuracy : (train) 99.9026290 (testing)   80.46875\n",
      "epoch : 1567| loss : (train) 0.00052585 (testing) 0.00676873 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1568| loss : (train) 0.00054410 (testing) 0.00690806 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1569| loss : (train) 0.00060440 (testing) 0.00656401 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1570| loss : (train) 0.00053334 (testing) 0.00640080 | accuracy : (train)      100.0 (testing)  81.640625\n",
      "epoch : 1571| loss : (train) 0.00058573 (testing) 0.00658884 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1572| loss : (train) 0.00058692 (testing) 0.00689229 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1573| loss : (train) 0.00052167 (testing) 0.00696397 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1574| loss : (train) 0.00054671 (testing) 0.00644808 | accuracy : (train)      100.0 (testing)      81.25\n",
      "epoch : 1575| loss : (train) 0.00053324 (testing) 0.00655716 | accuracy : (train) 99.9026290 (testing)  80.859375\n",
      "epoch : 1576| loss : (train) 0.00061367 (testing) 0.00683455 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1577| loss : (train) 0.00053051 (testing) 0.00671357 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1578| loss : (train) 0.00060753 (testing) 0.00679110 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1579| loss : (train) 0.00057734 (testing) 0.00664479 | accuracy : (train)      100.0 (testing)      81.25\n",
      "epoch : 1580| loss : (train) 0.00060187 (testing) 0.00686871 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1581| loss : (train) 0.00064048 (testing) 0.00631340 | accuracy : (train)      100.0 (testing)  81.640625\n",
      "epoch : 1582| loss : (train) 0.00052434 (testing) 0.00689094 | accuracy : (train) 99.9026290 (testing)   80.46875\n",
      "epoch : 1583| loss : (train) 0.00054094 (testing) 0.00645613 | accuracy : (train)      100.0 (testing)      81.25\n",
      "epoch : 1584| loss : (train) 0.00056421 (testing) 0.00664096 | accuracy : (train) 99.9026290 (testing)      81.25\n",
      "epoch : 1585| loss : (train) 0.00054735 (testing) 0.00701675 | accuracy : (train)      100.0 (testing)  80.078125\n",
      "epoch : 1586| loss : (train) 0.00052205 (testing) 0.00676617 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1587| loss : (train) 0.00050467 (testing) 0.00655975 | accuracy : (train) 99.9026290 (testing)  80.859375\n",
      "epoch : 1588| loss : (train) 0.00060583 (testing) 0.00678309 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1589| loss : (train) 0.00058320 (testing) 0.00673978 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1590| loss : (train) 0.00055963 (testing) 0.00654629 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1591| loss : (train) 0.00058784 (testing) 0.00647542 | accuracy : (train)      100.0 (testing)  81.640625\n",
      "epoch : 1592| loss : (train) 0.00049673 (testing) 0.00656143 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1593| loss : (train) 0.00051892 (testing) 0.00649236 | accuracy : (train)      100.0 (testing)      81.25\n",
      "epoch : 1594| loss : (train) 0.00057693 (testing) 0.00697933 | accuracy : (train) 99.9026290 (testing)   80.46875\n",
      "epoch : 1595| loss : (train) 0.00057792 (testing) 0.00672537 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1596| loss : (train) 0.00053845 (testing) 0.00679794 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1597| loss : (train) 0.00061493 (testing) 0.00756727 | accuracy : (train)      100.0 (testing)  79.296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1598| loss : (train) 0.00057913 (testing) 0.00661784 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1599| loss : (train) 0.00059263 (testing) 0.00690498 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1600| loss : (train) 0.00059899 (testing) 0.00684897 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1601| loss : (train) 0.00063923 (testing) 0.00663885 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1602| loss : (train) 0.00056270 (testing) 0.00674335 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1603| loss : (train) 0.00055119 (testing) 0.00648384 | accuracy : (train)      100.0 (testing)  81.640625\n",
      "epoch : 1604| loss : (train) 0.00048968 (testing) 0.00685863 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1605| loss : (train) 0.00056193 (testing) 0.00692230 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1606| loss : (train) 0.00053323 (testing) 0.00694405 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1607| loss : (train) 0.00049330 (testing) 0.00679465 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1608| loss : (train) 0.00050296 (testing) 0.00639756 | accuracy : (train)      100.0 (testing)   82.03125\n",
      "epoch : 1609| loss : (train) 0.00049336 (testing) 0.00688415 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1610| loss : (train) 0.00046744 (testing) 0.00692102 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1611| loss : (train) 0.00058136 (testing) 0.00717989 | accuracy : (train)      100.0 (testing)    79.6875\n",
      "epoch : 1612| loss : (train) 0.00055356 (testing) 0.00654223 | accuracy : (train)      100.0 (testing)      81.25\n",
      "epoch : 1613| loss : (train) 0.00049853 (testing) 0.00675754 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1614| loss : (train) 0.00049201 (testing) 0.00683132 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1615| loss : (train) 0.00048409 (testing) 0.00645672 | accuracy : (train)      100.0 (testing)   82.03125\n",
      "epoch : 1616| loss : (train) 0.00058911 (testing) 0.00728082 | accuracy : (train) 99.9026290 (testing)  79.296875\n",
      "epoch : 1617| loss : (train) 0.00057674 (testing) 0.00647004 | accuracy : (train)      100.0 (testing)   82.03125\n",
      "epoch : 1618| loss : (train) 0.00062053 (testing) 0.00710541 | accuracy : (train)      100.0 (testing)  80.078125\n",
      "epoch : 1619| loss : (train) 0.00057856 (testing) 0.00662487 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1620| loss : (train) 0.00055129 (testing) 0.00691384 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1621| loss : (train) 0.00065447 (testing) 0.00721702 | accuracy : (train)      100.0 (testing)    79.6875\n",
      "epoch : 1622| loss : (train) 0.00057352 (testing) 0.00671011 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1623| loss : (train) 0.00066326 (testing) 0.00663826 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1624| loss : (train) 0.00053599 (testing) 0.00687960 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1625| loss : (train) 0.00052053 (testing) 0.00691162 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1626| loss : (train) 0.00053424 (testing) 0.00661169 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1627| loss : (train) 0.00054135 (testing) 0.00696492 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1628| loss : (train) 0.00059578 (testing) 0.00685643 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1629| loss : (train) 0.00050932 (testing) 0.00663889 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1630| loss : (train) 0.00050456 (testing) 0.00673462 | accuracy : (train)      100.0 (testing)      81.25\n",
      "epoch : 1631| loss : (train) 0.00057996 (testing) 0.00751691 | accuracy : (train)      100.0 (testing)   78.90625\n",
      "epoch : 1632| loss : (train) 0.00050126 (testing) 0.00703791 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1633| loss : (train) 0.00052025 (testing) 0.00673868 | accuracy : (train)      100.0 (testing)      81.25\n",
      "epoch : 1634| loss : (train) 0.00056812 (testing) 0.00642038 | accuracy : (train)      100.0 (testing)  81.640625\n",
      "epoch : 1635| loss : (train) 0.00051979 (testing) 0.00640833 | accuracy : (train)      100.0 (testing)  81.640625\n",
      "epoch : 1636| loss : (train) 0.00047346 (testing) 0.00684580 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1637| loss : (train) 0.00053797 (testing) 0.00666717 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1638| loss : (train) 0.00053536 (testing) 0.00697465 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1639| loss : (train) 0.00054410 (testing) 0.00713125 | accuracy : (train)      100.0 (testing)  80.078125\n",
      "epoch : 1640| loss : (train) 0.00050502 (testing) 0.00702441 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1641| loss : (train) 0.00056038 (testing) 0.00640559 | accuracy : (train)      100.0 (testing)  81.640625\n",
      "epoch : 1642| loss : (train) 0.00054726 (testing) 0.00720550 | accuracy : (train)      100.0 (testing)  80.078125\n",
      "epoch : 1643| loss : (train) 0.00052469 (testing) 0.00694825 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1644| loss : (train) 0.00055475 (testing) 0.00671886 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1645| loss : (train) 0.00056233 (testing) 0.00697099 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1646| loss : (train) 0.00054963 (testing) 0.00717157 | accuracy : (train)      100.0 (testing)  80.078125\n",
      "epoch : 1647| loss : (train) 0.00050749 (testing) 0.00690726 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1648| loss : (train) 0.00055300 (testing) 0.00660013 | accuracy : (train)      100.0 (testing)  81.640625\n",
      "epoch : 1649| loss : (train) 0.00056681 (testing) 0.00698625 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1650| loss : (train) 0.00055237 (testing) 0.00679224 | accuracy : (train)      100.0 (testing)      81.25\n",
      "epoch : 1651| loss : (train) 0.00048749 (testing) 0.00679758 | accuracy : (train)      100.0 (testing)      81.25\n",
      "epoch : 1652| loss : (train) 0.00050547 (testing) 0.00685730 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1653| loss : (train) 0.00052101 (testing) 0.00648975 | accuracy : (train)      100.0 (testing)  81.640625\n",
      "epoch : 1654| loss : (train) 0.00052382 (testing) 0.00728239 | accuracy : (train)      100.0 (testing)    79.6875\n",
      "epoch : 1655| loss : (train) 0.00052949 (testing) 0.00695030 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1656| loss : (train) 0.00052138 (testing) 0.00693880 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1657| loss : (train) 0.00051523 (testing) 0.00668345 | accuracy : (train)      100.0 (testing)      81.25\n",
      "epoch : 1658| loss : (train) 0.00050389 (testing) 0.00726903 | accuracy : (train)      100.0 (testing)  80.078125\n",
      "epoch : 1659| loss : (train) 0.00051498 (testing) 0.00666742 | accuracy : (train)      100.0 (testing)  81.640625\n",
      "epoch : 1660| loss : (train) 0.00052299 (testing) 0.00712004 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1661| loss : (train) 0.00052444 (testing) 0.00692050 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1662| loss : (train) 0.00049969 (testing) 0.00671113 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1663| loss : (train) 0.00048874 (testing) 0.00684495 | accuracy : (train)      100.0 (testing)      81.25\n",
      "epoch : 1664| loss : (train) 0.00045955 (testing) 0.00688764 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1665| loss : (train) 0.00053181 (testing) 0.00736085 | accuracy : (train)      100.0 (testing)    79.6875\n",
      "epoch : 1666| loss : (train) 0.00046662 (testing) 0.00684750 | accuracy : (train)      100.0 (testing)      81.25\n",
      "epoch : 1667| loss : (train) 0.00053317 (testing) 0.00677521 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1668| loss : (train) 0.00053135 (testing) 0.00701296 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1669| loss : (train) 0.00047195 (testing) 0.00722552 | accuracy : (train)      100.0 (testing)  80.078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1670| loss : (train) 0.00051806 (testing) 0.00685729 | accuracy : (train)      100.0 (testing)      81.25\n",
      "epoch : 1671| loss : (train) 0.00058050 (testing) 0.00674832 | accuracy : (train)      100.0 (testing)  80.859375\n",
      "epoch : 1672| loss : (train) 0.00048163 (testing) 0.00657077 | accuracy : (train)      100.0 (testing)  82.421875\n",
      "epoch : 1673| loss : (train) 0.00051583 (testing) 0.00746957 | accuracy : (train)      100.0 (testing)  79.296875\n",
      "epoch : 1674| loss : (train) 0.00046509 (testing) 0.00734875 | accuracy : (train)      100.0 (testing)    79.6875\n",
      "epoch : 1675| loss : (train) 0.00055190 (testing) 0.00688904 | accuracy : (train)      100.0 (testing)      81.25\n",
      "epoch : 1676| loss : (train) 0.00045484 (testing) 0.00670245 | accuracy : (train)      100.0 (testing)  81.640625\n",
      "epoch : 1677| loss : (train) 0.00048396 (testing) 0.00693814 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1678| loss : (train) 0.00046983 (testing) 0.00684863 | accuracy : (train)      100.0 (testing)      81.25\n",
      "epoch : 1679| loss : (train) 0.00047435 (testing) 0.00695814 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1680| loss : (train) 0.00045689 (testing) 0.00716514 | accuracy : (train)      100.0 (testing)   80.46875\n",
      "epoch : 1681| loss : (train) 0.00051696 (testing) 0.00688921 | accuracy : (train)      100.0 (testing)      81.25\n",
      "epoch : 1682| loss : (train) 0.00048035 (testing) 0.00708625 | accuracy : (train)      100.0 (testing)   80.46875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9e1fdb905a15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mresult_train\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mresult_test\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-bb2babaaf438>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mloss_train_batch\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mloss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_train_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# function for testing the model\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def test():\n",
    "\n",
    "    # print('test the model at given epoch')\n",
    "\n",
    "    accuracy_test   = []\n",
    "    loss_test       = 0\n",
    "    correct         = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for idx_batch, (data, target) in enumerate(loader_test):\n",
    "\n",
    "        if bCuda:\n",
    "        \n",
    "            data, target    = data.cuda(), target.cuda()\n",
    "\n",
    "        data, target    = Variable(data), Variable(target)\n",
    "\n",
    "        output  = model(data)\n",
    "        loss    = objective(output, target)\n",
    "\n",
    "        loss_test   += loss.item()\n",
    "        pred        = output.data.max(1)[1]\n",
    "        correct     += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    loss_test       = loss_test / len(loader_test.dataset)\n",
    "    accuracy_test   = 100. * float(correct) / len(loader_test.dataset)\n",
    "\n",
    "    return {'loss_test': loss_test, 'accuracy_test': accuracy_test}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# iteration for the epoch\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# for system not down\n",
    "epoch_limit = 60000\n",
    "loss_train_epoch = {}\n",
    "loss_train_std = {}\n",
    "accuracy_train_std = {}\n",
    "accuracy_train_epoch = {}\n",
    "loss_test = {}\n",
    "accuracy_test = {}\n",
    "epoch_list = []\n",
    "loss_conv = 0.000001\n",
    "conv_count = 0\n",
    "\n",
    "for e in range(epoch_limit):\n",
    "        \n",
    "    result_train    = train()\n",
    "    result_test     = test()\n",
    "\n",
    "    loss_train_epoch[e]  = result_train['loss_train_epoch']\n",
    "    loss_train_std[e]   = result_train['loss_train_std']\n",
    "    accuracy_train_epoch[e]   = result_train['accuracy_train_epoch']\n",
    "    accuracy_train_std[e] = result_train['accuracy_train_std']\n",
    "\n",
    "    loss_test[e]        = result_test['loss_test']\n",
    "    accuracy_test[e]    = result_test['accuracy_test']\n",
    "    \n",
    "    print(\"epoch : %3s| loss : (train) %10.10s (testing) %10.10s | accuracy : (train) %10.10s (testing) %10.10s\"%(e,loss_train_epoch[e],loss_test[e],accuracy_train_epoch[e],accuracy_test[e]))\n",
    "    epoch_list.append(e)\n",
    "    \n",
    "    if (e > 0) :   \n",
    "        if (abs(loss_train_epoch[e]-loss_train_epoch[e-1]) < loss_conv ) :\n",
    "            conv_count += 1\n",
    "            if (conv_count > 1) :\n",
    "                print(\"loss is converged\")\n",
    "                break\n",
    "        else :\n",
    "            conv_count = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1_x = []\n",
    "t1_y = []\n",
    "t2_x = []\n",
    "t2_y = []\n",
    "for i in epoch_list :\n",
    "    t1_x.append(i)\n",
    "    t1_y.append(accuracy_train_epoch[i])\n",
    "    t2_x.append(i)\n",
    "    t2_y.append(accuracy_test[i])\n",
    "    \n",
    "t1 = plt.plot(t1_x,t1_y , color='orange',label='Training Acc')\n",
    "t2 = plt.plot(t2_x,t2_y, color= 'red',label='Validation Acc')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(['Training Acc','Testing Acc'])\n",
    "plt.show()\n",
    "\n",
    "t1_x = []\n",
    "t1_y = []\n",
    "t2_x = []\n",
    "t2_y = []\n",
    "for i in epoch_list :\n",
    "    t1_x.append(i)\n",
    "    t1_y.append(loss_train_epoch[i])\n",
    "    t2_x.append(i)\n",
    "    t2_y.append(loss_test[i])\n",
    "\n",
    "t1 = plt.plot(t1_x,t1_y , color='orange',label='Training Loss')\n",
    "t2 = plt.plot(t2_x,t2_y, color= 'red',label='Test Loss')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend(['Training Loss','Testing Loss'])\n",
    "plt.show()\n",
    "\n",
    "t1_x = []\n",
    "t1_y = []\n",
    "t2_x = []\n",
    "t2_y = []\n",
    "for i in epoch_list :\n",
    "    t1_x.append(i)\n",
    "    t1_y.append(loss_train_std[i])\n",
    "    t2_x.append(i)\n",
    "    t2_y.append(accuracy_train_std[i])\n",
    "\n",
    "t1 = plt.plot(t1_x,t1_y , color='orange',label='Training Loss std')\n",
    "t2 = plt.plot(t2_x,t2_y, color= 'red',label='Training Acc std')\n",
    "plt.title(\"Std\")\n",
    "plt.legend(['Training Loss std','Training Acc std'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
